---
layout: single
title:  "SSD 논문 리뷰"
categories : paper
tag : [SSD, object-detection, 논문리뷰, 딥러닝]
toc: true
toc_sticky: true
---

![header](https://capsule-render.vercel.app/api?type=waving&color=a2dcec&height=300&section=header&text=SSD 논문 리뷰&fontSize=40&animation=fadeIn&fontAlignY=38&fontColor=FFFFFF)

- 논문 링크 : [SSD: Single Shot MultiBox Detector](https://arxiv.org/abs/1512.02325)



## Introduction

- SSD는 단일 깊은 신경망을 사용한 탐지 기법

- 예측 단계에서 SSD는 디폴트 박스 내 객체 카테고리 존재 여부를 점수화하여 디폴트 박스가 객체 모양과 더 일치하도록 조정
    - 디폴트 박스는 YOLO에서의 anchor box와 같은 개념
    
- SSD는 다양한 크기의 객체를 탐지하도록 서로 다른 해상도를 갖는 여러 피처 맵의 예측 결과를 활용함

- SSD는 영역 추정을 필요로 하는 다른 객체 탐지 기법에 비해 상대적으로 간단함
  
    → 영역 추정 단계와 반복적인 피처 샘플링을 제거하여 모든 연산을 단일 네트워크로 수행하기 때문에, 이런 과정 때문에 훈련이 잘 됨 또한 다른 객체 탐지 요소와 결합도 쉬움
    
- 훈련과 예측을 단일 프레임워크로 처리한다는 장점이 있음

- Faster R-CNN보다 좋은 성능, 다른 single-stage 모델과 비교해도 SSD는 더 작은 이미지 크기로도 더 높은 정확도를 기록함

- SSD의 접근법 3가지 (1. 경계 박스 추정, 2. 각 경계 박스마다 피처 재 추출, 3. 성능 좋은 분류기 적용)
    - 위와 같은 파이프라인은 선택적 탐색이 나온 이후로 꾸준히 객체 탐지 모델에 적용해 왔음
    
- 정확성이 높다는 장점이 있지만 실시간 객체 탐지 서비스에 적용하기에는 속도가 느림

- 이 논문이 나왔을 때 기준으로 가장 속도가 빠른 모델은 Faster R-CNN이고 속도가 7 FPS, SSD는 59 FPS, YOLO 45 FPS 속도
    - 속도가 빨라진 이유는 경계 박스 추정과 연이은 피처 재 추출 단계를 없앴고 다양한 개선 사항을 더하면서 기존 시도보다 정확도가 높아짐
    
- 객체 클래스와 경계 박스 좌표를 예측하기 위해 작은 합성곱 필터를 사용함
    - 합성곱 필터는 다양한 스케일과 가로세로 비율의 피처 맵을 잘 탐지
    - 다양한 스케일로 예측하기 위해 다중 계층을 사용하는 방법으로 높은 정확도와 빠른 속도를 달성

- 요약
    - 기존의 SOTA인 YOLO보다 빠르고 정확한 SSD, 1-stage detector 방식임(region proposal 따로 안 함)
    - SSD의 핵심은 작은 합성곱 필터를 피처 맵에 적용해 고정된 경계 박스들을 활용해 클래스 레이블과 경계 박스 좌표를 예측한다는 것이 핵심
    - 정확도를 높이기 위해 다양한 스케일의 피처 맵에서 여러 스케일로 예측, 가로세로 비율에 따라 분리해 예측
    - 위와 같은 내용으로 end-to-end 방식으로 간단히 훈련할 수 있음, 입력 이미지의 해상도가 낮더라도 높은 정확도 보임



## SSD(The Single Shot Detector) - model



### SSD(The Single Shot Detector) 프레임워크

![Untitled](/images/2022-06-29-SSD/Untitled.png)

- (a) SSD는 훈련 시, 입력 이미지와 각 객체별 ground truth boxes만을 필요로 함, 입력 이미지에 합성곱 연산을 수행해 feature map 계산
- 이때 앞서 말했든 여러 차례 합성곱 연산을 해서 다양한 크기의 feature map을 생성, 다양한 feature map마다 각 픽셀당 서로 다른 비율을 갖는 default box를 가짐
    - 위 이미지에서 (b), (c)에 점선 이미지를 default box라고 함, default box는 한 픽셀당 네 가지 존재, (b) 8x8 feature map에서는 default box가 총 8x8x4
    - 4x4 feature map에서는 4x4x4개가 존재
- 각 default box마다 ‘경계 박스 좌표’, ‘그 경계 박스의 객체 신뢰도 점수’ 두 개를 예측함
- 위 (c) 그림에서 보다시피 객체 신뢰도 점수를 ![image-20220629165946818](/images/2022-06-29-SSD/image-20220629165946818.png) 로 표현
- 훈련 단계에서 default box를 먼저 ground truth boxes와 매칭
- 위 (a) 그림처럼 두 가지 default box가 고양이, 강아지 각각 한 마리씩 매칭되었다고 하면, 이 두 개의 default box를 positive로 간주하고 나머지 default box는 negative로 간주함



### Model

- SSD 모델의 가장 중요한 특징은 여러 가지 크기의 오브젝트를 검출하기 위해 default box를 각각의 feature map에 맞게 사용한다는 것
- 해상도가 높은 feature map에서 상대적으로 작은 박스를 사용하기 때문에 크기도 작은 오브젝트를 검출할 수 있으며 이런 원리로 다양한 크기의 오브젝트 검출이 가능해짐
- 고정되어 있는 bounding box들의 확률치를 구하여 ****이를 이용한 ****NMS 과정을 거친 뒤 최종 위치를 정함
- 전통적인 이미지 분류 모델 아키텍처를 SSD 앞부분에 사용, 이를 기본 네트워크
    - SSD에서는 기본 네트워크로 VGG-16 사용, 기본 네트워크 다음에 또 다른 구조를 덧붙임

![Untitled](/images/2022-06-29-SSD/Untitled%201.png)

- **Multi-scale feature maps for detection**
    - 기본 네트워크 다음에 여러 합성곱 피처 계층을 덧붙인 상태
    - 이 계층의 크기는 차례로 줄어듦, 다양한 스케일로 객체를 탐지하기 위함
    - 각 피처 계층마다 객체 탐지를 수행하는 것
        - base로 사용한 VGG-16에서도 feature map 추출, 이후 FC 단계의 conv에서도 feature map, 점차 줄여가면서 각 단계마다 feature map 추출함
        - 즉 bounding box를 각 계층마다 뽑음, 300x300 기준 8732개의 bounding box 추출
    - VGG-16의 결과에서는 공간 정보, 나머지 layer를 거치면서 feature의 특징을 뽑아내서 많은 정보를 가지는 bounding box들을 얻을 수 있다는 것이 SSD 장점
        - U-net의 복원 과정에서 이전 layer들의 결과를 사용하는 것과 같은 모습
    
    > 이 부분에서 Yolo v1과의 차이는 yolo는 최종적으로 마지막 단계에서만 feature map을 뽑고 그 개수가 98개 상대적으로 적은 bounding box를 추출, 상대적으로 적은 정보로 정확도가 떨어짐 (VOC mAP 기준 yolo는 63.4, SSD는 74.3, Fast R-CNN 73.2 )
    
    
    
- **Convolutional predictors for detection**
    
    - m x m 크기에 p 개의 channels을 갖는 feature map이 있을 때, 3x3xp 크기의 convolution을 사용
    - 위의 conv 수행으로 category에 대한 점수, bounding box regression을 수행
    
    > yolo는 category score, bbox regression을 fc layer에서 수행함, 실제로 모델 구성을 확인했을 때 1-stage detector라는 공통점을 빼면 SSD와 유사한 점을 찾기 어려움, 오히려 Faster R-CNN과 비슷한 구성
    
    
    
- **Default boxes and aspect ratios**
    - bounding box 1개를 얻으면 그 안에 (x,y,w,h) 정보 4개가 들어있음
        - x, y : 객체 중심 좌표
        - w, h : 이미지 너비, 높이
    - 구별해야 하는 class의 수 = c라고 한다면 각 class 개수 + bounding box 위치정보가 들어있어서 (C+4) 개의 location의 feature map이 생성
    
    ![Untitled](/images/2022-06-29-SSD/Untitled%202.png)
    
    - 위의 이미지를 자세하게 확인하면 각 layer 결과가
        - 3x3x(4x(classes + 4)) 또는 3x3x(6x(classes + 4))으로 구성되어 있음
        - 3x3 conv를 수행할 때 4,6은 뽑을 bounding box의 개수를 의미 즉
            - pascal voc 기준으로 설명하면
              
                ![Untitled](/images/2022-06-29-SSD/Untitled%203.png)
                
                - pascal voc는 class가 배경(1) 을 포함한 총 21개의 class로 구성되어 있음
                - 3x3(6x(21+4))는 3x3 conv 수행 시 채널은 21 클래스 + 4개의 위치정보가  담긴 6개의 bounding box를 뽑는 것
                - 6x(21+4) = 150개(output 채널 수), 결과물은 1x150의 벡터로 결과가 나오고
                - 1x150개 중에서 맨 앞의 4개는 1번째 bbox의 위치정보, 뒤에 21개는 bbox의 class 확률, 그다음 4개는 bbox의 2번째 위치정보, 21개 class 확률….
                - 이렇게 yolo의 anchor box와 유사한 형태로 나옴
                - 결과물인 1X150 vector가 모여서 각 layer의 input 크기만큼 생성이 됨
                    - 예를 들어 conv 3x3(6x(21+4))의 input으로 19x19x1024 가 들어왔다면
                    - 결과물로 19x19x150가 결과로 출력
        
    
    > yolo의 anchor box는 객체의 개수만큼 결과물이 생겨서 vector 자체가 가지고 있는 정보량이 SSD의 vector보다 적음, 또한 각 layer 단계에서 ssd는 feature map 크기가 다양하기 때문에 해상도가 다양해지고 이를 활용해 더욱 효과적인 객체 검출을 수행할 수 있음
    
    

### Training

- 훈련을 위해서 ground truth box가 필요함
    - Faster R-CNN, Yolo 도 ground truth box 필요함
    - 이를 통해 end-to-end 훈련에 손실 함수와 역전파 적용할 수 있음

    
    
- **Matching strategy**
    - model 부분에서 bbox는 300x300 이미지 기준  8732개가 생성됨
    
    - default box 중 ground truth box와 잘 매칭되는 box를 찾아야 함
        - ground truth box에 매칭되는 default box를 찾는 방식으로 훈련이 진행
        - 판단 기준으로 IoU를 사용, IoU가 큰 box 한 개만 찾는 것이 아닌 0.5 보다 큰 모든 default box를 찾음
        
        
    
- **Training objective**
    - SSD의 전체 손실 함수는 Faster R-CNN과 동일
    - ![image-20220629165146657](/images/2022-06-29-SSD/image-20220629165146657.png) : i 번째 default box와 j번째 ground truth box가 매칭되는지 여부
    - ![image-20220629165303029](/images/2022-06-29-SSD/image-20220629165303029.png) : Faster R-CNN과 같음
        - ![image-20220629165326034](/images/2022-06-29-SSD/image-20220629165326034.png) : confidence loss, N : bbox 매칭 했을때 매칭된 box들의 수
        - ![image-20220629165344084](/images/2022-06-29-SSD/image-20220629165344084.png) : localization loss : bbox regression loss
            - ![image-20220629165412396](/images/2022-06-29-SSD/image-20220629165412396.png) : x는 width의 비율로 계산
            - ![image-20220629165434884](/images/2022-06-29-SSD/image-20220629165434884.png) : y는 height의 비율로 계산
            - ![image-20220629165528757](/images/2022-06-29-SSD/image-20220629165528757.png) : width는 log scale 적용
            - ![image-20220629165544607](/images/2022-06-29-SSD/image-20220629165544607.png) : height는 log scale 적용
            
            - 너비, 높이에 log 취하는 이유는 상대적으로 x, y 좌표보다 너비 높이의 변화율이 커서 log 취함
    
    > 기존 yolo v1과의 차이점은 yolo v1은 아무것도 없는 상태에서 bbox를 바로 예측하지만 ssd는 bbox regression을 수행해서 위치를 조정해 더 좋은 정확도를 얻음
    
    
    
- **Choosing scales and aspect ratios for default boxes**
  
    ![Untitled](/images/2022-06-29-SSD/Untitled%204.png)
    
    - (a) 번 이미지를 보면 객체가 큰 이미지와 객체가 작은 이미지는 서로 다른 conv에서 나온 feature map을 사용하는 걸 확인할 수 있음
      
        ![Untitled](/images/2022-06-29-SSD/Untitled%202.png)
        
        - 각 conv layer에서 출력이 나오는데 가면 갈수록 conv input의 크기가 작아지면서 detection 된 영역이 원본에서는 큰 이미지로 잡히고, 반대로 앞에 있는 layer들은 상대적으로 원본에서 작은 객체가 detection 됨
        - 실제로 (a)의 고양이를 확인했을 때 8x8 conv로 4x4 보다 앞에 존재하는 conv이고 이때 고양이는 IoU ≥ 0.5이지만 강아지는 배경으로 처리됨
        - (a)의 강아지는 8x8 conv 보다 뒤에 있는 4x4 conv이고 강아지 객체는 IoU > =0.5 이지만 고양이는 배경처리가 됨
        
        >결과적으로 해상도가 큰 이미지에서 작은 객체가 검출되고, 해상도가 작은 이미지에서는 큰 객체가 검출되는 방식으로 이루어짐
        
      
  
- **각 단계의 bbox**
  
    ![Untitled](/images/2022-06-29-SSD/Untitled%205.png)
    
    - 하나의 이미지에서 동일 객체를 각 conv에서 한 객체를 맞추려고 각각 학습함
    - 이로 인해서 1-stage detector 방식이지만 yolo보다 성능이 높음

  
  
- default box를 위한 scale 공식
    1. ![image-20220629165629654](/images/2022-06-29-SSD/image-20220629165629654.png)
    2. ![image-20220629165642571](/images/2022-06-29-SSD/image-20220629165642571.png)
    3. ![image-20220629165655345](/images/2022-06-29-SSD/image-20220629165655345.png)
    
    - ![image-20220629165706776](/images/2022-06-29-SSD/image-20220629165706776.png) = 0.2, ![image-20220629165718886](/images/2022-06-29-SSD/image-20220629165718886.png) = 0.9
    - 1번 식에 m 대입하면 서로다른 6개의 s값이 출력 (m =  feature map의 수, 논문에서는 6)
    - 여기에 aspect ratio = {1,2,3,1/2,1/3} 설정, 설정된 a값에 따라 3번식의 사각형 모양이 변함 (a= 1 일때 3번식에 의해 정사각형, 2면 1:2인 직사각형 이렇게 변함)

    
    
- **Hard negative mining**
    
    - background에 대한 bbox가 객체에 비해 더 많은 개수를 가지고 있기 때문에 class 불균형이 발생
    - soft-max를 통한 확률 중 background로 설정되었지만 그 확률이 적은 bbox를 뽑아서 정렬
    - positives : negatives 비율 3:1로 사용함
    
    > class 불균형을 해소하기 위한 방법
    
    
    
- Data Augmentation
    - 전체 이미지 사용
    - 객체가 최소 IoU 0.1,0.3,0.5,0.7,0.9가 되도록 패치 설정
    - 랜덤 샘플링 해서 패치 구함
    
    

## SSD 리뷰 후기

- 장점
    - FC layer에 dense 사용하지 않고 conv를 사용 → 가중치 수 감소하고 속도가 증가하는 효과
    - 여러 feature 맵을 사용하고 한 이미지에 대해 각각의 conv에서의 결과를 모두 반영하기 때문에 더욱 정확도가 높은 결과를 얻음
    - 논문 기준 feature map이 6개이기 때문에 다양한 물체를 검출하기 좋음
    
    > 추가로 1-stage-detector는 SSD가 변형된 형태가 대부분이고 yolo 계열은 독자적으로 다른 방식으로 1-stage-detector가 발전한 형태
    > 
    
    > SSD는 Yolo와 유사한 점은 딱히 없지만 Yolo와 비교하면서 SSD만의 장점을 더 깊게 배울 수 있었습니다.