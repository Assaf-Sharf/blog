---
layout: single
title:  "핸즈온 머신러닝 - 14"
categories : scikit-learn
tag : [scikit-learn, machine-learning, python]
toc: true
toc_sticky: true
use_math : true
---

![header](https://capsule-render.vercel.app/api?type=waving&color=a2dcec&height=300&section=header&text=핸즈온 머신러닝 - 14&fontSize=40&animation=fadeIn&fontAlignY=38&fontColor=FFFFFF)

- 참고 : [핸즈온 머신러닝 2판](http://www.kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&ejkGb=KOR&barcode=9791162242964)

------------------------------------------------------

&nbsp;

## 합성곱 신경망을 사용한 컴퓨터 비전

- 지각은 간단한 문제가 아니고 이를 이해하기 위해서는 감각기관의 작동 원리를 이해해야 함
- 함성곱 신경망(CNN)은 1980년대부터 이미지 인식 분야에 사용
- CNN 시각분야 뿐만 아니라 **음성 인식**, **자연어 처리**와 같은 다른 작업에도 많이 사용됨

&nbsp;

### 시각 피질 구조

- 대뇌의 뉴런들이 시야의 일부 범위 안에 있는 시각 자극에만 반응
- 고수준의 뉴런이 저수준 뉴런의 출력에 기반한다는 의미를 얻음
- 위의 구조가 결과적으로 전체 시야 영역에 포함된 모든 종류의 복잡한 패턴을 감지할 수 있게 함

&nbsp;

### 합성곱 층

- CNN의 가장 중요한 구성 요소는 **합성곱 층**

  - ![image-20230222133107473](/images/2023-02-22-hands_on_14/image-20230222133107473.png)

  - 첫 번째 합성곱 층의 뉴런은 입력 이미지의 모든 픽셀에 연결되는 것이 아니라 합성곱 층 뉴런의 수용장 안에 있는 픽셀에만 연결

  - 두 번째 합성곱 층에 있는 각 뉴런은 첫 번째 층의 작은 사각 영역 안에 위치한 뉴런에 연결

  

  > 위와 같은 구조는 네트워크가 첫 번째 은닉층에서는 작은 저수준 특성에 집중하고, 그다음 은닉층에서는 더 큰 고수준 특성으로 조합해나가도록 도와줌. 
  >
  > 해당 하는 계층적 구조는 실제 이미지에서 흔히 볼 수 있으며, 이는 CNN이 이미지 인식에 잘 작동되는 이유 중 하나

&nbsp;

- **패딩**

  ![image-20230222133401775](/images/2023-02-22-hands_on_14/image-20230222133401775.png)

  - 위 이미지와 같이 높이와 너비를 이전 층과 같게 하기 위해 입력 주위에 0을 추가하는 것을 **제로 패딩**이라고 함

  ![image-20230222133454928](/images/2023-02-22-hands_on_14/image-20230222133454928.png)

  - 수용장 사이에 간격을 두어 큰 입력층을 훨씬 작은 층에 연결하는 것도 가능
    - 해당 기능은 모델의 계산 복잡도를 낮춰줌
  - 한 수용장과 다음 수용장 사이 간격을 **스트라이드**라고 함
  - 위 그림에서 5x7 입력층(제로 패딩 적용)이 3x3 수용장과 스트라이드 2를 사용해 3x4층에 연결
  - 상위층의 i행, j열에 있는 뉴런이 이전 층의 $i * S_h$에서 $ i * S_h + f_h -1$ 까지의 행과 $ j * S_w $ 에서 $ j * S_w + f_w -1 $ 까지의 열에 위치한 뉴런과 연결
  - 여기서 $ S_h, S_w $는 스트라이드의 수직 값과 수평 값  

&nbsp;

#### 필터

![image-20230222140006007](/images/2023-02-22-hands_on_14/image-20230222140006007.png)

- 뉴런의 가중치는 수용장 크기의 작은 이미지로 표현될 수 있음
- **필터**라 부르는 두 개의 가중치 세트를 위 그림에서 보면 첫 번째것은 가운데 흰 수직선이 있는 검은 사각형
  - 이런 가중치를 사용한 뉴런은 가운데 수직선 부분을 제외하고는 수용장에 있는 모든 것을 무시할 것

- 두 번째 필터는 가운데 흰 수평선이 있는 검은 사각형
  - 해당 가중치를 사용한 뉴런은 가운데 수평선 부분을 제외하고는 수용장 안의 모든 것을 무시

- 층의 전체 뉴런에 적용된 하나의 필터는 하나의 **특성 맵**을 생성
  - 특성맵은 필터를 가장 크게 활성화시키는 이미지의 영역을 강조
  - 수동으로 필터를 정의할 필요가 없음
  - 훈련하는 동안 합성곱 층이 자동으로 해당 문제에 가장 유용한 필터를 찾고 상위층은 이들을 연결하여 더 복잡한 패턴을 학습


&nbsp;

#### 여러 가지 특성 맵 쌓기

- 실제 합성곱층은 여러 가지 필터를 가지고 필터마다 하나의 특성 맵을 출력하므로 3D로 표현

- 각 특성 맵의 픽셀은 하나의 뉴런에 해당하고 하나의 특성 맵 안에서는 모든 뉴런이 같은 파라미터를 공유하지만, 다른 특성 맵에 있는 뉴런은 다른 파라미터를 사용

  - 한 수용장은 이전 층에 있는 모든 특성 맵에 걸쳐 확장 됨
  - 하나의 합성곱 층이 입력에 여러 필터를 동시에 적용하여 입력에 있는 여러 특성을 감지할 수 있음

  > CNN이 한 지점에서 패턴을 인식하도록 학습되었다면 다른 어느위치에서도 해당 패턴 인지 가능
  >
  > DNN은 한 지점에 있는 패턴을 인식하도록 학습되었다면 오직 패턴이 그 위치에 있을 때만 감지가 가능

- 입력 이미지는 **컬러 채널**마다 하나씩 여러 서브 층으로 구성되기도 함, 컬러 채널은 전형적으로 빨강, 파랑, 초록의 RGB 3개 
  - 흑백 이미지는 하나의 채널만 가짐, 하지만 어떤 이미지는 매우 많은 채널을 가질 수 있음
    - 위성 이미지는 가시광선외에도 다른 빛의 파장이 기록됨

![image-20230222180115602](/images/2023-02-22-hands_on_14/image-20230222180115602.png)

- 구체적으로 보면, 합성곱 층 $l$에 있는 $k$특성 맵의 $i$행,$j$열에 위치한 뉴런은 이전 $l-1$층에 있는 모든 특성 맵의 $i * S_h$에서 $i * S_h + f_h - 1$까지의 행과 $i * S_w$에서 $i * S_w + f_w -1$까지의 열에 있는 뉴런의 출력에 연결
  - 다른 특성 맵이더라도 같은 $i$행과 $j$열에 있는 뉴런이라면 정확히 이전층에 있는 동일한 뉴런들의 출력에 연결됨
- **합성곱 층에 있는 뉴런의 출력 계산**\
  - $z_{i,j,k} = b_k + \sum_{u=0}^{f_h-1} \sum_{v=0}^{f_w-1} \sum_{k'=0}^{f_n'-1} \chi_{i',j',k'} * W_{u,v,k',k}$
  - $i' = i * S_h + u, j' = j * S_w + v$
  - 해당 수식은 합성곱 층에서 한 뉴런의 출력을 계산하는 법에 해당, 입력에 대한 가중치 합을 계산하고 편향을 더하는 것


&nbsp;

#### 텐서플로 구현

- 텐서플로에서 각 입력 이미지는 보통 [높이, 너비, 채널] 형태의 3D 텐서로 표현

- 하나의 미니배치는 [미니배치 크기, 높이, 너비, 채널] 형태의 4D 텐서로 표현

- 합성곱 층의 가중치는 [$f_h, f_w, f_n', f_n$] 형태의 4D 텐서로 표현, 합성곱 층의 편향은 간단하게 [$f_n$] 형태의 1D 텐서로 나타냄

-  예제

  ```python
  import numpy as np
  from sklearn.datasets import load_sample_image
  
  # 샘플 이미지를 로드합니다.
  china = load_sample_image("china.jpg") / 255
  flower = load_sample_image("flower.jpg") / 255
  images = np.array([china, flower])
  batch_size, height, width, channels = images.shape
  
  # 2개의 필터를 만듭니다.
  filters = np.zeros(shape=(7, 7, channels, 2), dtype=np.float32)
  filters[:, 3, :, 0] = 1  # 수직선
  filters[3, :, :, 1] = 1  # 수평선
  
  outputs = tf.nn.conv2d(images, filters, strides=1, padding="SAME")
  
  plt.imshow(outputs[0, :, :, 1], cmap="gray") # 첫 번째 이미지의 두 번째 특성맵을 그립니다.
  plt.axis("off") # 책에는 없습니다.
  plt.show()
  ```

  ![image-20230222191200636](/images/2023-02-22-hands_on_14/image-20230222191200636.png)

  - tf.nn.conv2d()
    - image는 입력의 미니배치(4D)
    - filters는 적용될 일련의 필터(4D)
    - strides는 1이나 4개의 원소를 갖는 1D 배열로 지정할 수 있음, 1D 배열의 가운데 두 개의 원소는 수직, 수평, 스트라이드이고 현재는 첫 번째와 마지막 원소가 1이어야 함
    - padding은 'valid'와 'same' 중 하나를 지정
      - 'valid'로 지정하면 합성곱 층에 제로 패딩을 사용하지 않음
      - ![image-20230222192817569](/images/2023-02-22-hands_on_14/image-20230222192817569.png)
      - ![image-20230222193122146](/images/2023-02-22-hands_on_14/image-20230222193122146.png)

  - 해당 예제에서는 필터를 직접 지정, 하지만 CNN을 사용할때는 보통 훈련 가능한 변수로 필터를 정의 하므로 앞서 설명한 것처럼 신경망이 가장 잘 맞는 필터를 학습할 수 있음

    ```python
    conv = keras.layers.Conv2D(filters=32, kernel_size=3, strides=1, 
                               padding='same', activation='relu')
    ```

    - 해당 코드는 3x3 크기의 32개의 필터, 수평 수직 스트라이드 1, 'same' 패딩을 사용하는 conv2d 층을 만들고 출력을 위해 ReLU 활성화 함수를 적용
    - 합성곱 층을 위해 꽤 많은 하이퍼파마리터가 필요 <- 필터의 수, 필터의 높이와 너비, 스트라이드, 패딩 종류

&nbsp;

#### 메모리 요구 사항

- CNN에 관련된 또 하나의 문제는 합성곱 층이 많은 양의 RAM을 필요로 함
  - 특히 훈련하는 동안에 역전파 알고리즘이 역방향 계산을 할 때 정방향에서 계산했던 모든 중간 값을 필요로 하기 때문
  - 예시로 5 x 5 필터로 스트라이드 1과 'same' 패딩을 상요해 150 x 100 크기의 특성 맵 200개를 만드는 합성곱을 예시로 한다면
    - 입력이 150 x 100 RGB 이미지,  파라미터 수는 ((5x5x3+1)x200=15,200) (+1은 편향) 해당수는 완전연결 층보다는 적지만 200개의 특성 맵마다 150x100개의 뉴런을 포함하고, 각 뉴런이 5x5x3개의 입력에 대한 가중치 합을 계산
    - 추론을 수행할 때는 하나의 층이 점유하고 있는 RAM은 다음 층의 계산이 완료되자마자 해제가 가능
      - 연속된 두 개의 층에서 필요로 하는 만큼의 RAM만 가지고 있으면 가능함

&nbsp;

### 풀링 층

