---
layout: single
title:  "Pytorch-6 model 공유"
categories : Pytorch
tag : 
toc : true
---

기존에 학습되어 있는, 만들어져 잇는 모델을 가져와서 내 타깃을 학습하는 과정.

# 학습 결과를 공유하고 싶다.

코랩으로 하면 8시간 후에 꺼짐 -> 결과가 다 날라감

##  model.save()
학습 결과를 저장
모델형태와 parameter를 저장
모델 학습 중간 과정을 저장해, 최선의 결과모델을 선택
만들어진 모델을 외보에 공유


### 실습 코드)
코랩 가상환경에 올리면 상당히 오래 걸림
구글 드라이브에 올린 다음에 거기서 파일옮기는 것을 권장(더 빠름)


state_dict 는 모델의 파라메터를 표시함 
```python
# Print model's state_dict
print("Model's state_dict:")
# state_dict 는 모델의 파라메터를 표시함 

for param_tensor in model.state_dict():
	print(param_tensor, "\t", model.state_dict()[param_tensor].size())

```


torchsummary 쓰면 모델을 keras 형태로 대략적인 모습을 볼 수 있다.
```python
from torchsummary import summary
summary(model, (3, 224, 224))
```


torch.save(모델, 위치와 이름) : 모델의 파라메터 저장 (pt로 많이 저장됨)
```python
MODEL_PATH ="saved"
if not os.path.exists(MODEL_PATH):
	os.makedirs(MODEL_PATH)
torch.save(model.state_dict(),
			os.path.join(MODEL_PATH, "model.pt"))
```



.load_state_dict(torch.load(위치,이름)): 같은 모델 형태에서 parameter만 load
```python
new_model = TheModelClass()
new_model.load_state_dict(torch.load(os.path.join(
		MODEL_PATH, "model.pt")))
```


모델의 architecture와 함께 저장
모델의 architecture와 함께 load
```python
torch.save(model, os.path.join(MODEL_PATH, "model_pickle.pt"))
model = torch.load(os.path.join(MODEL_PATH, "model_pickle.pt"))
model.eval()
```


## checkpoints
학습의 중간 결과를 저장하여 최선의 결과를 선택
earlystopping 기법 사용시 이전 학습의 결과물을 저장
loss, metric값을 지속적으로 확인, 저장
epoch, loss, metric을 일반적으로 함께 저장


### 실습코드)
torch.save(에폭, 모델, 옵티마이저 ,로스) 모델의 정보를 epoch과 함께 저장
저장할때 이름은 loss, epoch등을 포함시켜 나중에 파일명으로 볼때 편하게
```python
torch.save({'epoch': e,			
			'model_state_dict': model.state_dict(),			
			'optimizer_state_dict': optimizer.state_dict(),			
			'loss': epoch_loss,
}, f"saved/checkpoint_model_{e}_{epoch_loss/len(dataloader)}_{epoch_acc/len(dataloader)}.pt")
```

각각 load 할때는 이런식으로
```python
checkpoint = torch.load(PATH)
model.load_state_dict(checkpoint["model_state_dict"])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']
loss = checkpoint['loss']
```




user warning 없애주는 코드 (유용함)
```python
import warnings
warnings.filterwarnings("ignore")
```


BCEwithLogitsloss : sigmoid가 자동으로 마지막에 달린다
```python
model.to(device)
criterion = nn.BCEWithLogitsLoss()
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)
```



## transfer learning
다른 데이터셋으로 만든 모델을 현재 데이터에 적용
일반적으로 대용량 데이터셋 -> 모델 성능 좋은 것을 이용
현재 DL에서 가장 일반적인 학습 기법
backbone architecture가 잘 학습된 모델에서 일부분만 변경하여 학습을 수행

ex) nlp에서는 hugginface가 표준으로 사용될 정도

### Freezing 
pretrained model 활용시 모델의 일부분을 frozen 시킴, 나머지만 학습하고 parameter 업데이트

요즘에는 stepping frozen을 통해 하나만 풀고 나머지 frozen을 여러 layer에 적용하여서 학습


### 실습코드)

+ pretrained 모델 loading
```python
import torch
from torchvision import models
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
vgg = models.vgg16(pretrained=True).to(device)
print(vgg)
```

pth는 잘 쓰지 말고 왠만하면 pt 확장자 쓰자

+ 모델에 마지막 linear layer 추가
```python
from torch import nn
from torchvision import models

class MyNewNet(nn.Module):
	def __init__(self):
		super(MyNewNet, self).__init__()
		self.vgg19 = models.vgg19(pretrained=True)
		self.linear_layers = nn.Linear(1000, 1)
		
	# Defining the forward pass
	def forward(self, x):
		x = self.vgg19(x)
		return self.linear_layers(x)
```

+ 마지막 레이어를 제외하고 frozen
```python
#모두 frozen
for param in my_model.parameters():
param.requires_grad = False
#학습 시킬 부분만 풀어 줌
for param in my_model.linear_layers.parameters():
param.requires_grad = True
```


코랩에서 실행시키면 코드가 돌아가는 것을 print보다는 slack으로 보내주는 코드를 적을 수 있다.