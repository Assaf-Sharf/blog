---
layout: post
title:  "Spark Partitioning 자원관리에 대한 고찰"
---

# 파티셔닝을 하는 이유는?

**파티셔닝이란 무엇인가요?**
스파크 파티셔닝은 Apache Spark라는 분산 데이터 처리 프레임워크에서 사용되는 중요한 개념입니다. 
스파크는 대량의 데이터를 효율적으로 처리하기 위한 기능을 제공하며, 이를 위해 데이터를 파티션으로 나누어 분산 처리하는 방식을 채택하고 있습니다.

스파크 파티셔닝은 데이터를 논리적 또는 물리적인 단위로 나누는 과정을 의미합니다. 이렇게 분할된 데이터는 여러 개의 노드에 분산되어 병렬로 처리될 수 있습니다. 스파크의 파티셔닝은 데이터를 효율적으로 분산 저장하고 처리할 수 있도록 도와줍니다.

**파티셔닝의 유형**
1. 첫 번째는 해시 파티셔닝(Hash Partitioning)이며, 데이터의 특정 열 값을 해싱하여 파티션을 할당합니다. 
해시 파티셔닝은 동일한 키 값이 동일한 파티션에 할당되도록 보장하므로, 동일한 키 값을 가진 데이터는 동일한 파티션에서 처리됩니다. 
이를 통해 조인 연산과 같은 작업에서 데이터의 이동이 최소화되어 성능을 향상시킬 수 있습니다.

2. 두 번째는 범위 파티셔닝(Range Partitioning)입니다. 이 방식은 데이터의 특정 열 값을 기준으로 범위를 나누어 파티션을 할당합니다. 
예를 들어, 날짜 열을 기준으로 범위를 나눈다면 각 파티션은 특정 기간의 데이터를 포함하게 됩니다. 
범위 파티셔닝은 데이터의 정렬이나 범위 기반의 질의에 유리하며, 일부 작업에서는 해시 파티셔닝보다 성능이 우수할 수 있습니다.

3. 세번째는 리스트 파티셔닝 입니다. 

스파크에서는 사용자가 직접 파티셔닝 방식을 선택하거나, 데이터의 크기와 특성에 따라 자동으로 파티셔닝을 결정할 수 있는 기능을 제공합니다. 
또한, 파티셔닝은 데이터의 물리적 배치를 제어하는 데 사용되며, 데이터의 로드 및 저장, 셔플 작업 등에서 중요한 역할을 합니다.
스파크 파티셔닝을 효과적으로 활용하면 데이터 처리 작업의 성능을 향상시킬 수 있습니다.

**효과적인 파티셔닝?**
파티셔닝을 무작정 한다고 좋은것은 아닙니다. 

파티션이 많은 경우의 장점과 단점:
장점:
- 데이터가 잘 분산되어 있으면 병렬 처리가 향상되어 전체 작업 속도가 빨라질 수 있습니다.
- 더 적은 데이터 양을 처리하므로 각 파티션에서 메모리 부족 문제가 발생할 가능성이 줄어듭니다.
단점:
- 많은 수의 작은 파티션은 각 작업에 대한 스케줄링 오버헤드를 증가시킬 수 있습니다. 이는 전체 작업 시간을 늘릴 수 있습니다.
- 너무 많은 파티션은 네트워크 트래픽을 증가시킬 수 있으며, 또한 클러스터의 각 노드에서 수행되는 작업 수가 많아져 CPU를 과부하로 만들 수 있습니다.
- 실무 경험상, 해당 parquet을 테이블화 하여 select해서 불러올때, 조회 시간이 오히려 증가하는것을 볼 수 있습니다.
- 파티션의 개수가 너무 많아지기에, 파일 관리가 힘들어집니다. 따로 파티션의 개수와 최소 용량을 지정 안해줄시, 테라바이트 기준의 파일이 KB 단위까지 파티션의 개수가 불어나는것을 확인할 수 있습니다.

파티션이 적은 경우의 장점과 단점:
장점:
- 파티션 수가 적으면 스케줄링 오버헤드가 줄어들어 작업 속도가 빨라질 수 있습니다.
- 네트워크 트래픽이 줄어들며, 각 노드에서 수행되는 작업 수가 줄어 CPU 과부하의 위험이 감소합니다.
단점:
- 데이터가 너무 적게 분산되면 병렬 처리 효과가 감소하여 전체 작업 시간이 증가할 수 있습니다.
- 각 파티션의 데이터 크기가 크면 메모리 부족 문제가 발생할 수 있습니다. 이를 조절하지 않는다면, 매우 자주 터집니다.

결론적으로 Spark는 데이터를 Parquet으로 변환시에 파티션을 생성합니다.
저는 파티션을 생성하는 과정을 해변가에 있는 모래를 집어서 버킷에 뿌리는 행위를 파티션이 많은 경우라 하고, 
버킷에 뿌렸던 모래를 다시 집어서 뭉친뒤에 다시 넣는 행위를 파티션을 적은 경우라고 비유합니다.
- 모래를 버킷에 뿌리기 때문에 작업 속도가 빠르고, 파티션의 개수가 많기에, 데이터가 어디에 있는지 찾으려면 시간이 걸립니다.
- 뿌린 모래를 다시 뭉치면, 작업 속도가 추가로 들지만, 파티션의 개수가 적기에, 데이터를 찾는 속도가 증가합니다.

따라서 적절한 파티션 수를 결정하는 것은 전체 시스템의 리소스, 데이터의 크기, 스케줄링 오버헤드 등 여러 요소를 고려한 복잡한 균형 작업입니다. 이를 통해 데이터 처리의 병렬성과 전체 시스템 성능을 극대화할 수 있습니다.

**자원은 어떻게 조절하는가?**
spark에서 session을 제출할때 자원을 조절할 수 있는 요소는, Driver와 Executor의 메모리와 코어 수 입니다.
1 Core = 1 Task = 1 Partition 
Memory Size = Partition Size 
정리하자면, 
파티션의 개수가 적을 시 = 파티션의 크기가 크고 = 메모리가 더 필요하다
파티션의 개수가 많을 시 = 파티션의 크기가 작고 = 메모리가 적게 필요하다

Ex) 6노드 16코어 64기가 메모리
ExecutorNum = 6      -> 18
ExecutorCores = 15   -> 5
ExecutorMemory = 63G -> 19G

ExecutorNum? ExecutorCores?
- 노드당 3개의 executor를 돌릴 수 있다는 뜻
- 코어수 먼저 정의 하기 5개로 지정
- 16/5 = 3.2-1 = 약 3개
- 노드당 executor는 3개
- 결론 : 3 * 6노드 -> num of executors(ExecutorNum) = 18, ExecutorCores = 5
ExecutorMemory?
- 63/3(노드당 executor 수) = (21*0.07) = 1.47 | 21-1.47 = 19


Ex) 10노드 96코어 384기가 메모리
ExecutorNum? ExecutorCores?
- 코어수 먼저 정의 하기 4개로 지정
- 96코어/4 = 24개-1 (리소스 100%사용은 안됨) = 23개
- 노드당 executor는 23개 
- 결론 : 23 * 10노드 -> num of executors(ExecutorNum) = 230, ExecutorCores = 4
ExecutorMemory?
- 384 -> yarn 리소스용 제외 360기가라고 가정
- 360기가 / 24 = (15*0.07) = 1.05 | 15-1.05 = 14





참고자료
https://tech.kakao.com/2021/10/08/spark-shuffle-partition/
https://jaemunbro.medium.com/apache-spark-partition-%EA%B0%9C%EC%88%98%EC%99%80-%ED%81%AC%EA%B8%B0-%EC%A0%95%ED%95%98%EA%B8%B0-3a790bd4675d
https://jaemunbro.medium.com/spark-executor-%EA%B0%9C%EC%88%98-%EC%A0%95%ED%95%98%EA%B8%B0-b9f0e0cc1fd8
https://m.blog.naver.com/syung1104/221103154997

