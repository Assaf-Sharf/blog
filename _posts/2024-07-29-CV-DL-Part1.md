---
layout: single
title: "Image Data, Convolutional Layer"
categories: Deep-Learning
tag: [Deep-Learning, ComputerVision]
use_math: true
---

컴퓨터비전 딥러닝 기본이론

# 1.Image Data

## 1-1.데이터 이해하기

<img src="{{site.url}}/images/240729/0000.png" width="1200" height="300">

이미지 데이터는 사각형 모양의 데이터로 가로 $N$, 세로 $M$인 이미지는 $NM$개의 픽셀들로 구성되어 있다. 첨부된 흑백(Gray Scale) 이미지를 보면, 검은색은 0, 흰색은 255인 픽셀들로 구성되어 있음을 볼 수 있는데 이를 통해 이미지 데이터가 갖는 특성에 대해 정리해보자.

- 이미지의 너비(Width)와 높이(Height)는 행렬의 행의 수와 열의 수와 같고, 픽셀은 행렬의 원소와 같다.
- 픽셀은 0과 255 사이의 값을 가질 수 있고, 0에 가까울 수록 검은색 255에 가까울수록 흰색에 가깝다.
- 즉, 이미지 데이터는 $N\times M$ 행렬과 같다.

일상에서 흔히 보는 색상 이미지(Color Image)는 동일한 크기의 행렬 3개가 모여 만들어지는데, 실제로 이미지의 형상을 출력하면 $H\times W\times 3$ 이라는 결과를 출력하게 된다.

<img src="{{site.url}}/images/240729/0001.png" width="1200" height="300">
$H, W$는 각각 높이와 너비라는 것은 알겠는데 뒤에 있는 3은 무엇일까?  
이는 빛의 3원색인 Red, Green Blue를 나타내는 것으로 $H\times W$ 크기의 행렬 3개가 각각 빨간색, 초록색, 파란색을 담당하고 있음을 의미한다.  
(이어지는 내용에서는 이와 같이 색상을 담당하는 행렬을 채널(Channel)로 표현한다.)

### 1-2. JPG와 PNG

앞으로 이미지 데이터를 기반으로한 task를 하다보면 jpg로 저장된 파일 또는 png로 저장된 파일들을 다루게 될텐데 jpg와 png는 모두 이미지 파일의 형식(format)으로, 서로 다른 장단점을 가지고 있다.

**JPG**

- 8비트를 통해 픽셀값을 할당. 검은색 픽셀 0은 0x00, 흰색 픽셀 255는 11111111
- 즉, 흑백 이미지의 픽셀은 8bit(1byte)이고 컬러 이미지의 픽셀은 RGB 채널별 픽셀이 8bit씩 사용해 총 24bit(3byte)이다.
- ```손실 압축 방식```으로 저장과 전송을 하므로, 속도가 매우 빠르지만, 일부 픽셀의 값이 삭제되는 문제가 있다. 
- 이로 인해 이미지를 가공할수록 품질이 점점 저하된다.
    

**PNG**

- jpg와 마찬가지로 8bit로 픽셀을 나타내며 RGB 컬러 이미지는 최대 24bit를 사용한다.
- 특이한 점은 32비트 RGBA라는 형태도 지원하는데, A는 알파 채널을 의미한다.
- 알파 채널은 픽셀별 “투명도”를 담당하며 이를 통해 이미지의 특정 부분을 투명하게 만들 수 있다.  
- ```비손실 압축 방식```을 사용하기 때문에 원본 이미지를 가공하더라도 품질이 저하되지 않는다.
- 이로 인해 저장, 전송과 같은 작업시 jpg보다 처리 속도가 느리다.


# 2.Convolution Layer

## 2-1.왜 conv layer를 사용할까?

### 문제점 1 : 계산 비용
이미지 데이터를 처리할 때 Fully Connected Layer를 사용한다면 어떨까??
- FC layer는 입력되는 데이터(x)가 $n$차원 벡터이며, 각각의 원소별로 가중치가 곱해지는 형태의 연산을 수행한다.
- 이미지 데이터는 행렬이므로, FC layer로 입력하기 위해서는 $H\times W\times 3$의 컬러 이미지를 $3(HW)$ 차원의 벡터로 만들어줘야한다. → 이를 Flatten, 평탄화라고 함.
    - $64\times 64\times3$ 이미지를 flatten하면 12288차원의 벡터가 만들어진다.
    - $224\times 224\times 3$ 이미지는 150528차원의 벡터가 만들어진다.
    - $1000\times 1000\times 3 = 3,000,000$
- 이와 같이 이미지의 너비와 높이값에 따라 벡터의 차원이 극단적으로 커져, 3,000,000 차원의 벡터를 입력으로 받는  hidden layer의 weight matrix 크기는$(\text{f}_{out}, 3,000,000)$가 된다.

결과적으로 하나의 layer가 총 $3,000,000 \times f_{out}$개의 parameter를 갖게 되어 계산 비용이 매우 비싸고, parameter의 수가 너무 많아져(복잡도가 높아져) overfitting될 가능성이 높아진다.

### 문제점 2: Spatial Information 손실
이미지 데이터는 인접한 픽셀들이 모여 하나의 객체(object)를 나타내는데 이미지를 Flatten해서 벡터로 만드는 경우 인접한 픽셀들이 모두 직렬화되어 객체, 경계 정보들이 모두 제거된다.  

따라서 이미지가 내포하고 있는 feature를 활용하기 위해서는 행렬과 같은 격자 형태를 그대로 유지한 상태로 처리할 수 있는 방식이 필요하다.


## 2-2. Convolutional Layer

앞서 본 문제를 해결할 수 있는 layer가 Convolutional layer이다. convolution이라는 단어가 포함되어 있듯 convolution(합성곱) 연산을 수행하는 층으로, 이미지와 같은 다차원 데이터를 벡터로 flatten하지 않고 그대로 사용할 수 있게 된다.

<img src="{{site.url}}/images/240729/0002.png" width="1200" height="300">

Convolution 연산은 입력 이미지에 $F \times F$의 필터(또는 커널)를 Sliding Window 방식으로 계산한다. 이는 필터가 보는 영역에 있는 픽셀값들을 대상으로하는 Linear Combination이기 때문에 Locality한 정보들을 구한다고 해석할 수 있다.
- 그림에서는 $3 \times 3$ 크기의 필터(노란색)가 주어진 $5 \times 5$ 크기의 이미지(파란색)를 순회하면서 이미지의 일부분과 convolution 연산을 수행한다.
- 필터가 보는 이미지의 $3 \times 3$ 부분은 element-wise product를 이용해 총 9개의 결과값을 생성하고 이들을 모두 더한 값이 output인 convolved feature에 순차적으로 저장된다.
- $(2\times1)+(4\times2)+(9 \times 3) + (2 \times -4) +(1 \times 7) + (4 \times 4) + (1 \times 1) + (1 \times -5) + (2 \times 1) = 51$

계산비용에 있어서도 FC layer보다 Conv layer가 더 효율성이 높은데, 입력 이미지가 $32 \times 32 \times 3$라고 가정해보자.
- Linear layer는 128개의 뉴런을 가진 경우 $(3072 \times 128) + 128=393,344$
- conv layer는 이고, 필터 크기가 $3\times 3$가 64개 적용되는 경우 $3\times 3 \times 3$ 필터가 64개이므로 $3\times 3\times 3\times 64 + 64 = 1792$

## 2-3. Padding과 Stride

### Padding

Convolution layer의 특징 중 하나는 입력 이미지의 크기보다 출력의 크기가 작다는 것이다.  예를 들어 $5 \times 5$ 인 이미지에 $3 \times 3$ 크기의 필터를 적용하게 되면 출력의 크기는 $ 3 \times 3 $ 로 줄어든다.

<img src="{{site.url}}/images/240729/0004.png" width="1200" height="300">
이는 딥러닝 모델의 Depth를 깊게 하려는 경우 문제가 될 수 있는데 Padding이라는 파라미터를 이용해 입력 이미지의 크기를 유지하는 방법이 있다. 

padding은 이미지의 가장자리에 임의의 값을 가진 픽셀들을 추가하는 것인데 일반적으로는 특별한 의미를 갖지 않도록 하기 위해 0으로 채워넣는 Zero-Padding을 많이 사용한다.

### Stride

<img src="{{site.url}}/images/240729/0005.png" width="1200" height="300">

stride는 컨볼루션 필터가 이동하는 간격을 설정하는 것으로 default는 1로 설정되어 한 칸씩 이동하며 이미지에 필터가 적용된다. 
- 좌우뿐만 아니라 상하로도 stride만큼 건너뛴다.
- 2이상의 값으로 stride를 설정하는 경우 필터가 이동하는 간격이 점점 커져 이미지에 필터가 띄엄띄엄 적용된다. 
- 그만큼 출력되는 이미지의 크기는 더 작아지게 된다.


## 2-4. input channel = filter channel

앞서 언급했듯이 RGB 컬러 이미지는 $H\times W\times 3$의 데이터이다. 따라서 컬러 이미지에 컨볼루션 필터를 적용하기 위해서는 필터 역시 $F_h\times F_w\times 3$ 이어야 한다.

- 이는 Linear Layer에서 유닛이 입력 feature의 차원가 동일한 것과 같은 원리로, convolution이 적용되기 위해서는 입력 이미지의 채널과 동일한 필터의 차원이 설정되어야 한다.
- 따라서 하나의 필터가 $3\times 3$ 인 경우 RGB 이미지에 적용되는 필터는 $3\times 3\times 3$.
- 필터의 첫번째 channel은 입력 이미지의 red channel에 적용되고 필터의 두번째 channel은 입력 이미지의 green channel에, 필터의 세번째 channel은 입력 이미지의 blue channel에 적용된다.

> 정리하면 conv layer에서는 입력 텐서의 channel과 필터의 channel이 반드시 같아야 한다.
> {:.notice--danger}


# 3.Conv layer Output

## 3-1.출력 크기 계산

Padding과 Stride의 설정값에 따라 convolution layer가 출력하는 이미지의 크기가 달라진다는 점을 반영해서 출력 이미지의 크기를 계산할 수 있다.

<img src="{{site.url}}/images/240729/0009.png" width="1200" height="300">

- $W_{out}, \ H_{out}$ : 출력 이미지의 너비와 높이.
- $W_{in}, \ H_{in}$ : 입력 이미지의 너비와 높이.
- $F_{width}, F_{height}$ : 필터의 너비와 높이.
- $p$ : 패딩(추가되는 칸의 수)
- $s$ : stride(필터가 이동하는 간격의 크기)
- floor를 적용하는 이유는 분수항이 정수값이 아닌 경우를 처리하기 위함.

## 3-2.Height, Width

<img src="{{site.url}}/images/240729/0007.png" width="1200" height="300">

padding=0, stride=1인 하나의 컨볼루션 필터를 적용했다고 가정하면 출력되는 이미지의 크기는 $4\times 4$로 줄어들고 depth 채널이 없는 것을 알 수 있다. 즉, 필터의 크기와 padding, stride 값을 어떻게 설정하느냐에 따라 출력 이미지의 height, width가 결정된다.

## 3-3.Depth

<img src="{{site.url}}/images/240729/0008.png" width="1200" height="300">

FC layer에서는 뉴런의 수에 따라 출력 차원이 결정되었다. 이와 같은 원리로 convolution layer에서적용할 필터의 수(=유닛의 수)에 따라 출력되는 이미지의 차원이 결정된다.

- Convolution layer에 적용된 필터의 수가 2인 경우, 독립적인 두 개의 $3\times 3\times 3$필터가 이미지에 별도로 적용되어 두 개의 $4 \times 4$ 출력 이미지를 만들어내고, 이를 쌓아 $4\times 4\times 2$의 출력 이미지를 최종적으로 만든다.
- 즉, convolution 연산을 할 때, 입력 이미지와 필터간의 depth는 동일한 차원을 가져야만 하며 출력 이미지의 채널은 convolution layer에 설정된 필터의 수로 결정된다.
- 또한 두 개의 필터를 적용함에 따라, 두 개의 bias가 존재하며 각 출력 이미지에 더해진다.(element-wise addition)

> 정리하면 conv layer의 output feature map에 대한 Depth(channel)은 해당 층의 필터의 수(뉴런의 수)와 같다.
> {:.notice--danger}

# 4.Pooling

<img src="{{site.url}}/images/240729/0011.png" width="1200" height="300">
Pooling Layer는 conv layer가 출력한 feature map을 입력으로 받아 필터가 sliding window 방식으로 적용되게 된다.

- 필터의 크기와 stride를 설정할 수 있다.
- 필터는 conv layer처럼 학습 가능한 파라미터가 존재하지 않으며 단순히 현재 보는 영역에서 최댓값 또는 평균값을 구하여 입력보다 더 작은 크기의 feature map을 출력한다.
- 즉, feature map을 sliding window로 보면서 Spatially Aggregation을 수행하며 크기를 줄이기 때문에 Down-sampling이라고도 한다.
- 여기서 말하는 Spatial은 이미지 또는 feature map의 Height, Width를 말한다.
- Down-sampling으로 인해 텐서의 원소 수가 줄어들기 때문에 모델의 파라미터 수를 줄이는 효과가 있다.

# 5.Receptive Field

<img src="{{site.url}}/images/240729/0012.png" width="1200" height="300">
Receptive Field는 모델을 구성하는 요소는 아니지만, Convolution 연산에서 등장하는 하나의 개념이다.

앞서 컨볼루션은 입력에 필터를 sliding window 방식으로 적용하는 것이고, 각각의 영역마다 dot product를 수행한 결과를 output feature map의 원소로 사용했다. 이 때 필터(뉴런)가 한 번에 보는 영역의 크기를 Receptive Field라고 한다.

- 3개의 conv layer로 구성된 CNN 모델이 있다고 가정.
- 각각의 conv layer는 $ 3 \times 3 $의 필터를 사용.
- 따라서 첫번째 conv layer의 receptive field는 $ 3 \times 3 $이다.
- 두번째 층으로 전달되었을 때, 첫번째 층에서 $ 3 \times 3 $ 영역내 인접 픽셀들이 하나의 값으로 종합되었기 때문에 두번째 층은 총 $ 5 \times 5 $ 만큼의 영역을 한 번에 보는 것과 같다.
- 동일한 방식으로 세번째 층에서는 한 번에 $ 7 \times 7 $ 의 receptive field를 갖는다.

$ 7 \times 7 $ 필터를 갖는 conv layer 하나를 사용했을 때 파라미터가 $ 7 \times 7 \times N filters = 7^2C^2 $ 이고 $ 3 \times 3 $ 필터를 갖는 conv layer를 3개 사용했을 때 총 파라미터는 $ 3 \times (3 \times 3 \times N filters) $ 로 동일한 Receptive Field를 보유하면서 더 층을 깊게 만들 수 있고(비선형성을 높일 수 있음) 더 적은 파라미터를 사용하게 된다.

<img src="{{site.url}}/images/240729/0013.png" width="1200" height="300">

이러한 개념을 모델의 관점으로 해석해보면 CNN을 구성하는 conv layer들 중 입력층에 가까운 층들은 픽셀 단위로 보기 때문에 경계선(edge)와 같은 작은 특징들을 추출하게 되고, 중간층은 선을 종합한 면(plane)을 보고, 출력층에 가까운 층들은 이미지 전체를 보게 된다.