---
title: "딥러닝개론"
escerpt: "LLM(Large Language Models) 논문 리뷰해보기"

categories:
  - DeepLearning
tags:
  - [AI, DeepLearning]

toc: true
toc_sticky: true

breadcrumbs: true

date: 2023-09-21
last_modified_at: 2023-09-21

comments: true


---

# 1. Overview

# 2. 인공지능,머신러닝,딥러닝
![image](https://github.com/OC-JSPark/oc-jspark.github.io/assets/46878973/b07ae984-82f1-4d1d-af53-b8f06266b204)
  - 머신러닝 : 학습!! 
  - 딥러닝 : 깊은 신경망 구조의 머신러닝
    - tree계열 : 의사결정(Decision tree)
    - SVM(Support Vector Machine) : 2가지 task를 나누는 직선을 찾는것. 어떤 직선을 만들때 가장 직선에서 수직거리가 가까운 포인트가 바로 Support Vector이다. 2가지 Support Vector 사이의 거리를 margin이라 한다. margin은 최대화하는 직선을 찾는 task이다. 가장 빠르게 작동하기때문에 간단한 모델에 적용하기 좋다.
    - 신경망 : hidden layer 수가 많은 깊은 신경망을 딥러닝이라 한다.
      - end-to-end 구조이다. 
      - 해석하기 힘들다 (node 간의 연결을 해석하기 힘들다.) 
      - ex) MLP(Multi-layer-perceptron), CNN, RNN, Transformer
        - CNN은 input이 이미지로 들어온다. 이게 filter를 통해 local 영역을 하나의 특성으로 이끌어내서 featrue extraction을 진행한다.
        - RNN은 어떤 노드가 다시 본인에게 회귀하는 경우.이떄는 timestamp가 중요하다.NLP쪽에서 많이 사용된다. 예를 들어 문장을 읽을때 이 정보가 앞에 등장하는지, 뒤에 등장하는지가 큰 의미를 가진다. 이런정보를 활용할떄 RNN사용한다. 
        - Transformer은 ViT라고 해서 vision쪽에서도 Tranformer를 활용한다. self-attention이라는 구조를 사용하는 딥러닝이다.

# 3. 학습(learning)의 개념과 원리
딥러닝에서 모델이 계속 바뀐다. 다만 예측력이 높은것으로 바뀐다. 이러면 개발자가 예측되지 않은 데이터가 오더라도 예측이 가능할 수 있다.

깊은신경망 : 가중치를 곱해서 새로운 feature를 만들어낸다. 즉 모든 feature의미가 모두 다르다.
출력은 결과이며 예측값이다. 은닉층의 수가 많으면 깊어진다. 즉 딥하다. 복잡한 특성을 추출하고 학습할 수 있다.

- 데이터셋 분할(split)
train set : test set 으로 나눠서 한다. 모델평가를 위해 test set을 사용한다. test set을 random 으로 분류할수도 있다.  그러나
만약 분류문제라고 한다면 class imbalanced 문제가 발생할수 있다. 그럴떄는 stratified sampling,층화추출 이라고 하여 클래스별로 test set을 일정한 비율만큼 추출하는 방법이다. 

  - 우리는 그래서 train : val : test으로 나눈다.
    왜? train에서 따로 val을 뽑아낸다. 학습은 train으로만 이루어지고, val은 같이 실시간으로 평가를 이루어 낸다. 학습이 이루어진다가 train성능이 떨어지는 구간이 있는데 이때가 overfitting이 일어난 떄이다. 즉 validation 성능은 학습하는 중에 일반화 성능을 측정하기 위해서이다.  hyperparameter(learning rate, 모델의 layer수, 등) 다양한것들을 바꿔가면서 실험해야 높은 validation이 나오는지를 알고 그 지표를 찾아야 한다.

  - 학습을 하는 목표? 더 나은 예측모델을 찾기 위해서! 
    모델은 신경망모델을 말한다. 
  - 일반화 성능(범용적인모델)을 높이는게 중요하다. 단순하게 train dataset에 대한 성능을 높이는게 아니라 전혀 별개의 새로운 dataset에서도 높은 성능을 낼수 있는 일반화 성능을 목표로 한다. 그것이 바로 더 나은 예측모델의 정의다!!
  


# 4. 지도학습(supervised learning), 비지도학습(unsupervised learning)
# 5. 선형회귀 1 (linear regression)
# 6. 선형회귀 2 (linear regression)
# 7. 신경망 1 (neural networks)
: 신경망은 수많은 선형회귀구조로 되어있다.
# 8. 신경망 2 (neural networks)
# 9. 가중치행렬(weight matrix)
# 10. 경사하강법(gradient descent)
# 11. Optimizer의 종류
# 12. 역전파 1 (backpropagation)
# 13. 역전파 2 (backpropagation) 
# 14. 소프트맥스(softmax)
:분류 문제를 풀기 위한 방법(회귀->분류로 변형필요)
# 15. 크로스엔트로피(cross-entropy)
:분류 문제를 풀기 위한 방법(회귀->분류로 변형필요)



CNN
# 1. Overview
# 2. 이미지필터(filters)
# 3. 합성곱 연산1 (convolution)
# 4. 합성곱 연산2 (convolution)
# 5. CNN 1 (convolutional neural networks)
# 6. CNN 2 (convolutional neural networks)
# 7. CNN 역전파
# 8. CV Task - 이미지분류(image classification)
# 9. CV Task - 객체검출(object detection)
# 10. CV Task - 객체추적(object tracking)
# 11. CV Task - 영역분할(segmentation)
# 12. 이미지 전처리(preprocessing)
# 13. 데이터 불균형(imbalance)
# 14. 오버피팅(overfitting)
# 15. 이미지증강(augmentation)



---


[맨 위로 이동하기](#){: .btn .btn--primary }{: .align-right}