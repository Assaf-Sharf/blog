---
layout: single
title:  "OpenCV chapter 2"
categories : OpenCV
tag : [python, OpenCV]
toc: true
toc_sticky: true
---

![header](https://capsule-render.vercel.app/api?type=waving&color=a2dcec&height=300&section=header&text=OpenCV chapter 2&fontSize=40&animation=fadeIn&fontAlignY=38&fontColor=FFFFFF)

- 참고 및 출처
  - [파이썬으로 만드는 OpenCV 프로젝트](https://github.com/dltpdn/insightbook.opencv_project_python)
  - [귀퉁이서재_opencv](https://bkshin.tistory.com/entry/OpenCV-1-%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9C%BC%EB%A1%9C-%EB%A7%8C%EB%93%9C%EB%8A%94-OpenCV-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8?category=1148027)



## 목차

- 스레시홀딩, 오츠의 알고리즘

- 이미지 연산 (합성, 알파 블렌딩, 마스킹)

&nbsp;

&nbsp;





## 5. 스레시홀딩, 오츠의 알고리즘

&nbsp;

### 스레시홀딩(Thresholding)

- 바이너리 이미지를 만드는 가장 대표적인 방법
  - 바이너리 이미지 : 검은색과 흰색만으로 표현한 이미지를 의미
- 스레시홀딩이란 여러 값을 어떤 임계점을 기준으로 두 가지 부류로 나누는 방법을 의미

&nbsp;

### 전역 스레시홀딩

- 어떤 임계값을 정한 뒤 픽셀 값이 임계값을 넘으면 255, 임계값을 넘지 않으면 0으로 지정하는 방식
- OpenCV에서 cv2.threshold() 함수로 구현가능
- 전역 스레시홀딩 작업을 numpy 연산과 cv2.threshold() 함수를 통해 수행하는 과정


```python
img = cv2.imread('gray_gradient.jpg', cv2.IMREAD_GRAYSCALE) #이미지를 그레이 스케일로 읽기

# NumPy API로 바이너리 이미지 만들기
thresh_np = np.zeros_like(img)   # 원본과 동일한 크기의 0으로 채워진 이미지
thresh_np[ img > 127] = 255      # 127 보다 큰 값만 255로 변경

# OpenCV API로 바이너리 이미지 만들기
ret, thresh_cv = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY) 
print(ret)  # 127.0, 바이너리 이미지에 사용된 문턱 값 반환

# 원본과 결과물을 matplotlib으로 출력
imgs = {'Original': img, 'NumPy API':thresh_np, 'cv2.threshold': thresh_cv}
for i , (key, value) in enumerate(imgs.items()):
    plt.subplot(1, 3, i+1)
    plt.title(key)
    plt.imshow(value, cmap='gray')
    plt.xticks([]); plt.yticks([])

plt.show()
```


![png](/images/2022-07-13-opencv2/output_96_1.png)
    


- 검은색에서 흰색으로 점점 변하는 그라데이션 이미지를 회색조로 읽음
- numpy 연산을 통해 픽셀 값이 127보다 크면 255, 픽셀 값이 127보다 작거나 같으면 0
- 위 작업을 cv2.threshold(img, 127, 255, cv2.THRESH_BINARY) 함수를 호출하여 수행가능



- ret, out = cv2.threshold(img, threshold, value, type_flag)

  - img: 변환할 이미지
  - threshold: 스레시홀딩 임계값
  - value: 임계값 기준에 만족하는 픽셀에 적용할 값
  - type_flag: 스레시홀딩 적용 방법

  

  - type_flag 값
    - cv2.THRESH_BINARY: 픽셀 값이 임계값을 넘으면 value로 지정하고, 넘지 못하면 0으로 지정
    - cv2.THRESH_BINARY_INV: cv.THRESH_BINARY의 반대
    - cv2.THRESH_TRUNC: 픽셀 값이 임계값을 넘으면 value로 지정하고, 넘지 못하면 원래 값 유지
    - cv2.THRESH_TOZERO: 픽셀 값이 임계값을 넘으면 원래 값 유지, 넘지 못하면 0으로 지정
    - cv2.THRESH_TOZERO_INV: cv2.THRESH_TOZERO의 반대

  - ret은 스레시홀딩에 사용한 임계값,  out은 스레시홀딩이 적용된 바이너리 이미지
  
  - 첫번째 결과인 ret은 threshold 파라미터로 전달한 값과 동일
  
    


```python
img = cv2.imread('gray_gradient.jpg', cv2.IMREAD_GRAYSCALE) #그레이 스케일로 이미지 읽기

_, t_bin = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY) # 임계값 = 127 이상시, 255 적용
_, t_bininv = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV) # 임계값 = 127 이상시, 255 적용 반대로
_, t_truc = cv2.threshold(img, 127, 255, cv2.THRESH_TRUNC) # 임계값 = 127 이상시, 255 적용
_, t_2zr = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO) # 임계값 = 127 이상시, 255 적용
_, t_2zrinv = cv2.threshold(img, 127, 255, cv2.THRESH_TOZERO_INV)

imgs = {'origin':img, 'BINARY':t_bin, 'BINARY_INV':t_bininv, \
        'TRUNC':t_truc, 'TOZERO':t_2zr, 'TOZERO_INV':t_2zrinv}

for i, (key, value) in enumerate(imgs.items()):
    plt.subplot(2,3, i+1)
    plt.title(key)
    plt.imshow(value, cmap='gray')
    plt.xticks([]);    plt.yticks([])
    
plt.show()
```

![png](/images/2022-07-13-opencv2/output_98_0.png)
    


&nbsp;

### 오츠의 이진화 알고리즘

- 바이너리 이미지를 만들 때 가장 중요한 점은 임계값을 얼마로 정하냐 하는 것
- 오츠의 알고리즘은 임계값을 임의로 정해 픽셀을 두 부류로 나누고 두 부류의 명암 분포를 구하는 작업을 반복, 모든 경우의 수 중에서 두 부류의 명암 분포가 가장 균일할 때의 임계값을 선택
- 밑은 오츠의 알고리즘 예시

![image-20220713180801183](/images/2022-07-13-opencv2/image-20220713180801183.png)

- OpenCV에서 오츠의 알고리즘 적용은 cv2.threshold() 함수의 마지막 파라미터로 cv2.THRESH_OTSU 사용
- 오츠의 알고리즘은 최적의 임계값을 찾아주므로 cv2.threshold() 함수에 전달하는 threshold 파라미터는 아무 값이어도 상관없음, 무시됨


```python
# 이미지를 그레이 스케일로 읽기
img = cv2.imread('scaned_paper.jpg', cv2.IMREAD_GRAYSCALE) 
# 경계 값을 130으로 지정
_, t_130 = cv2.threshold(img, 130, 255, cv2.THRESH_BINARY)        
# 경계 값을 지정하지 않고 OTSU 알고리즘 선택
t, t_otsu = cv2.threshold(img, -1, 255,  cv2.THRESH_BINARY | cv2.THRESH_OTSU) 
print('otsu threshold:', t)                 # Otsu 알고리즘으로 선택된 경계 값 출력

imgs = {'Original': img, 't:130':t_130, 'otsu:%d'%t: t_otsu}
for i , (key, value) in enumerate(imgs.items()):
    plt.subplot(1, 3, i+1)
    plt.title(key)
    plt.imshow(value, cmap='gray')
    plt.xticks([]); plt.yticks([])

plt.show()

>> otsu threshold: 131.0
```


![png](/images/2022-07-13-opencv2/output_104_1.png)
    


- 원본 이미지의 글씨는 선명하지 않지만 바이너리 이미지로 변환하니 글씨가 좀 더 선명해짐
- 맨 왼쪽은 원본 이미지, 두 번째 이미지는 임계값을 130으로 지정해준 바이너리 이미지, 세 번째 이미지는 오츠의 알고리즘을 적용한 바이너리 이미지(오츠의 알고리즘에 따르면 최적의 임계값은 131)
- 오츠의 알고리즘 내용을 확인하면


```python
t, t_otsu = cv2.threshold(img, -1, 255,  cv2.THRESH_BINARY | cv2.THRESH_OTSU) 
```

​	- 두 번째 파라미터인 -1은  threshold를 전달하는 값, 오츠의 알고리즘에서는 무시됨

​	- 오츠의 알고리즘이 최적의 임계값을 자동으로 찾아준다는 장점이 있지만, 모든 경우의 수에 대해 조사해야 하므로 속도가 빠르지 않다는 단점 존재

&nbsp;

### 적응형 스레시홀딩(Adaptive Thresholding)

- 전역 스레시홀딩이 매번 좋은 성능을 내는 것은 아님
      - 원본 이미지에서 조명이 일정하지 않거나 배경색이 여러 개인 경우에는 하나의 임계값으로 선명한 바이너리 이미지를 만들어내기 힘들 수도 있음
- 이때는 이미지를 여러 영역으로 나눈 뒤, 그 주변 픽셀 값만 활용하여 임계값을 계산, 이를 적응형 스레시 홀딩이라고 함



```python
cv2.adaptiveThreshold(img, value, method, type_flag, block_size, C)

   img: 입력영상
   value: 임계값을 만족하는 픽셀에 적용할 값
   method: 임계값 결정 방법
   type_flag: 스레시홀딩 적용 방법 (cv2.threshod()와 동일)
   block_size: 영역으로 나눌 이웃의 크기(n x n), 홀수
   C: 계산된 임계값 결과에서 가감할 상수(음수 가능)
```



- method

  - cv2.ADAPTIVE_THRESH_MEAN_C: 이웃 픽셀의 평균으로 결정
  - cv2.ADAPTIVE_THRESH_GAUSSIAN_C: 가우시안 분포에 따른 가중치의 합으로 결정


```python
blk_size = 9        # 블럭 사이즈
C = 5               # 차감 상수 
img = cv2.imread('./sudoku.png', cv2.IMREAD_GRAYSCALE) # 그레이 스케일로  읽기

# 오츠의 알고리즘으로 단일 경계 값을 전체 이미지에 적용
ret, th1 = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)

# 어뎁티드 쓰레시홀드를 평균과 가우시안 분포로 각각 적용
th2 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\
                                      cv2.THRESH_BINARY, blk_size, C)
th3 = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \
                                     cv2.THRESH_BINARY, blk_size, C)

# 결과를 Matplot으로 출력
imgs = {'Original': img, 'Global-Otsu:%d'%ret:th1, \
        'Adapted-Mean':th2, 'Adapted-Gaussian': th3}
for i, (k, v) in enumerate(imgs.items()):
    plt.subplot(2,2,i+1)
    plt.title(k)
    plt.imshow(v,'gray')
    plt.xticks([]),plt.yticks([])

plt.show()
```


![png](/images/2022-07-13-opencv2/output_109_0.png)
    


- 오츠의 알고리즘을 사용한 바이너리 이미지를 확인했을때
  - 왼쪽 아래는 검정색으로, 오른쪽 위는 흰색으로 변해 이미지를 식별하기가 어려움
  - 원본 이미지 좌측 하단이 우측 상단보다 더 그늘지고 어두워 발생하는 현상, 전역 스레시홀딩을 하면 발생하는 문제

- 적응형 스레시 홀딩
  - Adapted-Mean
    - Adapted-Gaussian 적용한것보다 선명하지만 잡음이 조금 있음
  - Adapted-Gaussian
    - Adapted-Mean보다 선명하지 않지만 잡음은 적음

- 적응형 스레시홀딩 알고리즘
  - 전체 이미지에 총 9개의 블록을 설정
  - 블록별로 임계값 설정(cv2.ADAPTIVE_THRESH_MEAN_C를 파라미터로 전달하면 각 블록의 이웃 픽셀의 평균으로 임계값 설정, cv2.ADAPTIVE_THRESH_GAUSSIAN_C를 파라미터로 전달하면 가우시안 분포에 따른 가중치의 합으로 임계값 설정)
  - 정해진 임계값을 바탕으로 각 블록별로 스레시홀딩 수행
  - 전역 스레시홀딩을 적용한 것보다 더 선명하고 부드러운 결과를 얻음
- 대부분 이미지에 조명차이가 있어서 전역 스레시홀딩보다 적응형 스레시 홀딩을 사용함

&nbsp;

## 6. 이미지 연산 (합성, 알파 블렌딩, 마스킹)

- 이미지 연산을 위한 방법은 numpy를 활용하는 방법이 있지만 opencv에서 연산함수를 제공하는 이유는 값의 범위때문, 0~255 인데 연산결과가 255보다 크거나 0보다 작을수 있어서 이를 제한할 필요가 있음

- opencv 제공되는 연산함수

  ```python
  cv2.add(src1,src2,dest,mask,dtype) : src1과 src2 더하기
      
      src1: 첫 번째 입력 이미지
      src2: 두 번째 입력 이미지
      dest(optional): 출력 영상
      mask(optional): mask 값이 0이 아닌 픽셀만 연산
      dtype(optional): 출력 데이터 타입(dtype)
          
  cv2.subtract(src1,src2,dest,mask,dtype) : src1과 src2 빼기
      - parameter cv2.add와 동일
      
  cv2.multiply(src1, src2, dest, scale, dtype) :  src1과 src2 곱하기
      - scale(optional) : 연산 결과에 추가 연산할 값
          
  cv2.multiply(src1, src2, dest, scale, dtype) :  src1을 src2로 나누기
      - cv2.multiply와 동일
  ```
  

&nbsp;


```python
# 연산에 사용할 배열 생성
a = np.uint8([[200, 50]]) 
b = np.uint8([[100, 100]])

# 배열 직접 연산
add1 = a + b
sub1 = a - b
mult1 = a * 2
div1 = a / 3

# OpenCV API를 이용한 연산
add2 = cv2.add(a, b)
sub2 = cv2.subtract(a, b)
mult2 = cv2.multiply(a , 2)
div2 = cv2.divide(a, 3)

# 각 연산 결과 출력
print(add1, add2)
print(sub1, sub2)
print(mult1, mult2)
print(div1, div2)


>> [[ 44 150]] [[255 150]]
    [[100 206]] [[100   0]]
    [[144 100]] [[255 100]]
    [[66.66666667 16.66666667]] [[67 17]]
```




- numpy 연산 결과와 OpenCV 연산 함수를 활용한 연산 결과가 서로 다름
- 덧셈에서 200 + 100 = 300으로 255를 초과, unit8 타입의 범위는 0~255 이므로 255를 넘는 값은 다시 0부터 카운팅 수행
  - numpy에서는 300 - 255 - 1 = 44
  - opencv에서는 255초과값은 255
- 위와 같은 이유로 뻴셈에서는 opencv는 0이하는 0, 곱하기, 나누기에서도 255초과하거나 0보다 작은 값을 갖지 않고 소수점은 갖지않음


- cv2.add()에 세 번째 파라미터를 전달하면 첫 번째 두 번째 파라미터 합을 세 번째 파라미터에 할당

```python
c = cv2.add(a,b)
c = cv2.add(a,b,None)
cv2.add(a,b,c)
```

- 위 3개의 코드는 같은 결과수행

&nbsp;

#### 4번째 parameter인 mask 사용시


```python
# 연산에 사용할 배열 생성
a = np.array([[1, 2]], dtype=np.uint8)
b = np.array([[10, 20]], dtype=np.uint8)
# 2번째 요소가 0인 마스크 배열 생성 
mask = np.array([[1, 0]], dtype=np.uint8)

# 누적 할당과의 비교 연산
c1 = cv2.add(a, b, None, mask)
print(c1)
c2 = cv2.add(a, b, b.copy(), mask)
print(c2, b)
c3 = cv2.add(a, b, b, mask)
print(c3, b)

>> [[11  0]]
    [[11 20]] [[10 20]]
    [[11 20]] [[11 20]]
```




- cv2.add(a, b, None, mask) 연산에서 a + b = [[11,22]]가 나와야하지만 mask옵션에서 0이 아닌 위치만 계산하기 때문에 [[11,0]]
- cv2.add(a, b, b.copy(), mask)는 a+b의 첫번째 요소만 더하고 b.copy()에 반영할때 첫번째 자리만 반영 [[11 , 20]]
- cv2.add(a, b, b, mask) 위와 같은 연산으로 이루어지고 기존의 b도 변경

&nbsp;

### 이미지 합성

- 두 이미지를 합성할 때 위에서 살펴본 numpy의 합이나 cv2.add() 함수만으로는 좋은 결과를 얻을 수 없음
  - numpy는 255초과 값만큼 반영 150+180 = 330 -> 74
  - cv2.add() 연산을 하면 대부분의 픽셀 값이 255으로 몰려서 흰색됨


```python
# 연산에 사용할 이미지 읽기
img1 = cv2.imread('./wing_wall.jpg')
img2 = cv2.imread('./yate.jpg')

# 이미지 덧셈
img3 = img1 + img2  # 더하기 연산
img4 = cv2.add(img1, img2) # OpenCV 함수

imgs = {'img1':img1, 'img2':img2, 'img1+img2': img3, 'cv.add(img1, img2)': img4}

# 이미지 출력
for i, (k, v) in enumerate(imgs.items()):
    plt.subplot(2,2, i + 1)
    plt.imshow(v[:,:,::-1]) # BGR -> RGB
    plt.title(k)
    plt.xticks([]); plt.yticks([])

plt.show()
```


​    ![png](/images/2022-07-13-opencv2/output_123_0.png)
​    


- numpy로 img1+img2를 한 경우 255를 넘는 픽셀은 이상한 색상을 보임
- cv2.add(img1, img2)를 수행한 경우 대부분의 값이 255에 몰려 전체적으로 하얀 픽셀


- 두 이미지를 제대로 합성하려면 각각의 이미지에 가중치를 주고 합해야함, 가중치를 알파(alpha) 값
- 새로운 이미지 알파(alpha)를 활용하여 합성 결과 픽셀 값 g(x)를 구하는 공식은 밑과 같음

![image-20220713180840346](/images/2022-07-13-opencv2/image-20220713180840346.png)

```python
cv2.addWeight(img1, alpha, img2, beta, gamma)

    img1, img2: 합성할 두 이미지
    alpha: img1에 지정할 가중치(알파 값)
    beta: img2에 지정할 가중치, 흔히 (1-alpha) 적용
    gamma: 연산 결과에 가감할 상수, 흔히 0 적용
```

&nbsp;

### 알파 블렌딩


```python
alpha = 0.5 # 합성에 사용할 알파 값

# 합성에 사용할 영상 읽기
img1 = cv2.imread('./wing_wall.jpg')
img2 = cv2.imread('./yate.jpg')

# NumPy 배열에 수식을 직접 연산해서 알파 블렌딩 적용
blended = img1 * alpha + img2 * (1-alpha)
blended = blended.astype(np.uint8) # 소수점 발생을 제거하기 위함

# addWeighted() 함수로 알파 블렌딩 적용
dst = cv2.addWeighted(img1, alpha, img2, (1-alpha), 0) 


imgs = {'img1 * alpha + img2 * (1-alpha)':blended, 'cv2.addWeighted':dst}

for i, (k, v) in enumerate(imgs.items()):
    plt.subplot(1,2, i + 1)
    plt.imshow(v[:,:,::-1]) # BGR -> RGB
    plt.title(k)
    plt.xticks([]); plt.yticks([])

plt.show()
```


​    ![png](/images/2022-07-13-opencv2/output_126_0.png)
​    


- 알파 값이 0.5라는 것은 두 이미지에 동일한 가중치를 주고 합성한다는 뜻
- 왼쪽은 알파를 활용한 이미지 합성을 numpy로 직접 구현한 결과고 오른쪽은 cv2.addWeight() 함수를 활용한 결과, 둘다 같음

&nbsp;

### 트랙바로 알파 블렌딩


```python
win_name = 'Alpha blending'     # 창 이름
trackbar_name = 'fade'          # 트렉바 이름

# 트렉바 이벤트 핸들러 함수
def onChange(x):
    alpha = x/100
    dst = cv2.addWeighted(img1, 1-alpha, img2, alpha, 0) 
    cv2.imshow(win_name, dst)


# 합성 영상 읽기
img1 = cv2.imread('./man_face.jpg')
img2 = cv2.imread('./lion_face.jpg')

# 이미지 표시 및 트렉바 붙이기
cv2.imshow(win_name, img1)
cv2.createTrackbar(trackbar_name, win_name, 0, 100, onChange)


cv2.waitKey()
cv2.destroyAllWindows()
```

![image-20220713180918737](/images/2022-07-13-opencv2/image-20220713180918737.png)



&nbsp;

### 비트와이즈 연산

- 비트와이즈 연산은 두 이미지를 합성할 때 특정 영역만 선택하거나 특정 영역만 제외하는 등의 선별적인 연산에 도움을 줌
- 비트와이즈 설명 밑 그림 참조

![image-20220713180934559](/images/2022-07-13-opencv2/image-20220713180934559.png)


- OpenCV에서 제공하는 비트와이즈 연산 함수
  - cv2.bitwise_and(img1, img2, mask=None): 각 픽셀에 대해 AND 연산
  - cv2.bitwise_or(img1, img2, mask=None): 각 픽셀에 대해 OR 연산
  - cv2.bitwise_xor(img1, img2, mask=None): 각 픽셀에 대해 XOR 연산
  - cv2.bitwise_not(img1, img2, mask=None): 각 픽셀에 대해 NOT 연산

  - img1, img2는 연산을 수행할 이미지, 두 이미지는 동일한 shape
  - mask는 0이 아닌 픽셀만 연산


```python
# 연산에 사용할 이미지 생성
img1 = np.zeros( ( 200,400), dtype=np.uint8)
img2 = np.zeros( ( 200,400), dtype=np.uint8)
img1[:, :200] = 255         # 왼쪽은 흰색(255), 오른쪽은 검정색(0)
img2[100:200, :] = 255      # 위쪽은 검정색(0), 아래쪽은 흰색(255)

# 비트와이즈 연산
bitAnd = cv2.bitwise_and(img1, img2)
bitOr = cv2.bitwise_or(img1, img2)
bitXor = cv2.bitwise_xor(img1, img2)
bitNot = cv2.bitwise_not(img1)

# Plot으로 결과 출력
imgs = {'img1':img1, 'img2':img2, 'and':bitAnd, 
          'or':bitOr, 'xor':bitXor, 'not(img1)':bitNot}

for i, (title, img) in enumerate(imgs.items()):
    plt.subplot(3,2,i+1)
    plt.tight_layout(h_pad=2, w_pad=2)
    plt.title(title)
    plt.imshow(img, 'gray')
    plt.xticks([]); plt.yticks([])

plt.show()
```


​    ![png](/images/2022-07-13-opencv2/output_133_0.png)
​    


- and는 둘다 1일때만 True 그래서 같이 흰색부분만 흰색으로 표시 나머지 검은색
- or은 흰색이 1번이라도 있으면 흰색
- xor 은 서로 반대될때만 1
- not은 반대

&nbsp;

### bitwise_and 연산으로 마스킹하기


```python
# 이미지 읽기
img = cv2.imread('./test_image.jpg')

# 마스크 만들기
mask = np.zeros_like(img)
cv2.circle(mask, (195,110), 90, (255,255,255), -1)  # cv2.circle(대상이미지, (원점x, 원점y), 반지름, (색상), 채우기)

# 마스킹
masked = cv2.bitwise_and(img, mask)

# 결과 출력
cv2.imshow('original', img)
cv2.imshow('mask', mask)
cv2.imshow('masked', masked)
cv2.waitKey()
cv2.destroyAllWindows()
```

![image-20220713181009362](/images/2022-07-13-opencv2/image-20220713181009362.png)

- 원본 이미지에서 검은색은 거의없음
- 두 번째 이미지인 흰색 원에서는 흰색 원 부분만 255의 값을 가지고 나머지는 0
- 원본 이미지와 원 이미지를 AND 연산하면 세 번째 이미지 계산

&nbsp;

### 두 이미지의 차이

- 두 이미지의 픽셀 값을 빼면 음수가 나올수 있으므로 절댓값 취해줘야함

  ```python
  diff = cv2.absdiff(img1, img2)
  ```

   - img1, img2: 입력 이미지
   - diff: 두 이미지의 차의 절대 값

&nbsp;

### 두 이미지의 차를 통해 도면의 차이 찾아내기


```python
# 연산에 필요한 영상을 읽고 그레이스케일로 변환
img1 = cv2.imread('./robot_arm1.jpg')
img2 = cv2.imread('./robot_arm2.jpg')
img1_gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

# 두 영상의 절대값 차 연산
diff = cv2.absdiff(img1_gray, img2_gray)

# 차 영상을 극대화 하기 위해 쓰레시홀드 처리 및 컬러로 변환
_, diff = cv2.threshold(diff, 1, 255, cv2.THRESH_BINARY)
diff_red = cv2.cvtColor(diff, cv2.COLOR_GRAY2BGR)
diff_red[:,:,0] = 0

# 두 번째 이미지에 변화 부분 표시
spot = cv2.bitwise_xor(img2, diff_red)

# 결과 영상 출력

imgs = {'img1':img1, 'img2':img2, 'diff':diff, 'spot':spot}
plt.figure(figsize=(20, 10))
for i, (title, img) in enumerate(imgs.items()):
    plt.subplot(2,2,i+1)
    plt.tight_layout(h_pad=2, w_pad=2)
    plt.title(title)
    plt.imshow(img, 'gray')
    plt.xticks([]); plt.yticks([])
    
plt.show()
```


​    ![png](/images/2022-07-13-opencv2/output_142_0.png)
​    


- 두 이미지를 읽어온 뒤 그레이 스케일 적용 후 두 이미지 차 계산
- 차이를 뚜렷하게 하기 위해 cv2.threshold() 함수를 활용하여 픽셀 값이 1보다 큰 값은 255로 바꾸고 그렇지 않은 픽셀 값은 0으로 변경 (diff에서 255된 곳이 흰색)
- 색상을 표현하기 위해 cv2.cvtColor() 함수를 활용하여 색상 스케일을 맞추기 위해 차원을 변경, 색상 빨간색으로 변경
- 마지막으로 cv2.bitwise_xor() 연산수행 (img2 와 diff_red 비트와이즈 연산수행하면 서로 다른부분만)

&nbsp;

### 이미지 합성과 마스킹

- 이미지는 배경과 전경으로 나눔
- 배경이 투명한 이미지를 활용하여 BGRA 색상 형식으로 표현할 때, 배경은 A(알파, alpha)가 0이고, 전경은 A가 255
- 이를 활용해서 배경을 분리할수있음

&nbsp;

### 투명 배경 PNG 파일을 이용한 합성


```python
# 합성에 사용할 영상 읽기, 전경 영상은 4채널 png 파일
img_fg = cv2.imread('./opencv_logo (1).png', cv2.IMREAD_UNCHANGED)
img_bg = cv2.imread('./girl.jpg')

# 알파채널을 이용해서 마스크와 역마스크 생성
_, mask = cv2.threshold(img_fg[:,:,3], 1, 255, cv2.THRESH_BINARY)
mask_inv = cv2.bitwise_not(mask)

# 전경 영상 크기로 배경 영상에서 ROI 잘라내기
img_fg = cv2.cvtColor(img_fg, cv2.COLOR_BGRA2BGR)
h, w = img_fg.shape[:2]
roi = img_bg[10:10+h, 10:10+w ]

# 마스크 이용해서 오려내기
masked_fg = cv2.bitwise_and(img_fg, img_fg, mask=mask)
masked_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)

# 이미지 합성
added = masked_fg + masked_bg
img_bg[10:10+h, 10:10+w] = added

imgs = {'mask':mask, 'mask_inv':mask_inv, 'img_fg':img_fg, 'roi': roi, 'masked_fg':masked_fg, 'masked_bg':masked_bg, 'added':added, 'result':img_bg}
plt.figure(figsize=(20, 10))
for i, (title, img) in enumerate(imgs.items()):
    plt.subplot(4,2,i+1)
    plt.tight_layout(h_pad=0, w_pad=0)
    plt.title(title)
    if i == 7:
        plt.imshow(img[:,:,::-1], 'gray')
    else:
        plt.imshow(img, 'gray')
    plt.xticks([]); plt.yticks([])
    
plt.show()
```


​    ![png](/images/2022-07-13-opencv2/output_147_0.png)
​    


- _, mask = cv2.threshod(img_fg[:, :, 3], 1, 255, cv2.THRESH_BINARY) 를 통해서 픽셀 값이 1보다 큰 값은 255로 바꾸고 그렇지 않은 픽셀 값은 0 이렇게 해서 배경과 전경을 분리하는 mask 생성, 배경 부분은 BRGA의 A값이 0 전경 부분은 A != 0
- mask_inv = cv2.bitwise_not(mask) 는 mask와 반대, 배경 A!=0 , 전경 A=0
- bitwise_and 계산을 통해 img_fg 와 img_fg 같은 부분만 이때 마스크는 글자와 로고 부분만 흰색임으로 해당 위치만 계산
- bitwise_and 계산을 통해 roi 와 roi 같은 부분만, mask_inv는 배경만 흰색 그래서 배경만 계산하고 글자 로고는 계산 안함
- 위의 masked_fg + masked_bg 합쳐서 added 얻음 , 이후 girl 이미지의 해당영역에 합성



&nbsp;

### HSV 색상으로 마스킹


```python
# 큐브 영상 읽어서 HSV로 변환
img = cv2.imread("./cube.jpg")
hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)

# 색상별 영역 지정
blue1 = np.array([90, 50, 50])
blue2 = np.array([120, 255,255])
green1 = np.array([45, 50,50])
green2 = np.array([75, 255,255])
red1 = np.array([0, 50,50])
red2 = np.array([15, 255,255])
red3 = np.array([165, 50,50])
red4 = np.array([180, 255,255])
yellow1 = np.array([20, 50,50])
yellow2 = np.array([35, 255,255])

# 색상에 따른 마스크 생성
mask_blue = cv2.inRange(hsv, blue1, blue2)
mask_green = cv2.inRange(hsv, green1, green2)
mask_red = cv2.inRange(hsv, red1, red2)
mask_red2 = cv2.inRange(hsv, red3, red4)
mask_yellow = cv2.inRange(hsv, yellow1, yellow2)

# 색상별 마스크로 색상만 추출
res_blue = cv2.bitwise_and(img, img, mask=mask_blue)
res_green = cv2.bitwise_and(img, img, mask=mask_green)
res_red1 = cv2.bitwise_and(img, img, mask=mask_red)
res_red2 = cv2.bitwise_and(img, img, mask=mask_red2)
res_red = cv2.bitwise_or(res_red1, res_red2)
res_yellow = cv2.bitwise_and(img, img, mask=mask_yellow)

# 결과 출력
imgs = {'original': img, 'blue':res_blue, 'green':res_green, 'red':res_red, 'red1': res_red1, 'red2': res_red2 ,'yellow':res_yellow}
plt.figure(figsize=(20, 10))

for i, (k, v) in enumerate(imgs.items()):
    plt.subplot(2,4, i+1)
    plt.title(k)
    plt.imshow(v[:,:,::-1])
    plt.xticks([]); plt.yticks([])
plt.show()
```


![png](/images/2022-07-13-opencv2/output_150_0.png)
    


- cv2.inRange(hsv, lower, upper)는 hsv의 모든 값 중 lower와 upper 범위 사이에 있는 값은 255 나머지 값은 0
  - red1 = np.array([0, 50,50]), red2 = np.array([15, 255,255]) 이걸 cv2.inRange(hsv, red1, red2) 로 한다면 hsv 값이 0 ~ 15, 50 ~ 255 , 50 ~ 255 사이만 값을 255로 나머지는 0

&nbsp;

### 크로마키 마스킹과 합성


```python
# 크로마키 배경 영상과 합성할 배경 영상 읽기
img1 = cv2.imread('./man_chromakey.jpg')
img2 = cv2.imread('./street.jpg')

# ROI 선택을 위한 좌표 계산
height1, width1 = img1.shape[:2]
height2, width2 = img2.shape[:2]
x = (width2 - width1)//2
y = height2 - height1
w = x + width1
h = y + height1
print(f'roi 좌표 x={x},y={y},w={w},h={h}')

# 크로마키 배경 영상에서 크로마키 영역을 10픽셀 정도로 지정
chromakey = img1[:10, :10, :]
offset = 20

# 크로마키 영역과 영상 전체를 HSV로 변경
hsv_chroma = cv2.cvtColor(chromakey, cv2.COLOR_BGR2HSV)
hsv_img = cv2.cvtColor(img1, cv2.COLOR_BGR2HSV)

# 크로마키 영역의 H값에서 offset 만큼 여유를 두어서 범위 지정
# offset 값은 여러차례 시도 후 결정
# chroma_h = hsv_chroma[0]
chroma_h = hsv_chroma[:,:,0]
lower = np.array([chroma_h.min()-offset, 100, 100])
upper = np.array([chroma_h.max()+offset, 255, 255])

# 마스크 생성 및 마스킹 후 합성
mask = cv2.inRange(hsv_img, lower, upper)
mask_inv = cv2.bitwise_not(mask)
roi = img2[y:h, x:w]
fg = cv2.bitwise_and(img1, img1, mask=mask_inv)
bg = cv2.bitwise_and(roi, roi, mask=mask)
img2[y:h, x:w] = fg + bg

# 결과 출력
imgs = {'fg':fg, 'bg':bg, 'chromakey':img1, 'added':img2}
plt.figure(figsize=(20, 10))


for i, (k, v) in enumerate(imgs.items()):
    plt.subplot(2,2, i + 1)
    plt.imshow(v[:,:,::-1]) # BGR -> RGB
    plt.title(k)
    plt.xticks([]); plt.yticks([])

plt.show()

>> roi 좌표 x=163,y=26,w=477,h=426
```


![png](/images/2022-07-13-opencv2/output_153_1.png)
    


- ROI 위치를 x,y,w,h에 할당
- chromakey 영역 지정
- chromakey와 img1을 hsv로 변환
- 크로마키 영역을 h값에서 offset(사전 지정)한만큼 범위 여유를 둠
- inRange를 통해서 img안에 해당하는 색부분만 255
- not 연산을 통해서 반대만 출력 (mask가 배경을 가리킴 not 연산통해 사람부분만) 
- and연산으로 fg,bg각각 얻고 해당 좌표에 합성

- 이미지 합성에는 블렌딩과 마스킹이 필요
- 블렌딩을 위한 알파 값 선택과 마스킹을 위한 좌표, 색상 선택에는 많은 시간이 소요
- cv2.seamlessClone()을 통해 두 이미지의 특징을 살려 알아서 합성하는 기능 수행

```python
dst = cv2.seamlessClone(src, dst, mask, coords, flags, output)

	src: 입력 이미지, 일반적으로 전경
    dst: 대상 이미지, 일반적으로 배경
    mask: 마스크, src에서 합성하고자 하는 영역은 255, 나머지는 0
    coords: src가 놓이기 원하는 dst의 좌표 (중앙)
    flags: 합성 방식
    output(optional): 합성 결과
```

&nbsp;

### SeamlessClone을 활용한 이미지 합성


```python
# 합성 대상 영상 읽기
img1 = cv2.imread("./drawing.jpg")
img2 = cv2.imread("./my_hand.jpg")

# 마스크 생성, 합성할 이미지 전체 영역을 255로 셋팅
mask = np.full_like(img1, 255)
 
# 합성 대상 좌표 계산(img2의 중앙)
height, width = img2.shape[:2]
center = (width//2, height//2)
 
# seamlessClone 으로 합성 
normal = cv2.seamlessClone(img1, img2, mask, center, cv2.NORMAL_CLONE)
mixed = cv2.seamlessClone(img1, img2, mask, center, cv2.MIXED_CLONE)

# 결과 출력
imgs = {'normal':normal, 'mixed':mixed}
plt.figure(figsize=(20, 10))


for i, (k, v) in enumerate(imgs.items()):
    plt.subplot(1,2, i + 1)
    plt.imshow(v[:,:,::-1]) # BGR -> RGB
    plt.title(k)
    plt.xticks([]); plt.yticks([])

plt.show()
```


​    ![png](/images/2022-07-13-opencv2/output_157_0.png)
​    


- 알파 값이나 마스크를 신경 쓰지 않아도 됨
- mask는 img1의 전체 영역을 255로 채워서 해당 영역 전부가 합성의 대상임을 표현
- 합성하려는 영역을 제외하고는 0으로 채우는 것이 더 좋음
- cv2.NORMAL_CLONE일 때는 꽃은 선명하지만 주변의 피부가 흐려짐
- cv2.MIXED_CLONE일 때는 꽃은 다소 흐리지만 주변 피부가 선명함

