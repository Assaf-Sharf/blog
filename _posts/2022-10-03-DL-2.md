---
layout: single
title:  "DL-2 NN & MLP"
categories : DL
tag : 
toc : true
---

## Neural Networks

하늘을 날고자 해서 새처럼 날 필요는 없듯이
AI를 위해서 인간의 뇌를 완벽히 모방할 필요는 없다.


NN : function approximators that stack affine transformations followed by nonlinear transformations

먼저 linear regression에서
![image2](/images/2022-10-03-DL-2/image2.png)


Loss function을 줄이는 방향으로 backpropagation

![image-20221003200024336](/images/2022-10-03-DL-2/image-20221003200024336.png)

## Multi-Layer Perceptron

![image-20221003200814467](/images/2022-10-03-DL-2/image-20221003200814467.png)

이런 식으로 다층을 쌓아서 만들면 nonlinearity를 가지게 되고, 다양한 표현이 가능하다.
그 사이사이에 activation function으로 마무리 해줘서 층을 구별함.
ex) relu, tanh, sigmoid


### Loss function

![image-20221003201457417](/images/2022-10-03-DL-2/image-20221003201457417.png)


## 실습 코-드



train에서 update 하기
```python
optm.zero_grad() # reset gradient
loss_out.backward() # backpropagate
optm.step() # optimizer update
```