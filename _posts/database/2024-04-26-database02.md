---
layout: single
title: "MongoDB와 임베딩 그리고 Python"
categories: [Database, ML-AI, Python] 
tags: [MongoDB, NoSQL, Embedding, Word2Vec, Python]
toc: true
author_profile: false
sidebar:
  nav: "counts"
---

## MongoDB 개요

MongoDB는 가장 대중적인 문서 지향 NoSQL 데이터베이스입니다. 관계형 데이터베이스와 달리 MongoDB는 데이터를 JSON과 유사한 BSON 문서로 저장합니다. 이 BSON 문서에는 다양한 데이터 구조를 임베딩할 수 있습니다.

| RDBMS | MongoDB |
|-------|----------|
| 테이블 기반 | 문서 기반 |
| 정해진 스키마 | 스키마 없는 구조 |
| SQL | 다양한 API 지원|
| 수직적 확장 | 수평적 확장 |

MongoDB의 주요 장점

- 유연한 데이터 모델링
- 고성능
- 수평적 확장성
- 풍부한 쿼리 기능

## 임베딩(Embedding) 개요

임베딩은 기계 학습 분야에서 원본 데이터를 저차원 밀집 벡터 공간에 매핑하는 기술입니다. 대표적인 예로 Word2Vec을 통한 워드 임베딩이 있습니다. 임베딩의 목적은 데이터의 유사도를 벡터 공간상에서 잡아내는 것입니다.

| One-Hot 인코딩 | 임베딩 |
|-----------------|---------|
| 차원 수가 많음 | 낮은 차원 |
| 희소 벡터 | 밀집 벡터 |
| 유사도 정보 부재 | 유사도 정보 포함 |

임베딩의 장점:

- 데이터 차원 축소
- 유사도 정보 포착
- 기계 학습 모델 입력으로 활용

## MongoDB에 임베딩 저장하기

임베딩 벡터는 MongoDB의 BSON 문서에 저장할 수 있습니다. Python의 pymongo 라이브러리와 Word2Vec 모델을 활용한 예시는 다음과 같습니다:

```python
import pymongo
from gensim.models import Word2Vec

# MongoDB 연결
client = pymongo.MongoClient("mongodb://localhost:27017/")
db = client["mydatabase"]
collection = db["wordvectors"]

# 문장 데이터셋
sentences = [
    ['안녕', '나는', '김철수야'],
    ['너는', '누구', '이름이', '뭐야'],
    ['반갑다', '김철수', '나는', '이영희야']
]

# Word2Vec 모델 훈련
model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)

# 단어와 임베딩 벡터를 MongoDB 문서로 저장
for word in model.wv.index_to_key:
    vector = model.wv[word]
    doc = {"word": word, "vector": vector}
    collection.insert_one(doc)
```

위 코드에서는 Word2Vec 모델을 이용해 문장 데이터셋에서 단어 임베딩을 학습했습니다. 그런 다음 각 단어와 그에 해당하는 임베딩 벡터를 key-value 형태의 BSON 문서로 MongoDB에 저장하고 있습니다.

**이렇게 MongoDB에 임베딩 벡터를 저장하는 이유는 다음과 같습니다.**

1. **확장 가능한 문서 모델**: MongoDB의 문서 모델은 고정된 스키마 없이 다양한 데이터 구조를 저장할 수 있습니다. 이렇게 유연한 모델 덕분에 임베딩 벡터와 같은 배열 형태의 데이터를 쉽게 저장할 수 있습니다.

2. **다양한 데이터 활용**: 임베딩 벡터를 MongoDB에 저장하면 MongoDB의 집계 파이프라인, 텍스트 검색, 지리 공간 쿼리 등 다양한 기능과 결합하여 데이터를 활용할 수 있습니다.

3. **대용량 데이터 관리**: 임베딩 모델에서 생성되는 대용량 벡터 데이터를 MongoDB의 분산 클러스터 아키텍처를 통해 효율적으로 저장하고 관리할 수 있습니다.

4. **데이터 지속성**: 임베딩 벡터를 영구 저장소인 MongoDB에 저장하면 모델 재학습 없이도 기존 데이터에 접근할 수 있습니다.

따라서 MongoDB는 임베딩과 같은 기계 학습 데이터를 유연하게 저장하고, 다양한 방식으로 활용할 수 있는 적합한 데이터베이스입니다. 이런 이유로 많은 머신러닝 및 자연어 처리 애플리케이션에서 MongoDB를 임베딩 데이터 저장소로 활용하고 있습니다.

네, K-POP 노래와 가수 그룹으로 예시를 바꿔보겠습니다.

### 음악 추천 서비스 예제
MongoDB와 임베딩을 활용한 실제 프로젝트 예시로 음악 추천 서비스를 들어보겠습니다.

#### MongoDB 데이터 모델링
사용자 프로필, 플레이리스트, 곡 메타데이터를 MongoDB 문서로 모델링합니다.

```python
# 사용자 프로필
{
  "_id": ObjectId("..."),
  "name": "신다현",
  "playlists": [ObjectId("..."), ObjectId(...)]
}

# 플레이리스트 
{
  "_id": ObjectId("..."),
  "title": "뉴진스 최고!",
  "songs": [ObjectId("..."), ObjectId(...)]
}

# 곡 메타데이터
{
  "_id": ObjectId("..."),
  "title": "Attention",
  "artist": "NewJeans",
  "lyrics": "주목해 바로 넌 My Attention..."
}
```

#### 임베딩 생성 및 저장
곡 제목과 가사 텍스트를 Word2Vec으로 임베딩하여 MongoDB에 저장합니다.

```python
import pymongo
from gensim.models import Word2Vec

# 곡 데이터 로드
song_data = []
for song in songs.find({}, {"title": 1, "lyrics": 1}):
    text = song["title"] + " " + song["lyrics"]
    song_data.append(text.split())

# Word2Vec 모델 훈련
model = Word2Vec(song_data, vector_size=100, window=5, min_count=1, workers=4)

# 임베딩을 MongoDB에 저장
for word in model.wv.index_to_key:
    vector = model.wv[word]
    doc = {"word": word, "vector": vector}
    embeddings.insert_one(doc)
```

#### 유사 음악 추천
MongoDB의 데이터와 임베딩 벡터를 활용하여 사용자 플레이리스트와 유사한 곡을 추천합니다.

```python
import numpy as np

def recommend_songs(playlist_id, num_recommendations=10):
    playlist = playlists.find_one({"_id": playlist_id})
    song_ids = playlist["songs"]
    
    # 플레이리스트 곡 임베딩 평균 계산
    embeddings_cursor = embeddings.find({"word": {"$in": [song["title"] for song in songs.find({"_id": {"$in": song_ids}}, {"title": 1})]}})
    playlist_embedding = np.mean([emb["vector"] for emb in embeddings_cursor], axis=0)
    
    # 유사 곡 찾기
    similar_songs = embeddings.find(
        {"vector": {"$ne": playlist_embedding}},
        {"word": 1, "_id": 0}
    ).featsort("vector", playlist_embedding).limit(num_recommendations)
    
    return [song["word"] for song in similar_songs]
```

예를 들어 `recommend_songs(playlist_id)` 함수를 호출하면 다음과 같은 결과가 반환될 수 있습니다

```
['Hype Boy', 'OMG', 'Ditto', 'Love Dive', ...]
```

이 함수는 주어진 플레이리스트 ID의 플레이리스트 문서에서 곡 ID 리스트를 가져와서, 해당 곡들의 임베딩 벡터를 찾아 평균 벡터를 계산합니다. 

그리고 이 평균 벡터와 가장 유사한 임베딩 벡터(코사인 유사도 기준)를 가진 곡 제목들을 MongoDB에서 검색하여 반환합니다.

이렇게 MongoDB의 문서 데이터 모델과 풍부한 쿼리 기능을 Word2Vec 임베딩 기술과 결합하면, 사용자의 음악 취향을 잘 반영하는 개인화된 추천 시스템을 구축할 수 있습니다.