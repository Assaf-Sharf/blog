---
layout: single
title:  "R-CNN 논문 리뷰"
categories : paper
tag : [R-CNN, 논문리뷰, 딥러닝]
toc: true
toc_sticky: true
---

R-CNN 논문 : [**R-CNN**](https://arxiv.org/pdf/1311.2524.pdf)







### 요약

- Object Detection 성능이 정체되었고 그중 가장 좋은 성능을 가진 알고리즘 보더 mAP score 30% 이상을 높혀 53.3% mAP 달성
    - mAP(mean Avergae Precision)
        - 객체 탐지의 성능을 측정하는 대표적인 지표
    
- 객체 탐지 알고리즘의 핵심 2가지
    1. 객체 탐지를 위한 영역 제안에 CNN 적용
        - 영역 제안(Region Proposal)
            - 이미지 안에서 객체가 있을 만한 후보 영역을 먼저 찾아주는 방법, Selective Search (선택적 탐색)이 속함
                - Selective Search 알고리즘
                    - R-CNN에서 사용하고 YOLO에서 안씀
                      
                        —> YOLO부터는 conv 내부에서 처리
                        
                    - Segmentation과 Exhaustive search 두 방법을 결합해 후보영역 추천
                        - Segmentation : 이미지 구조를 사용해서 구역 분할
                        - Exhaustive search : 모든 객체의 위치를 찾는것
                    - Selective Search의 특징
                        - Capture All Scales : 이미지 내에서 물체 크기는 랜덤하고 일부객체에 경계가 덜 명확함 이를 위해서 모든 객체 크기를 고려하는 것
                        - Diversification : 영역들을 그룹화 하는데 있어 최적화된 방법이 없음, 그래서 색상,재질등 다양한 것을 고려
                        - Fast to Compute : 실제 Object detection에 사용할수 있을정도로 빠름
                        - 학습방법
                          
                            ![Untitled](/images/2022-06-27-R-CNN/Untitled.png)
                            
                            - R = 선택된 region 후보들 {r1,r2,...} , S = region들의 유사도 집합 {s(ri,rj),....}
                            
                            1. r1,r2,....rn → 값 초기화
                            2. 가장 유사성 높은 s(ri,rj) 선택
                            3. 선택된 ri,rj 영역을 rt로 합침
                            4. 합쳐진 rt와 나머지 region들의 새로운 유사성 집합(St)를 계산
                            5. 새로운 유사성 집합, 합쳐진 region(rt)을 원래 집합(S,R)에 포함
                            6. 하나의 region이 될때까지 반복
                            
                            - 유사성 판단 방법
                                - Region similarity : [0,1]로 정규화된 4가지 요소(color,Texture,size,Fill)들의 가중합으로 계산 (위에서Diversification의 특징이 여기서 반영됨 )
                                    - 유사성 공식
                                    
                                    ![Untitled](/images/2022-06-27-R-CNN/Untitled%201.png)
                                    
                                    ​	→ A의 값 설정을 모두 동일한 가중치로 줌
                                    
                                    - Color,Texture,Size,Fill 관련 공식
                                        - Color (색상)
                                            - 각 컬러 채널 25개 bin으로 설정
                                            - 각 region 마다 컬러 히스토그램 생성 (DPM의 SIFT와 비슷)
                                            - 차원 (RGB = 3 * 25개 bin = 75)
                                            - L1-norm 정규화 [0,1]
                                            - 인접한 regions의 교집합을 유사도로 측정
                                              
                                                ![Untitled](/images/2022-06-27-R-CNN/Untitled%202.png)
                                                
                                                - 위 식에서 2개의 변수 입력받아서 2개의 히스토리 생성후 둘간의 교집합이 유사성 척도
                                        - Texture (주변 픽셀 변화량)
                                            - σ = 1 인 8방향의 가우시안 미분 적용(가우시안관련은 DPM에 서술됨)
                                            - 10개의 bin 히스토그램 도출
                                            - L1-norm 정규화 [0,1]
                                            - 차원(8방향 * 10개 bin = 80)의 벡터로 인접한 region사이 유사성 평가
                                            - RGB 차원 : 8방향 * bin(10개) * RGB (3) = 240
                                              
                                                ![Untitled](/images/2022-06-27-R-CNN/Untitled%203.png)
                                            
                                        - Size (Region 들의 사이즈)
                                            - 사이즈 작을수록 유사도 높음
                                              
                                                ![Untitled](/images/2022-06-27-R-CNN/Untitled%204.png)
                                                
                                            - im = 원 이미지
                                        - Fill (candidate Bounding Box 크기와 차이)
                                            - candidate Bounding Box와 Region들의 사이즈의 차이가 적을수록 유사도가 높음
                                              
                                                ![Untitled](/images/2022-06-27-R-CNN/Untitled%205.png)
                                                
                                            - im은 원 이미지 나타냄
                                    - 위에서 합처진 영역(rt) 구하는 공식
                                      
                                        ![Untitled](/images/2022-06-27-R-CNN/Untitled%206.png)
                                        
                                        c = color 관련공식에서 생성된 히스토그램 의미,  r = region
        
    2. 사전 훈련과 파인 튜닝을 적용해 훈련 데이터가 적은 상황에서 성능을 향상
        - 파인 튜닝(fine-tuning) : 기존에 학습되어져 있는 모델을 기반으로 아키텍쳐를 새로운 목적에 맞게 변형하고 이미 학습된 모델의 가중치를 미세하게 조정하여 학습시키는 방법
    
    —> 영역 제안과 CNN을 결합했다는 이유로 R-CNN
    
- 특히. R-CNN은 OverFeat이라는 알고리즘의 성능보다 높은 성능 기록
    - OverFeat : Sliding Window 검출기 기반의 객체 탐지 알고리즘
        - 슬라이딩 윈도우(Sliding Window) 방식이란 사각형 윈도우를 이미지 왼쪽 위부터 오른쪽 아래까지 이동하면서 객체를 탐지하는 방식
        
          

### 서론

- Object detection 분야는 SIFT,HOG 검출기 기반으로 발전
  
- 2010년 부터 2012년까지 PASCAL VOC 데이터셋에서 객체 탐지 성능 향상되지 않았음

- R-CNN은 두 단계(2-stage) 절차를 갖는 구조화된 모델
    - 첫 번째 단계는 객체 분류(classification)
    - 두 번째 단계는 경계 박스 추정(bounding-box regression)
    
- ImageNet에서 우수한 성능을 기록한 CNN을 객체 탐지에 사용하면서 좋은 성능을 낼수 잇다고 생각함, CNN으로 Object detection을 하려면 2가지 문제 해결이 필요
    1. CNN으로 객체 localization 문제
        - localization : 객체 위치를 찾는일
    2. annotation 된 데이터가 부족한 상태에서 모델 학습해야 하는 문제
        - annotation : 객체 레이블 정보, 경계 박스 위치 정보 등을 포함하는 메타 정보
            - 경계 박스 : 객체 위치를 표시하는 사각형 박스 의미
    
    - 1번 문제인 CNN으로 객체 localization하는 문제
        - 이미지 분류와 달리, 객체 탐지는 객체를 분류하는 작업 뿐만 아니라 객체의 위치 좌표를 찾는 일까지 해야 함
        - 이미지 분류 보다 수행하는 작업이 추가됨
        - 객체 localization 위해 3가지 접근 방법
            1. localization을 회귀 문제로, 하지만 Szegedy의 논문에서 localization을 회귀 문제로 다루면 실효성이 떨어짐
            2. Sliding-Window Detector를 사용하는 방법,  R-CNN 연구진도 슬라이딩 윈도우 검출기 방식을 고려했음 하지만 R-CNN은 합성곱 계층이 5개인 구조 Sliding-Window 방식을 쓰려면 (195 x 195) 픽셀의 꽤 큰 윈도우와 (32 x 32) 픽셀의 스트라이드를 가져야 합니다. 윈도우와 스트라이드가 이렇게 크면 정확히 localization하기 어렵기 때문에 Sliding-Window Detector 사용하지 않음
            3. R-CNN 연구진은 영역 제안(region proposals) 기법을 사용해 객체 탐지, 세그멘테이션 모두 효과를 얻음
                - 세그멘테이션(Segmentation) : 이미지에서 픽셀단위로 관심 객체를 추출하는 방법
                - 영역 제안 기법 (Region proposal)
                  
                    ![Untitled](/images/2022-06-27-R-CNN/Untitled%2040.png)
                    
                    1. 이미지를 input
                    2. 2,000개의 후보 영역을 제안
                    3. 후보 영역을 일정한 크기로 조정하고 CNN을 이용해 각 후보 영역에서 피처를 계산, 일정한 크기로 조정하는 이유는 CNN 특성상 input 데이터 크기가 고정되어야 해서
                    4. CNN의 마지막 단계는 전결합 계층, 전결합 계층에 있는 값을 피처라고 간주하고, 서포트 벡터 머신(SVM)을 이용해 각 영역에 대해 분류 작업을 수행
        
    - 2번 문제인 annotation 된 데이터가 부족한 상태에서 모델 학습해야 하는 문제
        - 위에서 객체 localization 문제는 영역 제안 기법으로 해결
        
        - 레이블된 데이터 부족한 상황을 해결해야함
            - CNN은 깊은 CNN 구조를 가졌는데, 이렇게 큰 CNN을 제대로 훈련할 정도의 데이터가 부족
            
            - 이 문제를 해결하려고 R-CNN 연구진은 ILSVRC의 많은 데이터로 사전 훈련(pre-training)을 한 뒤, 적은 수의 PASCAL 데이터로 원하는 도메인에 맞게 파인튜닝(fine-tunning)을 수행
            
            - ILSVRC의 보조 데이터를 활용해 사전 훈련을 하기 때문에, annotation된 PASCAL 데이터가 적어도 파인튜닝만으로도 좋은 성능을 얻음
            
            - mAP가 8% 상승
            
              

### R-CNN 핵심

![Untitled](/images/2022-06-27-R-CNN/Untitled%2041.png)

- input data로 이미지, 정답 bounding box가 들어감

- R-CNN은 세 가지 모듈로 구성 (region proposal, CNN, SVM)
  
    각 클래스별로 영역 제안 하는 모듈 (Region Proposals) : detector가 이용가능한 영역 후보 선정
    
    - **첫 번째 모듈, Region Proposals**
      
        ![Untitled](/images/2022-06-27-R-CNN/Untitled%2042.png)
        
        - Region Proposals은 전부를 탐색하는 완전탐색과 다르게 기준에 따라 탐색을 수행, 상향식 탐색방법인 계층적 그룹 알고리즘 사용
        
        - selective search 알고리즘
          
            ![Untitled](/images/2022-06-27-R-CNN/Untitled%2043.png)
            
            - Segmentation과 Exhaustive search 두 방법을 결합해 후보영역 추천
                - Segmentation : 이미지 구조(색상, 무늬, 크기, 모양)를 사용해서 구역 분할
                - Exhaustive search : 모든 객체의 위치를 찾는것(모든 가능한 후보 영역을 검색하는것)
            - selective search 특징
                - Capture All Scales : 이미지 내에서 물체 크기는 랜덤하고 일부객체에 경계가 덜 명확함 이를 위해서 모든 객체 크기를 고려하는 것
                    - Capture All Scales의 모든 객체 크기 고려하기 위해 [hierarchical grouping algorithm 사용](https://www.notion.so/R-CNN-a41e32f853614501937614eff67e5977)
                - Diversification : 영역들을 그룹화 하는데 있어 최적화된 방법이 없음, 그래서 색상,재질등 다양한 것을 고려
                - Fast to Compute : 실제 Object detection에 사용할수 있을정도로 빠름
            - 단점
                - Selective Search의 경우 후보 영역 추출 과정이 CNN과 별도로 동작, 실시간 처리가 어려워짐)
            
        - selective search 과정
            1. Efficient Graph-Based Image Segmentation(Felzenszwalb)을 사용하여 초기 후보 영역을 다양한 크기와 비율로 생성
               
                ![Untitled](/images/2022-06-27-R-CNN/Untitled%2044.png)
                
                - 위와 같이 여러가지 후보영역 생성
                - Efficient Graph-Based Image Segmentation(Felzenszwalb) 란?
                    - 인지적인 관점에서 의미 있는 부분을 모아서 그룹화, 연산량 관점에서 효율성 증대 라는 2개의 목표를 기반으로 segmentation 기법 개발
                    - 다른 segmentation 기법도 있지만 연산량관점에서 이방법이 좋음
                    - 설명
                      
                        ![Untitled](/images/2022-06-27-R-CNN/Untitled%2045.png)
                        
                        - 논문에서 (a)와 같은 합성 이미지를 사용해 segmentation 수행, 만약 사람이 인식하는 방식으로 segmentation 수행하면 (b)와 같이 크게 3개의 영역으로 나눠짐
                        - 그림 (a)를 보면 왼쪽 부분은 밝기가 조금씩 변하기 때문에 그림 (b)의 왼쪽과 같이 segmentation을 한다는 것이 쉽지 않음
                        - (a)의 오른쪽을 보면 바코드와 같은 형태가 있는데 이것을 여러 개의 작은 영역으로 구분하지 않고 (b)의 오른쪽 그림처럼 1개의 영역으로 깔끔하게 구별하는 것 역시 기존 segmentation 알고리즘으로 쉽지 않음
                        - 그림 (c)는 사람이 하는 것처럼 의미 있는 부분만을 모아서 그룹화를 제대로 시키지 못한 경우를 보여줌
                        
                        - 논문에서는 사람이 인지하는 방식으로의 segmentation을 위해 graph 방식을 사용 (graph 방식 설명)
                          
                            ![Untitled](/images/2022-06-27-R-CNN/Untitled%2046.png)
                            
                            - 그래프 이론 G = (V, E)에서 V는 노드(virtex)를 나타내는데, 여기서는 픽셀이 바로 노드
                            - 기본적으로 이 방식에서는 픽셀들 간의 위치에 기반하여 가중치(w)를 정하기 때문에 “grid graph 가중치” 방식 이라고 함(가중치는 위와 같은 수식으로 결정이 되고 graph는 상하좌우 연결된 픽셀에 대하여 만듬)
                            - E(edge)는 픽셀과 픽셀의 관계를 나타내며 가중치 w(vi, vj)로 표현이 되는데, 위 식에서 알 수 있듯이 가중치는 픽셀간의 유사도가 떨어질수록 큰 값을 갖게 되며, 결과적으로 w 값이 커지게 되면 영역의 분리가 발생
                            
                            ![Untitled](/images/2022-06-27-R-CNN/Untitled%2047.png)
                            
                            - 위 그림과 같이 C1과 C2가 있는 경우에, 영역을 분리할 것인지 혹은 통합할 것인지를 판단하는 아래와 같은 수식을 사용
                            
                            ![Untitled](/images/2022-06-27-R-CNN/Untitled%2048.png)
                            
                            - 위 식에서 Dif(C1, C2)는 두개의 그룹을 연결하는 변의 최소 가중치를 나타내고, MInt(C1, C2)는 C1과 C2 그룹에서 최대 가중치 중 작은 것을 선택한 것
                            - 그룹간의 차가 그룹 내의 차보다 큰 경우는 별개의 그룹으로 그대로 있고, 그렇지 않은 경우에는 병합을 하는 방식
                            
                            ![Untitled](/images/2022-06-27-R-CNN/Untitled%2049.png)
                            
                            - Efficient Graph-Based Image Segmentation를 통해 비교적 간단한 알고리즘으로 segmentation을 수행했음에도 불구하고 위 그림과 같이 양호한 결과를 얻음
                            
                            ![Untitled](/images/2022-06-27-R-CNN/Untitled%2050.png)
                            
                            - 기존 segmentation 방법으로는 에펠탑을 같은 대상으로 처리하기가 어렵지만, 본 논문의 방식을 사용하면 좋은 결과를 얻을 수 있음
                            
                            - 결론
                                - Efficient Graph-Based Image Segmentation 알고리즘은 앞서 살펴본 것처럼 결과가 비교적 좋고 연산 속도가 매우 빨라 Selective Search의 3단계 과정 첫번째 단계에 적용
            2. 그리디 알고리즘을 통해 비슷한 영역을 반복적으로 통합 (이때 hierarchical grouping algorithm 사용)
               
                ![Untitled](/images/2022-06-27-R-CNN/Untitled%2051.png)
                
                - 위와 같이 비슷한 영역간에 통합
                - hierarchical grouping algorithm 과정
                  
                    ![Untitled](/images/2022-06-27-R-CNN/Untitled.png)
                    
                    - R = 선택된 region 후보들 {r1,r2,...} , S = region들의 유사도 집합 {s(ri,rj),....}
                    - r1,r2,....rn → 값 초기화
                    1. 처음에 모든 영역에 대해 유사도를 계산하여 similarity set S를 생성한다.
                    2. S에서 가장 큰 유사도 값을 가진 ri, rj에 대해 통합한다.
                    3. ri, rj의 유사도 값은 S로부터 제거한다.
                    4. 통합된 새로운 영역(rt)과 인접한 영역들에 대해 유사도(St)를 계산 통합된 새로운 영역(rt)과 인접한 영역들에 대해 유사도(St)를 계산
                    5. S와 R에 유사도(St)와 통합된 새로운 영역(rt)을 추가 S와 R에 유사도(St)와 통합된 새로운 영역(rt)을 추가
                    
                    - 유사성 판단 방법
                        - Region similarity : [0,1]로 정규화된 4가지 요소(color,Texture,size,Fill)들의 가중합으로 계산 (위에서 [Diversification의 특징](https://www.notion.so/R-CNN-a41e32f853614501937614eff67e5977)이 여기서 반영됨 )
                            - 유사성 공식
                            
                            ![Untitled](/images/2022-06-27-R-CNN/Untitled%201.png)
                            
                            → A의 값 설정을 모두 동일한 가중치로 줌
                            
                            - Color,Texture,Size,Fill 관련 공식
                                - Color (색상)
                                    - 각 컬러 채널 25개 bin으로 설정
                                    - 각 region 마다 컬러 히스토그램 생성 (DPM의 SIFT와 비슷)
                                    - 차원 (RGB = 3 * 25개 bin = 75)
                                    - L1-norm 정규화 [0,1]
                                    - 인접한 regions의 교집합을 유사도로 측정
                                      
                                        ![Untitled](/images/2022-06-27-R-CNN/Untitled%202.png)
                                        
                                        - 위 식에서 2개의 변수 입력받아서 2개의 히스토리 생성후 둘간의 교집합이 유사성 척도
                                - Texture (주변 픽셀 변화량)
                                    - σ = 1 인 8방향의 가우시안 미분 적용(가우시안관련은 DPM에 서술됨)
                                    - 10개의 bin 히스토그램 도출
                                    - L1-norm 정규화 [0,1]
                                    - 차원(8방향 * 10개 bin = 80)의 벡터로 인접한 region사이 유사성 평가
                                    - RGB 차원 : 8방향 * bin(10개) * RGB (3) = 240
                                      
                                        ![Untitled](/images/2022-06-27-R-CNN/Untitled%203.png)
                                    
                                - Size (Region 들의 사이즈)
                                    - 사이즈 작을수록 유사도 높음
                                      
                                        ![Untitled](/images/2022-06-27-R-CNN/Untitled%204.png)
                                        
                                    - im = 원 이미지
                                - Fill (candidate Bounding Box 크기와 차이)
                                    - candidate Bounding Box와 Region들의 사이즈의 차이가 적을수록 유사도가 높음
                                      
                                        ![Untitled](/images/2022-06-27-R-CNN/Untitled%205.png)
                                        
                                    - im은 원 이미지 나타냄
                            - 위에서 합처진 영역(rt) 구하는 공식
                              
                                ![Untitled](/images/2022-06-27-R-CNN/Untitled%206.png)
                                
                                c = color 관련공식에서 생성된 히스토그램 의미,  r = region
                
            3. 최종적으로 하나의 영역이 만들어질 때까지, 2번을 반복적으로 수행
            
            - 1, 2, 3번 과정을 지나면서
              
                ![Untitled](/images/2022-06-27-R-CNN/Untitled%2052.png)
                
                - 각 후보 영역들이 유사도가 높은 영역간에 통합이 되어감
                - 위 과정을 통해 ROI 생성 , 직사각형의 bounding box로 생성
                    - ROI(region of interest) : 이미지 처리함에 있어서 객체를 탐지하거나 검출하는 영역, 관심 영역
            
        - selective search 과정을 통해 임의의 bounding box 영역 설정 (2000개의 후보영역 생성)
        
        - 생성된 임의의 2000개 bounding box와 input data로 주어진 정답 bounding box 간의 IoU 계산 (논문에서 임계값 0.5 이상 positive, 미만은 negative로 설정)
            - IoU(Intersection of Union)
                - 실제 bounding box와 예측한 bounding box 사이에 교집합,합집합을 구하고 교집합 / 합집합 (0~1 까지값)
                
                ![Untitled](/images/2022-06-27-R-CNN/Untitled%2053.png)
            
        - 2000장의 region proposals을 NMS 수행해 최종적으로 얻은 이미지를 227x227로 사이즈를 통합
            - 227x227 사이즈로 바꾸는 이유?
                - Convolution Layer에는 input size가 고정이지 않음
                - 마지막 FC layer에서 동일한 output size를 얻기위해 입력에서 동일한 input size로 넣어줌 (selective search에서 얻어진 영역의 크기 일정하지 않음 → output도 일정하지 않게됨)
                - 227x227 사이즈로 자를때 객체 영역만 자르지 않고 16픽셀만큼 주변 배경을 살려서
                
            - 이미지 마다 2000개의 bounding box 표시가 불필요, NMS(Non maximum Supression) 사용
              
                ![Untitled](/images/2022-06-27-R-CNN/Untitled%2054.png)
                
                1. bounding box별로 지정한 confidence scroe threshold 이하의 box를 제거한다.
                2. 남은 bounding box를 confidence score에 따라 내림차순으로 정렬한다. 그 다음 confidence score가 높은 순의 bounding box부터 다른 box와의 IoU값을 조사하여 IoU threshold 이상인 box를 모두 제거한다.
                3. 2의 과정을 반복하여 남아있는 box만 선택한다.
                
                
    1. CNN : 각각의 region에 대한 고정된 크기의 feature vector 추출
        - **두 번째 모듈, CNN**
          
            ![Untitled](/images/2022-06-27-R-CNN/Untitled%2055.png)
            
            - R-CNN에서는 CNN arichitecture를 AlexNet을 이용
                - classification dataset을 이용해 pre-trained된 AlexNet 구조 이용
                    - AlexNet 구조
                      
                      
                        | input (3 x 224 x 224) |
                        | --- |
                        | 11 x 11 conv |
                        | 3 x 3 MaxPool |
                        | 5 x 5 conv |
                        | 3 x 3 MaxPool |
                        | 3 x 3 conv |
                        | 3 x 3 conv |
                        | 3 x 3 conv |
                        | 3 x 3 MaxPool |
                        | Dense |
                        | Dense |
                        | Dense(softmax) |
                    - AlexNet 특징
                        - 당시 가장 좋은 성능인 SVM + HoG 모델을 제치고 가장 좋은 성능 기록
                        - 기존에 사용되돈 활성함수인 sigmoid,tanh 아닌 ReLU를 사용해 학습, 예측 속도가 빠르고 정확도 유지
                        - FC layer에서 과적합 방지를 위해 drop out 사용 → 성능향상
                
            - pre-train AlexNet은 분류로 학습된 모델, 객체 검출분야에 사용하기 위해 해당 도메인에 특화되게 파인튜닝하는 과정 필요
              
                —>  도메인 특화 파인튜닝(Domain-specific fine-tunning)
                
                - Pre-train AlexNet 으로 Domain-specific fine-tunning 적용후 fine-tuned AlexNet 생성과정
                  
                    ![Untitled](/images/2022-06-27-R-CNN/Untitled%2056.png)
                    
                    - 2000장의 region proposals와 ground-truth box의 IoU(Intersection of Union)을 비교
                    - IoU가 0.5보다 큰 경우 positive samples, 0.5보다 작은 경우 negative samples로 나눔
                    - 이렇게 sample을 나눴을 때, ground truth만 positive sample로 정의할때 보다 30배 많은 학습데이터를 얻을 수 있음
                      
                        —> 많은 데이터를 통해 overfitting을 방지
                        
                        - ground truth : 모델이 우리가 원하는 답으로 예측해주길 바라는 답
                    - Positive sample는 객체가 포함되어 있는 sample을 의미, negative sample은 객체가 포함되지 않은 배경 sample을 의미
                    - positive sample 32개 + negative sample 96개 = 128개의 이미지로 이루어진 하나의 Mini batches 생성
                    - 이렇게 생성된 배치를 이용해 fine-tuning을 진행
                        - fine-tuning을 하기 위해서 기존의 pre-trained된 AlexNet의 마지막 softmax layer를 수정해서 N+1 way classification을 수행
                            - N : R-CNN에서 사용하는 dataset의 객체들의 종류의 개수, 1을 더해준 이유는 배경인지 판단하기 위해
                            - SGD를 통해 N+1 way classification을 수행하면서 학습된 CNN 구조는 domain-specific fine-tuning을 이룸
                            - 마지막의 N+1 way classification을 위해 수정한 softmax layer는 R-CNN 모델 사용시 사용하지 않음.  왜냐하면 softmax layer는 fine-tuning을 위해 사용한 것이고, 원래 R-CNN에서 CNN 구조의 목표는 4096-dimensional feature vector를 추출하는 것이 목표이기 때문
                    - 여기까지 진행하면서 Fine tuned AlexNet을 얻음
                - fine-tuned AlexNet을 통해 4096 feature vector 얻는 과정
                  
                    ![Untitled](/images/2022-06-27-R-CNN/Untitled%2057.png)
                    
                    - 2000장의 region proposals에서 fine-tuning때와는 다르게 ground truth box만을 positive sample, IoU 값이 0.3보다 작은 것은 negative sample로 지정
                      
                        —> IoU값이 0.3보다 큰 경우 무시
                        
                        - fine-tuning 할때와 train SVM 수행시 positive, negative examples 다르게 설정하는 이유
                            - fine-tuning 에서는 IoU 0.5 이상이면 positive 그 외 negative로 놓는 반면 SVM으로 훈련시킬 때는 0.3 IoU 이상이면 positive 그 외는 negative로 설정하여 더 높은 성능을 기록했기 때문
                            - 추가로, 논문에서 fine-tuning 과 SVM 훈련시 임계값 0.5로 서로 같게 했을경우 성능이 떨어졌고 0,0.1~0.5 다양하게 실험한 결과 fine-tuning 0.5 , SVM 0.3 이 성능이 가장 좋음
                        - 임계값 설정하는 이유?
                            - 자동차 탐지 이진분류를 볼때 , 자동차 타이트하게 표시한 bounding box는 positive, 자동차 없는건 negative
                            - 만약 애매하게 자동차를 걸친 경계박스는 positive 인지 negative인지 확인하기 어려움
                            - 이때 IoU 임계값을 활용해 문제를 해결했고 이를 통해 fine-tuned, SVM 각각 임계값을 설정함
                    - fine-tuning과 마찬가지로 positive sample 32개 + negative sample 96개 = 128개의 미니배치를 구성
                    - fine-tuning된 AlexNet에 입력하여 4096 dimensional feature vector를 추출
                    - 추출된 4096 dimensional feature vector를 얻음
                
            - 사전 학습된 CNN에 region proposals 2000개의 각각의 227x227 image 입력받아서 4096-dimensional feature vector를 추출
            
            
        
    2. linear SVM :  분류 수행
       
        ![Untitled](/images/2022-06-27-R-CNN/Untitled%2058.png)
        
        - SVM
          
            ![Untitled](/images/2022-06-27-R-CNN/Untitled%2059.png)
            
            - SVM은 기계 학습의 분야 중 하나로 패턴 인식, 자료 분석 등을 위한 지도 학습 모델, 주로 분류와 회귀 분석을 위해 사용
            - 각각의 분류 클래스에 대해서 SVM을 적용한 Matrix를 기반으로 분류 작업을 수행 (해당 클래스 ~ O/X)
            
        - SNM classigier 사용하는 이유
            - softmax 방식의 regression classifier가 VOC 기준 mAP 50.9% 기록하는데 반해 SVM이 더 높은 성능을 기록
            
        - CNN을 거쳐서 얻은 4096개의 feature vector를 사용해 SVM으로 분류 수행
            - SVM은 2진 분류로 사용되고 이때 분류할려는 객체의 종류 만큼 SVM이 필요함, 학습을 1차적으로 수행해서 SVM 미세 조정
            
            - 미세조정된 SVM을 hard negative mining 기법을 통해 재학습을 수행
            
            - hard negative mining
                - hard negative mining : positive 샘플과 negative 샘플의 개수를 균일하게 만드는 방법
                
                - 신뢰도 점수(confidence score)를 활용해 negative 샘플을 선정
                    - 신뢰도 점수(confidence score)
                        - confidence score은 bounding box가 객체를 포함한다는 것을 얼마나 믿을만 한지 그리고 예측한 bounding box가 얼마나 정확한지를 나타내는 수치
                          
                            ![Untitled](/images/2022-06-27-R-CNN/Untitled%2060.png)
                            
                            - Pr(Object) = softmax 결과와 같이 각 class에 속할 확률
                            - IOU = 실제 bounding box와 예측한 bounding box 사이에 교집합,합집합을 구하고 교집합 / 합집합 (0~1 까지값)
                    
                - negative 샘플 = 배경 ,이미지 안에 배경 영역은 많고, negative 샘플이 될 경계 박스도 많음
                
                - negative 샘플이 지나치게 많으면 객체 탐지 모델의 성능이 떨어질 우려가 있으니, 신뢰도 점수가 가장 높은 경계 박스순으로 negative 샘플을 선정한다는 의미
                    - 객체 = positive sample, 배경 = negative sample
                    - bounding box를 배경이라고 예측하고 실제로 배경인 경우 true negative sample , 객체라고 예측했지만 실제는 배경인 경우 false positive sample
                    - 객체 탐지 시, positive sample보다 negative sample이 더 많은 클래스 불균형 때문에 모델은 주로 false positive 오류를 주로 범하게 됨
                    - 이러한 문제를 해결하기 위해 처음 linear SVMs를 학습시킬 때의 false positive sample들을 epoch마다 학습 데이터에 추가하여 학습을 진행, 이로인해 모델 robust해지고 false positive 줄어듦
                    
                    
            
        - SVM으로 분류가된 bounding box에 bounding box regression 적용
            - bounding box regression
                - SVM을 통해 불류된 bounding box를 ground-truth box와 비슷하게 조정해주는 역할 수행
                - selective search로 검출된 2000개의 bounding box에 모두 적용하는 것이 아니라, ground-truth box와 IoU가 가장 높은 bounding box를 선택하여 bounding box regression을 적용
                
                - bounding box regression 적용하는 이유
                    - selective search 알고리즘을 통해 얻은 객체의 위치는 부정확할 수 있고 이런 문제를 해결하기 위해 객체의 위치를 조절
                    - 과정
                        - 하나의 박스 표현
                          
                            ![Untitled](/images/2022-06-27-R-CNN/Untitled%2061.png)
                            
                            - 위에서 x,y 이미지 중심점  w,h 너비,높이
                        - Ground Truth에 해당하는 박스 표현
                          
                            ![Untitled](/images/2022-06-27-R-CNN/Untitled%2062.png)
                            
                            - Ground Truth : 우리의 모델이 우리가 원하는 답으로 예측해주길 바라는 답
                        - P에 해당하는 박스를 최대한 G에 가깝게 이동하는 함수를 학습시키는 것이 목표 (box가 인풋으로 들어왔을 때 x,y,w,h를 각각 이동 시켜주는 함수들을 표현해보면 다음과 같음
                          
                            ![Untitled](/images/2022-06-27-R-CNN/Untitled%2063.png)
                            
                            - x,y는 좌표이기 때문에 이미지 크기와 상관없이 위치만 변경
                              
                                ![Untitled](/images/2022-06-27-R-CNN/Untitled%2064.png)
                                
                            - 너비와 높이는 이미지 크기에 비례해서 조정해야함
                              
                                ![Untitled](/images/2022-06-27-R-CNN/Untitled%2065.png)
                            
                        - 위 식의 d를 구하기 위해 CNN을 통과할 때 pool5 레이어에서 얻어낸 특징 벡터를 사용, 함수에 학습 가능한 가중치 벡터 주어서 계산
                          
                            ![Untitled](/images/2022-06-27-R-CNN/Untitled%2066.png)
                            
                        - loss function
                          
                            ![Untitled](/images/2022-06-27-R-CNN/Untitled%2067.png)
                            
                            - MSE 에 L2-norm 합쳐놓은 형태
                            - 람다 = 1000
                        - 최종식
                          
                            ![Untitled](/images/2022-06-27-R-CNN/Untitled%2068.png)
                            
                        - 요약
                            - CNN을 통과해 얻은 벡터와 x,y,w,h 를 조정하는 함수의 가중치를 곱해서 bounding box를 조정해주는 선형 회귀를 학습하는 것
                            - N개의 training pair인 P는 ground truth 와 IoU 값이 0.6 이상인 경우만 사용, 겹치는 영역 적을수록 학습이 어려워짐, (Ground Truth box G의 overlap을 최대화 하는 P인 임계값 0.6 선택)
                            - bounding box regression은 여러번 수행해도 결과 향상 없어서 한 번만 수행
                            
        



### 후기

- 하나의 이미지에 2000개의 region 존재할 때마다 이미지 cropping, CNN 연산 수행 결과적으로 연산량이 많아지고, detection 속도가 느림
- 3가지 주요 module로 구성되어있어서 학습 과정이 복잡하고 , end-to-end 학습 불가능