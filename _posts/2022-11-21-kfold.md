---
title: '[DL/BASIC] 교차 검증 - 안정적인 모델 성능 평가 방법 🚥 '
layout : single
toc: true
toc_sticky: true
categories:
  - basics
---

## 7. 교차검증 (cross validation)

### 7.0 들어가며
머신러닝 모델은 훈련 데이터에서의 정확도도 물론 중요하지만 머신러닝의 궁극적인 목표는 모델이 처음 접하는 데이터에서 얼마나 뛰어난 성능을 보여주는 것이다. 그렇기 때문에 우리는 모델이 훈련 데이터를 통해 얼마나 훈련이 잘 되었는지 판단할 수 있는 지표가 필요하기 때문에 검증 데이터를 통해 검증을 하는 과정을 거쳐야한다. 이번 글에서는 구축한 모델이 안정적인 일반화 성능 측정 방법인 여러가지 교차검증 방법을 알아보겠다.


### 7.1 k-겹 교차 검증

**교차 검증(cross-validation)**은 모델의 성능을 평가하기 위해 훈련 세트와 검증 세트로 한 번만 나누는 것보다 더 안정적인 평가 방법이다. 가장 보편적으로 사용하는 교차 검증 방법은 **k-겹 교차 검증(k-fold cross-validation)**이다. k-fold 교차 검증은 데이터를 k개의 비슷한 크기의 부분 집합 세트로 나눈다. 그 다음 첫번째 폴드부터 k번째 폴드까지 부분집합 데이터를 검증 데이터로 사용하고 나머지 데이터를 훈련 데이터로 사용하는 k개의 모델을 만든다. 그럼 총 k개의 모델에서 서로다른 k개의 정확도를 얻을 수 있다. 다음 이미지를 참고해보자.

이미지1

출처(https://donaldaq.github.io/articles/2018-11/Chapter-4-with-Keras)

k-fold 교차검증의 예제로 scikit-learn에서 제공하는 라이브러리를 이용한 교차 검증을 구현해보겠다.


```python
from sklearn.model_selection import  cross_val_score
from sklearn.datasets import load_iris # 예제를 위한 데이터 로드
from sklearn.linear_model import LogisticRegression # 예제를 위한 머신러닝 모델

iris = load_iris()
logreg = LogisticRegression(max_iter=1000)

# cv 매개변수를 이용해서 몇개의 폴드를 사용할건지 설정(default=5)
scores = cross_val_score(logreg, iris.data, iris.target, cv=10)
print('교차 검증 점수: ',scores)
```

    교차 검증 점수:  [1.         0.93333333 1.         1.         0.93333333 0.93333333
     0.93333333 1.         1.         1.        ]


10개의 폴드를 사용해서 교차검증을 했기 때문에 10개의 점수가 반환되었다. 그리고 보통 교차 검증의 정확도를 간단하게 나타내기 위해 출력된 점수들의 평균을 사용한다.


```python
print('교차 검증 평균 점수: {:.2f}'.format(scores.mean()))
```

    교차 검증 평균 점수: 0.97


cross_val_score과 비슷하지만 모델의 훈련에 대한 자세한 훈련과 테스트에 걸린 시간을 담은 딕셔너리를 반환하는 cross_validate 함수를 사용할 수도 있다.


```python
from sklearn.model_selection import cross_validate
output = cross_validate(logreg, iris.data, iris.target, return_train_score=True)
output
```




    {'fit_time': array([0.02925134, 0.03023601, 0.02448535, 0.03000307, 0.02381682]),
     'score_time': array([0.00050068, 0.00037575, 0.00043106, 0.00042295, 0.00041652]),
     'test_score': array([0.96666667, 1.        , 0.93333333, 0.96666667, 1.        ]),
     'train_score': array([0.96666667, 0.96666667, 0.98333333, 0.98333333, 0.975     ])}



교차 검증을 사용하는 이유는 뭘까? 먼저 모델의 일반화 성능을 평가하기 위해 어떻게 훈련 데이터와 검증데이터로 나누는가는 평가 점수에 큰 영향을 미친다. 만약 테스트 세트에 분류하기 쉬운 샘플이 많이 들어갔다면 검증 세트의 정확도는 비현실적으로 높게 나올것이고, 반대로 검증 세트에 분류하기 어려운 샘플들이 많이 들어갔다면 정확도가 아주 낮게 나올 것이다. train_test_split은 데이터를 무작위로 나누기 때문에 앞에서 언급한 상황이 발생할 수도 있기 때문에 위험하지만 교차 검증은 검증 세트에 각 데이터가 정확하게 한번씩 들어가기 때문에 비교적 정확한 모델의 점수를 얻을 수 있다. 하지만 아무래도 교차 검증은 k개의 모델을 만들고 훈련해야하기 때문에 많은 계산량을 요구한다.

#### 7.1 계층별 k-겹 교차 검증 

7.1 절에서 언급한 대로 데이터셋을 나열 순서대로 k개의 폴드로 나누는 것이 항상 좋은 것은 아니다. iris 데이터셋으로 예를 들어보겠다.


```python
from sklearn.datasets import load_iris
iris = load_iris()
print('iris 데이터 레이블 : \n',iris.target)
```

    iris 데이터 레이블 : 
     [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
     0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
     1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2
     2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
     2 2]


출력된 값을 보면 첫번째 1/3은 클래스 0, 두번째 1/3은 클래스 1, 마지막 1/3은 클래스 2이다. 이 데이터에 3-겹 교차 검증을 적용하면 정확도가 0이 나오게 된다. 정확도가 0보다는 높아야하기 때문에 이 교차 검증 방법은 잘못되었다. scikit-learn은 분류 문제일 경우 이 방법 대신 **계층별 k-겹 교차검증(stratified k-fold cross-validation)**을 제공한다. 계층별 교차 검증은 다음 이미지처럼 폴드 안의 클래스 비율이 전체 데이터셋의 클래스 비율과 같도록 데이터를 나눈다.

이미지2

출처(https://blog.csdn.net/htuhxf/article/details/102847188)

예를 들어 데이터의 10%가 클래스 A이고, 30%가 클래스 B이고, 60%가 클래스 C이면 계층별 교차 검증은 각 폴드에 클래스 A 샘플이 10%, B 샘플이 30%, C 샘플이 60%가 되도록 만든다. 참고로 머신러닝 문제 중 회귀 문제에서는 보통 k-fold 교차 검증을 사용한다.

앞서 cross_val_score를 사용할 때 cv 매개변수를 이용해 폴드의 개수를 조정했었는데, scikit-learn에서는 cv 매개변수에 교차 검증 분할기를 전달함으로써 데이터를 분할하는 과정을 더 세밀하게 제어할 수 있다. 예시로 iris 데이터셋에서 기본 3-겹 교차 검증을 사용하는 것은 좋은 방법이 아니라는 것을 확인해보겠다.


```python
from sklearn.model_selection import KFold
kfold = KFold(n_splits=3)

# 그런 다음 kfold 객체를 cross_val_score의 cv 매개변수로 전달

print('교차 검증 점수: \n',cross_val_score(logreg, iris.data, iris.target,cv=kfold))
```

    교차 검증 점수: 
     [0. 0. 0.]


위의 교차 검증에서 각 폴드는 iris 데이터셋의 클래스 중 하나에 대응하므로 아무것도 학습할 수 없다. 계층별 교차 검증을 사용할 수도 있지만 , 샘플의 순서를 무작위로 섞는 것도 방법이 될 수 있다. 데이터를 분할하기 전에 섞어주면 더 좋은 결과가 나온다.


```python
kfold = KFold(n_splits=3, shuffle=True, random_state=0)
print('교차 검증 점수: \n',cross_val_score(logreg, iris.data, iris.target,cv=kfold))
```

    교차 검증 점수: 
     [0.98 0.96 0.96]


### 7.3 임의 분할 교차 검증
또 하나의 유연한 교차 검증 방법은 **임의 분할 교차 검증(shuffle-split cross-validation)**이다. 임의 분할 교차 검증은 다음 이미지 같이 train_size 만큼의 데이터로 훈련 세트를 만들고, test_size 만큼의 훈련 세트와 중첩되지 않는 데이터로 데이터 셋을 만들도록 분할하고 n_splits 만큼 분할을 반복한다. (train_size와 test_size 매개변수에 실수를 입력하면 데이터의 비율을, 정수를 입력하면 데이터의 절대 개수를 의미한다.) 

이미지3

출처(https://medium.com/swlh/cross-validation-estimator-evaluator-897d28afb4ff)


```python
from sklearn.model_selection import ShuffleSplit
# 데이터의 50%를 훈련데이터, 50%를 검증 데이터세트로 10번 반복
shuffle_split = ShuffleSplit(test_size=0.5, train_size=0.5, n_splits =10)
print('교차 검증 점수 : \n', cross_val_score(logreg, iris.data,iris.target,cv=shuffle_split))
```

    교차 검증 점수 : 
     [0.92       0.96       0.96       0.94666667 0.96       0.97333333
     0.96       0.94666667 0.97333333 0.96      ]


### 7.4 그룹별 교차 검증

데이터 안에 매우 연관된 그룹이 있을 때도 교차 검증이 많이 사용된다. 예를 들어 사람의 표정을 인식하는 모델을 만들기 위해 100명의 사진을 데이터로 사용한다고 해보자. 모델의 궁극적인 목표는 처음 보는 사람의 표정을 구분하는 것이다. 이 데이터셋에 계층별 교차 검증을 사용할 수 있지만 같은 사람의 얼굴이 훈련 세트와 검증 세트에 모두 들어갈 수가 있다. 그렇게 되면 검증 세트에 있는 처음 보는 얼굴보다 훈련 세트에 있던 얼굴의 표정을 훨씬 쉽게 식별할 수 있기 때문에 정확한 평가가 어려워진다. 정확한 평가를 위해서 훈련 세트와 검증세트에 서로 다른 사람의 사진이 들어가도록 해야한다.

그렇게 하기 위해 사진이 어떤 사람의 얼굴인지 기록한 배열을 groups 매개변수로 전달 받을 수 있는 GroupKFold를 사용할 수 있다. groups 배열은 훈련 세트와 테스트 세트를 만들 때 분리되지 않아야 할 그룹을 지정하는 것이다. 아래 예제 코드는 인위적으로 만든 데이터셋에 groups 배열로 그룹을 지정한다. 데이터셋은 12개의 데이터로 이뤄져 있고 4개의 그룹을 나타내고 있다. 


```python
from sklearn.datasets import make_blobs
from sklearn.model_selection import GroupKFold
# 인위적 데이터셋 생성
X,y = make_blobs(n_samples=12, random_state=0)
groups = [0,0,0,1,1,1,1,2,2,3,3,3]
scores = cross_val_score(logreg, X, y, groups = groups , cv = GroupKFold(n_splits=3))
print('교차 검증 점수 : \n',scores)
```

    교차 검증 점수 : 
     [0.75       0.6        0.66666667]


이미지4

출처(https://m.blog.naver.com/fbfbf1/222451319719)

### 7.5 반복 교차 검증
데이터셋의 크기가 크지 않은 경우 안정된 검증 점수를 얻기 위해 교차 검증을 반복해서 여러번 수행하는 경우가 많다. scikit-learn에서 제공하는 RepeatedKFold와 RepeatedStratifiedKFold 분할기를 이용하면 된다. 분할 폴드 수는 n_splits 매개변수로 설정하면 되고(기본값 5), 반복 횟수는 n_repeats 매개변수로 설정하면 된다(기본값 10). 분할기는 반복할 때마다 데이터를 다시 섞는다. iris 데이터셋으로 예를 들어보겠다.


```python
from sklearn.model_selection import RepeatedStratifiedKFold

rskfold = RepeatedStratifiedKFold(random_state=42)
scores = cross_val_score(logreg,iris.data,iris.target,cv=rskfold)

print('교차 검증 점수 : \n',scores) # n_splits x n_repeats 개수만큼 검증 점수 출력 (기본값은 5x10)
print('교차 검증 평균 점수 : {:.3f}'.format(scores.mean()))
```

    교차 검증 점수 : 
     [1.         0.96666667 0.93333333 1.         0.93333333 0.96666667
     0.96666667 0.93333333 1.         0.96666667 0.93333333 1.
     1.         0.96666667 0.96666667 0.9        1.         1.
     0.93333333 0.96666667 0.93333333 0.96666667 0.96666667 1.
     0.96666667 1.         0.96666667 0.96666667 0.9        1.
     0.96666667 0.96666667 0.96666667 0.96666667 0.93333333 0.96666667
     0.96666667 1.         1.         0.9        0.96666667 1.
     0.9        0.96666667 0.96666667 0.9        0.96666667 0.96666667
     1.         0.96666667]
    교차 검증 평균 점수 : 0.965


반복 교차 검증을 위한 이 두 분할기는 [**다음 글**](https://hamin-chang.github.io/basics/gridsearch/)에서 설명할 GridSearchCV의 cv매개변수에도 적용할 수 있다.

[<파이썬 라이브러리를 활용한 머신러닝:사이킷런 핵심개발자가 쓴 머신러닝과 데이터 과학 실무서>]을 학습하고 개인 학습용으로 정리한 내용입니다.]
```python

```
