---
layout: post
title:  "Your Working Space"
---

## AI model 
### Decoder Model 
* M.E
* Solar
  * LLaMA2 아키텍쳐럴 upsate에서 Depth Up-Scaling 기술을 이용하여 제작한 모델
* Mistral
  * Sliding window attention, Rolling Buffer Cache 등의 기술을 이용하여 제작한 모델
  * LLaMA2 13B 보다 좋은 성능
* LLaMA2
  * 메타에서 제작한 대규모 AI 언어모델로 LLaMA1 보다 더 많은 2조개의 토큰을 학습한 모델

### Encoder Model 
* Klue roberta large
  * 기존의 bert에서 학습 방식을 발전 시켜 만든 roberta 를 klue 데이터로 사전 학습 시킨 모델
* KcELECTRA base
  * 기존의 bert의 MLM 학습이 아닌 RTD 학습 방법은 채택한 ELECTRA를 온라인 뉴스와 댓글을 수집해 사전 학습 시킨 모델 


## AI Dataset 
### ASAP (Automated Student Assessment Prize) 
-> Kaggle 이 공유한 학생용 데이터셋 ASAP, ASAP-AES, ASAP-SAS, ASAP++

'''
'''

### ASAP 활용 AI 모델 
* 최단 경로 유사성, LSA 회귀 모델
* word-graph
* LSTM
* 분류모델
* 회귀모델
* CNN
* Bi-LSTM
* SVM 선형회귀
* RNN

### AI Hub 사용하기 
* <b>데이터셋 이용하기</b>
  * <b>한국 데이터셋 다운로드</b>
* AI 모델 이용하기
  * 딥러닝 모델 API 사용하기 - openAPI key 가 있는 경우
* 컴퓨팅 자원 신청하기

## 데이터셋 
### 과제 데이터셋의 국내 외 현황 
* 국내 현황
* 해외 현황


