---
published: true
layout: single
title: "[Machine Learning PerfectGuide] 정밀도/재현율 트레이드 오프"
category: mlbasic
tags:
comments: true
sidebar:
  nav: "mainMenu"
use_math: true
--- 
* * *

#### 정밀도/재현율 트레이드 오프
* * *
- 업무 특성상 정밀도 또는 재현율이 특별히 강조돼야 하는 경우 분류의 결정 임곗값(Threshold)을 조정해 정밀도 또는 재현율의 수치를 높일 수 있음.
- 정밀도와 재현율은 상호 보완적인 지표이기 때문에 어느 한쪽을 강제로 높이면 다른 하나의 수치는 떨어지기 쉬운데 이것을 정밀도/재현율의 트레이드 오프라고 함.

#### predict_proba()
* * *
- 일반적으로 이진 분류 모델에서는 임곗값을 50%로 정하고 이 기준보다 크면 Positive 작으면 Negative로 결정함.
- 사이킷런에서는 개별 데이터별로 예측 확률을 반환하는 메서드인 predict_proba()를 제공함.
- predict_proba()는 학습이 완료된 사이킷런 Classifier 객체에서 호출이 가능하며 테스트 피처 데이터 셋을 파라미터로 입력해주면 테스트 피처 레코드의 개별 클래스 예측 확률을 반환한다.
- predict_proba()는 m x n (m:입력 값의 레코드 수, n:클래스 값 유형) ndarray 형태로 반환함.
- 즉, 표본 개수가 100개이고 값 유형이 2개인 이진 분류라면 100 x 2 ndarray 가 반환됨.

  ```python
  pred_proba = lr_clf.predict_proba(X_test)
  pred = lr_clf.predict(X_test)
  print('pred_proba() 결과 Shape : {0}'.format(pred_proba.shape))
  print('pred_proba array에서 앞 3개만 샘플로 추출 \n:', pred_proba[:3])
  ```
  ```
  pred_proba() 결과 Shape : (179, 2)
  pred_proba array에서 앞 3개만 샘플로 추출 
  : [[0.39243346 0.60756654]
  [0.92787379 0.07212621]
  [0.92097003 0.07902997]]
  ```

#### 임계값 튜닝을 통해 정밀도/재현율 조절 
* * * 
- Binarizer 클래스 : fit_transform() 메서드에 input 값으로 m x n ndarray를 입력하면, 설정한 임곗값(threshold)보다 크면 1, 작거나 같을 경우 0인 값으로 치환한 m x n ndarray를 반환하는 클래스

  ```python
  from sklearn.preprocessing import Binarizer
  x = [ [1, -1, 2], [2, 0, 0], [0, 1.1, 1.2] ]

  binarizer = Binarizer(threshold = 1.1)
  print(binarizer.fit_transform(x))
  ```
  ```
  [ [0. 0. 1.]
    [1. 0. 0.]
    [0. 0. 1.] ]
  ```

<br>

- predict()가 predict_proba()에 기반함을 Binarizer 클래스를 이용하여 확인할 수 있음.

  ```python
  from sklearn.preprocessing import Binarizer

  # 임곗값은 디폴트 값인 0.5
  custom_threshold = 0.5
  # predict_proba()는 [negative에 대한 예측 확률, positive에 대한 예측 확률] 쌍 ndarray list를 반환 합니다
  # positive에 대한 예측 확률 ndarray를 reshape로 m x 1 2차원 ndarray 반환
  pred_proba_1 = pred_proba[:, 1].reshape(-1, 1)

  # 책에서는 Binarizer의 fit까지 사용 중인데, 레퍼런스 찾아보니 아무것도 하지 않고 estimator를 반환 합니다.
  # 여기서 estimator는 임곗값 0.5에 대해서 동작하는 이진 분류기
  binarizer = Binarizer(threshold=custom_threshold)

  # pred_proba_1에 있는 positive일 확률에 따라 0 또는 1로 이진 분류하여 custom_predict에 저장
  custom_predict = binarizer.transform(pred_proba_1)

  get_clf_eval(y_test, custom_predict)
  ```
  ```
  오차 행렬
  [[99 18]
  [15 47]]
  정확도:  0.8156, 정밀도:  0.7231, 재현율:  0.7581
  ```

<br>

- 임곗값을 낮추면 위 결과에서 재현율 값이 올라가고 정밀도가 떨어짐.
- 이유는 임곗값을 낮춘 만큼 positive로 분류하는 경우의 수가 많아져서 실제 positive가 아닌데도 positive로 분류하는 FP 늘어나고 반대로 FN은 줄어들기 때문.
- 반대로 임곗값을 높이면 정밀도가 올라가고 재현율이 떨어짐.
- 임곗값을 높인 만큼 negative로 분류하는 경우의 수가 많아져서 실제 negative가 아닌데도 negative로 분류하는 FN 늘어나고 반대로 FP는 줄어들기 때문.

<br>

- 적당한 임곗값을 찾기 위해 임곗값을 0.4부터 0.6까지 0.05씩 증가시키며 평가 지표를 조사해보기

  ```python
  def get_eval_threshold(y_test, pred_proba_c1, thresholds):
      for custom_threshold in thresholds:
          binarizer = Binarizer(threshold=custom_threshold)
          custom_predict = binarizer.transform(pred_proba_c1)
          print('임곗값 : ', custom_threshold)
          get_clf_eval(y_test, custom_predict)
          
  threadholds = [0.4, 0.45, 0.5, 0.55, 0.6]
  get_eval_threshold(y_test, pred_proba_1, threadholds)
  ```
  ```
  임곗값 :  0.4
  오차 행렬
  [[98 19]
  [13 49]]
  정확도:  0.8212, 정밀도:  0.7206, 재현율:  0.7903

  임곗값 :  0.45
  오차 행렬
  [[98 19]
  [15 47]]
  정확도:  0.8101, 정밀도:  0.7121, 재현율:  0.7581

  임곗값 :  0.5
  오차 행렬
  [[99 18]
  [15 47]]
  정확도:  0.8156, 정밀도:  0.7231, 재현율:  0.7581

  임곗값 :  0.55
  오차 행렬
  [[108   9]
  [ 17  45]]
  정확도:  0.8547, 정밀도:  0.8333, 재현율:  0.7258

  임곗값 :  0.6
  오차 행렬
  [[110   7]
  [ 21  41]]
  정확도:  0.8436, 정밀도:  0.8542, 재현율:  0.6613
  ```

<br>

- precision_recall_curve()를 사용하여 예측 모델의 임곗값별 정밀도와 재현율 구할 수 있음.
- 정밀도, 재현율, 임곗값을 ndarray로 반환함
- 임곗값은 일반적으로 0.11 ~ 0.95 정도의 ndarray이고 이 임곗값에 해당하는 정밀도 재현율 ndarray가 반환됨.
- input으로 실제 target(레이블) 값과 positive 예측 확률 값이 사용 됨.

  ```python
  from sklearn.metrics import precision_recall_curve

  # positive 일 예측 확률 추출
  pred_proba_class1 = lr_clf.predict_proba(X_test)[:, 1]

  precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_class1)
  print('반환된 분류 결정 임곗값 배열의 shape', thresholds.shape)

  # 임곗값이 157개로 너무 많으므로 15step으로 10건만 추출
  # 여기서 step이란 건수를 추출할 때 각 건수의 array index 차가 15라는 의미 
  # np.arange(시작 index, 끝 index, step)
  thr_index = np.arange(0, thresholds.shape[0], 15)
  print('샘플 추출을 위한 임곗값 배열의 index 10개 : ', thr_index)
  print('샘플용 10개의 임곗값 : ', np.round(thresholds[thr_index], 2))

  # 15 step 단위로 추출된 임곗값에 따른 정밀도와 재현율 값
  print('샘플 임곗값별 정밀도: ', np.round(precisions[thr_index], 3))
  print('샘플 임곗값 별 재현율: ', np.round(recalls[thr_index], 3))
  ```
  ```
  반환된 분류 결정 임곗값 배열의 shape (157,)

  샘플 추출을 위한 임곗값 배열의 index 10개 :  [0 15 30 45 60 75 90 105 120 135 150]
  샘플용 10개의 임곗값 :  [0.08 0.1 0.11 0.15 0.18 0.25 0.4 0.59 0.67 0.84 0.94]
  샘플 임곗값별 정밀도:  [0.38 0.415 0.454 0.504 0.566 0.651 0.721 0.83 0.919 1. 1. ]
  샘플 임곗값 별 재현율:  [1. 0.984 0.952 0.935 0.903 0.871 0.79 0.71 0.548 0.355 0.113]
  ```
<br>

- precision_recall_curve() Graph

  ```python
  import matplotlib.pylot as plt
  import matplotlib.ticker as ticker
  # %matplotlib inline
  # brief: notebook을 실행한 브라우저에서 plotting을 활성화하여
  #        Matplotlib으로 생성한 그래프, 그림을 바로 볼수 있게 해주는 것
  %matplotlib inline

  def precision_recall_curve_plot(y_test, pred_proba_c1)
    precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)

    # threshold 값으로 Y축은 정밀도, X축은 재현율 값으로 각각 Plot 수행, 정밀도는 점선으로 표시
    plt.figure(figsize=(8, 6))
    threshold_boundary = thresholds.shape[0]
    plt.plot(thresholds, precisions[0:threshold_boundary], linestyle='--', label='precision')
    plt.plot(thresholds, recalls[0:threshold_boundary], label='recall')

    # threshold 값 X축의 Scale을 0.1 단위로 변경

    # X축, Y축 label과 legend, 그리고 grid 설정
    plt.xlabel('Threshold value') # x축 레이블
    plt.ylabel('Precision and Recall value') # y축 레이블
    plt.legend() # 범례
    plt.grid()   # 격자
    plt.show()

  precision_recall_curve_plot(y_test, lr_clf.predict_proba(X_test)[:, 1])
  ```

#### 맹점
* * *
- Positive 예측의 임곗값을 변경함에 따라 정밀도와 재현율의 수치가 변경 됨.
- 그러나 이러한 변경은 정밀도와 재현율을 상호 보완할 수 있는 수준에서 이루어져야만하고 다른 성능 지표 수치를 높이기 위한 수단으로 사용해서는 안됨.
- **다음은 정밀도와 재현율을 극단적으로 높이는 방법이지만, 숫자 놀음에 불과한 방법 입니다.**

#### 정밀도를 100%로 만드는 방법
* * *
- 정말로 확실한 경우만 Positive로 예측하고 나머지는 모두 Negative로 예측하는 것, 즉 FP 값을 0으로 만드는 것. 이렇게 되면 정밀도는 1/(1+0)으로 100%가 됨.

#### 재현율을 100%로 만드는 방법
* * *
- 모든 환자를 Positive로 예측하는 것. FN 값이 0이 되므로 N/(N+0)으로 100%가 됨.

<body translate="no" oncontextmenu="return false" ondragstart="return false" onselectstart="return false">
  <div id="mouse_no" oncontextmenu="return false" ondragstart="return false" onselectstart="return false">
  </div>
</body>