---
layout: single
title:  "OpenCV chapter 3"
categories : OpenCV
tag : [python, OpenCV]
toc: true
toc_sticky: true

---

![header](https://capsule-render.vercel.app/api?type=waving&color=a2dcec&height=300&section=header&text=OpenCV chapter 3&fontSize=40&animation=fadeIn&fontAlignY=38&fontColor=FFFFFF)

- 참고 및 출처
  - [파이썬으로 만드는 OpenCV 프로젝트](https://github.com/dltpdn/insightbook.opencv_project_python)
  - [귀퉁이서재_opencv](https://bkshin.tistory.com/entry/OpenCV-1-%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9C%BC%EB%A1%9C-%EB%A7%8C%EB%93%9C%EB%8A%94-OpenCV-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8?category=1148027)

&nbsp;

## 목차

- 히스토그램과 정규화(Normalize), 평탄화(Equalization), CLAHE

- 2차원 히스토그램과 역투영(back project)

- 이미지 유사도 비교, 사람 얼굴과 해골 합성

&nbsp;

&nbsp;



## 7. 히스토그램과 정규화(Normalize), 평탄화(Equalization), CLAHE

&nbsp;

### 히스토그램

- 히스토그램은 도수 분포표를 그래프로 나타낸 것, 무엇이 몇 개 있는지 개수를 세어 놓은 것을 그래프로 나타낸 것 의미
- 이미지의 픽셀값을 히스토그램으로 표시하는 것은 이미지를 분석하는 데 도움을 줌
  - 전체 이미지에서 픽셀 값이 1인 픽셀이 몇 개이고, 2인 픽셀이 몇 개이고, 255인 픽셀이 몇 개인지까지 세는 것
  - 이를 통해 픽셀들의 색상이나 명암의 분포를 파악 가능

```python
cv2.calHist(img, channel, mask, histSize, ranges)

img: 이미지 영상, [img]처럼 리스트로 감싸서 전달
channel: 분석 처리할 채널, 리스트로 감싸서 전달 - 1 채널: [0], 2 채널: [0, 1], 3 채널: [0, 1, 2]
mask: 마스크에 지정한 픽셀만 히스토그램 계산, None이면 전체 영역
histSize: 계급(Bin)의 개수, 채널 개수에 맞게 리스트로 표현 - 1 채널: [256], 2 채널: [256, 256], 3 채널: [256, 256, 256]
ranges: 각 픽셀이 가질 수 있는 값의 범위, RGB인 경우 [0, 256]
```

&nbsp;

### 회색조 1채널 히스토그램


```python
# 이미지 그레이 스케일로 읽기 및 출력
img = cv2.imread('./mountain.jpg', cv2.IMREAD_GRAYSCALE)

fig, axes = plt.subplots(1,2)
plt.tight_layout(h_pad=0, w_pad=3)

axes[0].imshow(img,cmap='gray')


# 히스토그램 계산 및 그리기
hist = cv2.calcHist([img], [0], None, [256], [0,256])
axes[1].plot(hist)

print("hist.shape:", hist.shape)  # 히스토그램의 shape (256,1)
print("hist.sum():", hist.sum(), "img.shape:",img.shape) # 히스토그램 총 합계와 이미지의 크기
plt.show()

>> hist.shape: (256, 1)
    hist.sum(): 270000.0 img.shape: (450, 600)
```


![png](/images/2022-07-26-opencv3/output_164_1.png)
    


- 그레이 스케일 한 이미지를 1차원 히스토그램으로 표현한 결과
- range가 [0, 256] : 0~255 까지
- cv2.calcHist()로 반환한 hist 객체는 plt.plot(hist)을 통해 그래프로 출력가능

&nbsp;

### 색상 이미지 히스토그램


```python
#이미지 읽기 및 출력
img = cv2.imread('./mountain.jpg')

fig, axes = plt.subplots(1,2)
plt.tight_layout(h_pad=0, w_pad=3)

axes[0].imshow(img[:,:,::-1])

#히스토그램 계산 및 그리기
channels = cv2.split(img)

colors = ('b', 'g', 'r')
for (ch, color) in zip (channels, colors):
    hist = cv2.calcHist([ch], [0], None, [256], [0, 256])
    axes[1].plot(hist, color = color)
plt.show()
```

![png](/images/2022-07-26-opencv3/output_167_0.png)
​    


- cv2.split(img) 함수를 호출하면 R, G, B 채널이 각각 나눔
- img는 색상 이미지이므로 3 채널 이미지인데, cv2.split(img)을 해주면 빨강, 파랑, 초록의 각 1 채널 이미지로 나눔
- 히스토그램을 보면 파란색 분포가 큰 것을 알 수 있음, 파란색 하늘 영역이 많아서

&nbsp;

### 정규화(Normalization)

- 특정 영역에 몰려 있는 경우 화질을 개선하기도 하고, 이미지 간의 연산 시 서로 조건이 다른 경우 같은 조건으로 만들기도 가능
- OpenCV는 cv2.normalize()라는 함수로 정규화를 제공

```python
dst = cv2.normalize(src, dst, alpha, beta, type_flag)

src: 정규화 이전의 데이터
dst: 정규화 이후의 데이터
alpha: 정규화 구간 1
beta: 정규화 구간 2, 구간 정규화가 아닌 경우 사용 안 함
type_flag: 정규화 알고리즘 선택 플래그 상수
```


- type_flag
  - alpha와 beta 구간으로 정규화하는 cv2.NORM_MINMAX
  - 전체 합으로 나누는 cv2.NORM_L1
  - 단위 벡터로 정규화하는 cv2.NORM_L2
  - 최댓값으로 나누는 cv2.NORM_INF

&nbsp;

### 히스토그램 정규화


```python
# 그레이 스케일로 영상 읽기
real = cv2.imread('./abnormal.jpg')
img = cv2.imread('./abnormal.jpg', cv2.IMREAD_GRAYSCALE)

# 직접 연산한 정규화
img_f = img.astype(np.float32)
img_norm = ((img_f - img_f.min()) * (255) / (img_f.max() - img_f.min()))
img_norm = img_norm.astype(np.uint8)

# OpenCV API를 이용한 정규화
img_norm2 = cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)

# 히스토그램 계산
hist = cv2.calcHist([img], [0], None, [256], [0, 255])
hist_norm = cv2.calcHist([img_norm], [0], None, [256], [0, 255])
hist_norm2 = cv2.calcHist([img_norm2], [0], None, [256], [0, 255])



imgs = {'Before' : real, 'Manual' : img_norm, 'cv2.normalize()' : img_norm2}
plt.figure(figsize=(20, 10))
for i, (k, v) in enumerate(imgs.items()):
    plt.subplot(1,3, i + 1)
    plt.tight_layout(h_pad=0, w_pad=3)
    
    if i == 0:
        plt.imshow(v)
    else:
        plt.imshow(v,cmap='gray') # BGR -> RGB
    plt.title(k)
    plt.xticks([]); plt.yticks([])

plt.show()

hists = {'Before' : hist, 'Manual':hist_norm, 'cv2.normalize()':hist_norm2}
plt.figure(figsize=(20, 10))
for i, (k, v) in enumerate(hists.items()):
    plt.subplot(1,3,i+1)
    plt.tight_layout(h_pad=0, w_pad=3)
    plt.title(k)
    plt.plot(v)
plt.show()
```

![png](/images/2022-07-26-opencv3/output_172_0.png)
​    


![png](/images/2022-07-26-opencv3/output_172_1.png)
    


- 왼쪽 : 원본이미지
- 가운데 : 공식 수동으로 계산한 정규화 이미지
- 오른쪽 cv2.normalize() 함수를 활용하여 정규화한 이미지


- 정규화 전에는 픽셀 값이 중앙에 몰려있음, 정규화 적용하면 픽셀 값이 전체적으로 고르게 퍼져서 화질이 개선됨

&nbsp;

### 평탄화(Equalization)

- 정규화는 분포가 한곳에 집중되어 있는 경우에는 효과적
- 집중된 영역에서 멀리 떨어진 값이 있을 경우에는 효과가 없음
- 평탄화는 각각의 값이 전체 분포에 차지하는 비중에 따라 분포를 재분배하므로 명암 대비를 개선하는 데 효과적
- 이미지의 히스토그램이 특정 영역에 너무 집중되어 있으면 명암 대비가 낮아 좋은 이미지라고 할 수 없음
- 특정 영역에 집중되어 있는 분포를 골고루 분포하도록 하는 작업을 히스토그램 평탄화(Histogram Equalization)라고 함


```python
dst = cv2.equalizeHist(src, dst)

src: 대상 이미지, 8비트 1 채널
dst(optional): 결과 이미지
```

&nbsp;

### 회색조 이미지에 평탄화 적용


```python
# 대상 영상으로 그레이 스케일로 읽기
img = cv2.imread('./yate.jpg', cv2.IMREAD_GRAYSCALE)
rows, cols = img.shape[:2]

# 이퀄라이즈 연산을 직접 적용
hist = cv2.calcHist([img], [0], None, [256], [0, 256])  #히스토그램 계산
cdf = hist.cumsum()                                     # 누적 히스토그램 
cdf_m = np.ma.masked_equal(cdf, 0)                      # 0(zero)인 값을 NaN으로 제거
cdf_m = (cdf_m - cdf_m.min()) /(rows * cols) * 255      # 이퀄라이즈 히스토그램 계산
cdf = np.ma.filled(cdf_m,0).astype('uint8')             # NaN을 다시 0으로 환원
print(cdf.shape)
img2 = cdf[img]                                         # 히스토그램을 픽셀로 맵핑

# OpenCV API로 이퀄라이즈 히스토그램 적용
img3 = cv2.equalizeHist(img)

# 이퀄라이즈 결과 히스토그램 계산
hist2 = cv2.calcHist([img2], [0], None, [256], [0, 256])
hist3 = cv2.calcHist([img3], [0], None, [256], [0, 256])

# 결과 출력

imgs = {'Before' : img, 'Manual' : img2, 'cv2.equalizeHist()' : img3}
plt.figure(figsize=(20, 10))
plt.tight_layout(h_pad=0, w_pad=3)
for i, (k, v) in enumerate(imgs.items()):
    plt.subplot(1,3, i + 1)
    plt.imshow(v,cmap='gray') # BGR -> RGB
    plt.title(k)
    plt.xticks([])
    plt.yticks([])

plt.show()



hists = {'Before':hist, 'Manual':hist2, 'cv2.equalizeHist()':hist3}
plt.figure(figsize=(20, 5))
plt.tight_layout(h_pad=0, w_pad=3)
for i, (k, v) in enumerate(hists.items()):
    plt.subplot(1,3,i+1)
    plt.title(k)
    plt.plot(v)
plt.show()
```


![png](/images/2022-07-26-opencv3/output_177_1.png)


![png](/images/2022-07-26-opencv3/output_177_2.png)
    


- 명암 대비가 낮은 부둣가 이미지의 화질이 개선됨
- 원본 이미지와 비교했을때 전체적으로 선명한 것을 확인할수 있음

&nbsp;

### 색상 이미지에 대한 평탄화 적용


```python
img = cv2.imread('./yate.jpg') #이미지 읽기, BGR 스케일

# 컬러 스케일을 BGR에서 YUV로 변경
img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV) 

# YUV 컬러 스케일의 첫번째 채널에 대해서 이퀄라이즈 적용
img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0]) 

# 컬러 스케일을 YUV에서 BGR로 변경
img2 = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR) 


fig, axes = plt.subplots(1,2,figsize=(20, 10))
axes[0].imshow(img[:,:,::-1])
axes[1].imshow(img2[:,:,::-1])

axes[0].set_title("Before")
axes[1].set_title("After")
plt.show()
```

​    ![png](/images/2022-07-26-opencv3/output_180_0.png)
​    


- 평탄화 적용 전(왼쪽 이미지) 보다 적용 후(오른쪽 이미지)가 더 선명
- 밝기가 더 개선되어 화질이 좋아진 것을 확인할수있음

&nbsp;

### CLAHE (Contrast Limited Adaptive Histogram Equalization)

- 평탄화를 하면 이미지의 밝은 부분이 날아가는 현상이 발생
- 이미지의 밝은 부분이 날라가는 현상을 막기 위해 이미지를 일정한 영역으로 나누어 평탄화를 적용
  - 일정한 영역 내에서 극단적으로 어둡거나 밝은 부분이 있으면 노이즈가 생겨 원하는 결과를 얻을 수 없음
- 어떤 영역이든 지정된 제한 값을 넘으면 그 픽셀은 다른 영역에 균일하게 배분하여 적용, 이러한 평탄화 방식을 CLAHE


```python
clahe = cv2.createCLAHE(clipLimit, tileGridSize)

clipLimit: 대비(Contrast) 제한 경계 값, default=40.0
tileGridSize: 영역 크기, default=8 x 8
clahe: 생성된 CLAHE 객체
```

```python
clahe.apply(src): CLAHE 적용

src: 입력 이미지
```

&nbsp;


```python
# 이미지 읽어서 YUV 컬러스페이스로 변경
img = cv2.imread('./bright.jpg')
img_yuv = cv2.cvtColor(img, cv2.COLOR_BGR2YUV)

# 밝기 채널에 대해서 이퀄라이즈 적용
img_eq = img_yuv.copy()
img_eq[:,:,0] = cv2.equalizeHist(img_eq[:,:,0])
img_eq = cv2.cvtColor(img_eq, cv2.COLOR_YUV2BGR)

# 밝기 채널에 대해서 CLAHE 적용
img_clahe = img_yuv.copy()
clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8)) #CLAHE 생성
img_clahe[:,:,0] = clahe.apply(img_clahe[:,:,0])           #CLAHE 적용
img_clahe = cv2.cvtColor(img_clahe, cv2.COLOR_YUV2BGR)

# 결과 출력

fig, axes = plt.subplots(1,3,figsize=(20, 10))
axes[0].imshow(img[:,:,::-1])
axes[1].imshow(img_clahe[:,:,::-1])
axes[2].imshow(img_eq[:,:,::-1])

axes[0].set_title("Before")
axes[1].set_title("CLAHE")
axes[2].set_title("equalizeHist")
plt.show()
```

  ![png](/images/2022-07-26-opencv3/output_184_0.png)
​    


- 오른쪽의 단순한 평탄화를 적용하면 밝은 부분은 날아가는 현상이 발생
- CLAHE를 적용할 땐 이러한 현상이 개선되고 선명해짐



&nbsp;

## 8. 2차원 히스토그램과 역투영(back project)

&nbsp;

### 2차원 히스토그램 (2D Histogram)

- 1차원 히스토그램은 이미지 안에 픽셀이 각각 몇 개인지를 표현
- 2차원 히스토그램은 축이 2개이고, 각 축이 만나는 지점의 개수를 표현

&nbsp;

### 2D 히스토그램


```python
plt.style.use('classic')            # 컬러 스타일을 1.x 스타일로 사용
img = cv2.imread('./mountain.jpg')
plt.figure(figsize=(20, 10))
plt.tight_layout(h_pad=0, w_pad=3)


plt.subplot(131)
hist = cv2.calcHist([img], [0,1], None, [32,32], [0,256,0,256]) 
p = plt.imshow(hist)                                           
plt.title('Blue and Green')                                   
plt.colorbar(p)                                              


plt.subplot(132)
hist = cv2.calcHist([img], [1,2], None, [32,32], [0,256,0,256]) 
p = plt.imshow(hist)
plt.title('Green and Red')
plt.colorbar(p)

plt.subplot(133)
hist = cv2.calcHist([img], [0,2], None, [32,32], [0,256,0,256])
p = plt.imshow(hist)
plt.title('Blue and Red')
plt.colorbar(p)

plt.show()
```

  ![png](/images/2022-07-26-opencv3/output_190_0.png)
​  

&nbsp;


### 역투영(Back Projection)

- 관심 영역의 히스토그램과 유사한 히스토그램을 갖는 영역을 찾아내는 기법
- 역투영을 활용하면 이미지 내에서 특정 물체나 배경을 분리할 수 있음
- 색상을 기준으로 분리하기 때문에 잔디와 비슷한 색상을 가진 다른 물체가 있는 경우 성능이 떨어짐

&nbsp;

### 마우스로 선택한 영역의 물체 분리하기


```python
win_name = 'back_projection'
img = cv2.imread('./pump_horse.jpg')
hsv_img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
draw = img.copy()
fig, axes = plt.subplots(1,2)
plt.tight_layout(h_pad=0, w_pad=3)

# 역투영된 결과를 마스킹해서 결과를 출력하는 공통함수
def masking(bp, win_name):
    disc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))
    cv2.filter2D(bp,-1,disc,bp)
    _, mask = cv2.threshold(bp, 1, 255, cv2.THRESH_BINARY)
    result = cv2.bitwise_and(img, img, mask=mask)
    cv2.imshow(win_name, result)
    axes[1].imshow(result)

# OpenCV API로 구현한 함수
def backProject_cv(hist_roi):
    # 역투영 함수 호출 
    bp = cv2.calcBackProject([hsv_img], [0, 1], hist_roi,  [0, 180, 0, 256], 1)
    # 역 투영 결과로 마스킹해서 결과 출력 
    masking(bp,'result_cv')

# ROI 선택 
(x,y,w,h) = cv2.selectROI(win_name, img, False)
if w > 0 and h > 0:
    roi = draw[y:y+h, x:x+w]
    # 빨간 사각형으로 ROI 영역 표시
    cv2.rectangle(draw, (x, y), (x+w, y+h), (0,0,255), 2)
    # 선택한 ROI를 HSV 컬러 스페이스로 변경
    hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)
    # H,S 채널에 대한 히스토그램 계산
    hist_roi = cv2.calcHist([hsv_roi],[0, 1], None, [180, 256], [0, 180, 0, 256] )
    # ROI의 히스토그램을 매뉴얼 구현함수와 OpenCV 이용하는 함수에 각각 전달
    backProject_cv(hist_roi)
    
cv2.imshow(win_name, draw)
axes[0].imshow(draw)
cv2.waitKey()
cv2.destroyAllWindows()


axes[0].set_title('Before')
axes[1].set_title('After') 
axes[0].set_xticks([]) 
axes[0].set_yticks([]) 
axes[1].set_xticks([]) 
axes[1].set_yticks([]) 


plt.show()
```

  ![png](/images/2022-07-26-opencv3/output_194_0.png)
​    


- 마우스로 관심영역을 선택한 뒤, 관심 영역에 해당하는 물체만 추출
- 관심 영역을 HSV 형식으로 변경한 뒤 H, S 채널에 대한 2차원 히스토그램 생성
- 히스토그램을 OpenCV 함수의 파라미터로 전달

```python
cv2.calcBackProject(img, channel, hist, ranges, scale) -> 역투영을 직접 구현한 함수

img: 입력 이미지, [img]처럼 리스트로 감싸서 사용
channel: 처리할 채널, 리스트로 감싸서 사용
hist: 역투영에 사용할 히스토그램
ranges: 각 픽셀이 가질 수 있는 값의 범위
scale: 결과에 적용할 배율 계수
```

&nbsp;


- cv2.getStructuringElement()와 cv2.filter2D()는 마스크의 표면을 부드럽게 해주는 역할 수행


```python 
cv2.getStructuringElement(shape, ksize[,anchor]) -> 모폴로지( 영상을 형태학적인 측면으로 접근하는 것) 구조 요소를 생성해주는 함수

shape : 구조화 요소 커널의 모양
    - cv2.MORPH_CROSS : 십자가형
    - cv2.MORPH_ELLIPSE : 타원형
    - cv2.MORPH_RECT : 직사각형
Ksize : 구조화 요소 커널의 크기
anchor : 구조화 요소 커너르이 기준점, default = (-1,-1)은 기준점을 중심으로 잡음
```

&nbsp;

```python
cv2.filter2D(src, ddepth, kernel, dst=None, anchor=None, delta=None, borderType=None) -> 기본적인 2D 필터링 수행시 사용

src : 입력 영상
ddepth : 출력 영상 데이터 타입. (e.g) cv2.CV_8U, cv2.CV_32F, cv2.CV_64F, -1을 지정하면 src와 같은 타입의 dst 영상을 생성합니다.
kernel: 필터 마스크 행렬. 실수형.
anchor: 고정점 위치. (-1, -1)이면 필터 중앙을 고정점으로 사용
delta: 추가적으로 더할 값
borderType: 가장자리 픽셀 확장 방식
dst: 출력 영상
```

&nbsp;

### 역투영 장단점

- 알파 채널이나 크로마 키 같은 것이 없어도 복잡한 모양의 사물을 분리할 수 있다는 장점
- 역투영은 히스토그램을 기반으로 관심 영역의 색상과 비슷한 물체를 추출하므로, 관심 영역의 색상과 비슷한 다른 물체가 뒤섞여 있을 때는 효과가 떨어짐

&nbsp;

## 9. 이미지 유사도 비교, 사람 얼굴과 해골 합성

&nbsp;

### 이미지 유사도 비교 실습

- 픽셀 값의 분포가 서로 비슷하다면 유사한 이미지일 확률이 높고, 분포가 서로 다르다면 서로 다른 이미지일 확률이 높음
  --> 이러한 사실을 이용하여 이미지의 유사도를 측정가능, 두 이미지의 히스토그램을 비교하면 되는 것


```python
cv2.compareHist(hist1, hist2, method)

hist1, hist2: 비교할 두 개의 히스토그램, 크기와 차원이 같아야 함
method: 비교 알고리즘
    - cv2.HISTCMP_CORREL: 상관관계 (1: 완전 일치, -1: 완전 불일치, 0: 무관계)
    - cv2.HISTCMP_CHISQR: 카이제곱 (0: 완전 일치, 무한대: 완전 불일치)
    - cv2.HISTCMP_INTERSECT: 교차 (1: 완전 일치, 0: 완전 불일치 - 1로 정규화한 경우)
```

&nbsp;

### 히스토그램 유사도 비교 


```python
img1 = cv2.imread('./taekwonv1.jpg')
img2 = cv2.imread('./taekwonv2.jpg')
img3 = cv2.imread('./taekwonv3.jpg')
img4 = cv2.imread('./dr_ochanomizu.jpg')

imgs = [img1, img2, img3, img4]
hists = []
for i, img in enumerate(imgs) :
    plt.subplot(1,len(imgs),i+1)
    plt.title('img%d'% (i+1))
    plt.axis('off') 
    plt.imshow(img[:,:,::-1])
    
    # 각 이미지를 HSV로 변환
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    
    # H,S 채널에 대한 히스토그램 계산
    hist = cv2.calcHist([hsv], [0,1], None, [180,256], [0,180,0, 256])
    
    # 0~1로 정규화
    cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)
    hists.append(hist)

query = hists[0]
methods = {'CORREL' :cv2.HISTCMP_CORREL, 'CHISQR':cv2.HISTCMP_CHISQR, 
           'INTERSECT':cv2.HISTCMP_INTERSECT,
           'BHATTACHARYYA':cv2.HISTCMP_BHATTACHARYYA}

for j, (name, flag) in enumerate(methods.items()):
    print('%-10s'%name, end='\t')
    for i, (hist, img) in enumerate(zip(hists, imgs)):
        
        # 각 메서드에 따라 img1과 각 이미지의 히스토그램 비교
        ret = cv2.compareHist(query, hist, flag)
        
        if flag == cv2.HISTCMP_INTERSECT: #교차 분석인 경우 
            ret = ret/np.sum(query)        #비교대상으로 나누어 1로 정규화
        print("img%d:%7.2f"% (i+1 , ret), end='\t')
    print()
plt.show()

>> CORREL    	img1:   1.00	img2:   0.70	img3:   0.56	img4:   0.23	
    CHISQR    	img1:   0.00	img2:  67.33	img3:  35.71	img4:1129.49	
    INTERSECT 	img1:   1.00	img2:   0.54	img3:   0.40	img4:   0.18	
    BHATTACHARYYA	img1:   0.00	img2:   0.48	img3:   0.47	img4:   0.79	
```


![png](/images/2022-07-26-opencv3/output_202_1.png)
    


- 각 이미지를 HSV 형식으로 변환한 뒤 H, V에 대하여 2차원 히스토그램을 계산해 정규화 수행
- query에 img1의 정규화된 히스토그램 할당
- compareHist로 query에 들어있는 img1의 히스토그램과 img1~4까지 비교수행
- img1이 원본과 동일, img4가 가장 비슷하지 않음

- 보통의 compareHist의 flag들은 정규화한 이미지를 원본과 비교하지만, cv2.HISTCMP_INTERSECT인 경우 원본 히스토그램으로 나누어주면 정규화가 되어 결과를 판별하기가 쉬워짐

&nbsp;

### 사람 얼굴과 해골 합성


```python
# 영상의 15%를 알파 블렌딩의 범위로 지정
alpha_width_rate = 15
fig, axes = plt.subplots(1,2)
plt.tight_layout(h_pad=0, w_pad=3)


# 합성할 두 영상 읽기
img_face = cv2.imread('./man_face.jpg')
img_skull = cv2.imread('./skull.jpg')

# 입력 영상과 같은 크기의 결과 영상 준비
img_comp = np.zeros_like(img_face)

# 연산에 필요한 좌표 계산
height, width = img_face.shape[:2]
middle = width//2                             # 영상의 중앙 좌표
alpha_width = width * alpha_width_rate // 100 # 알파 블렌딩 범위
start = middle - alpha_width//2               # 알파 블렌딩 시작 지점
step = 100/alpha_width                        # 알파 값 간격

# 입력 영상의 절반씩 복사해서 결과 영상에 합성
img_comp[:, :middle, : ] = img_face[:, :middle, :].copy()
img_comp[:, middle:, :] = img_skull[:, middle:, :].copy()

axes[0].imshow(img_comp[:,:,::-1])
axes[0].set_title('half')

# 알파 값을 바꾸면서 알파 블렌딩 적용
for i in range(alpha_width+1 ):
    alpha = (100 - step * i) / 100  # 증감 간격에 따른 알파 값 (1~0)
    beta = 1 - alpha                # 베타 값 (0~1)
    # 알파 블렌딩 적용
    img_comp[:, start+i] = img_face[:, start+i] * \
                                alpha + img_skull[:, start+i] * beta
    # print(i, alpha, beta)

axes[1].imshow(img_comp[:,:,::-1])
axes[1].set_title('half skull') 

axes[0].set_xticks([]) 
axes[0].set_yticks([]) 
axes[1].set_xticks([]) 
axes[1].set_yticks([]) 


plt.show()
```

![png](/images/2022-07-26-opencv3/output_205_0.png)
​    


- 위 코드에서 man_face 만큼의 빈 공간 img_comp 생성
- img_comp의 절반을 나눠 남자,해골 붙이기
- alpha,beta 조절하면서 알파 블렌딩 사용
- 부드럽게 합성됨