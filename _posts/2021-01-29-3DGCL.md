---
layout: single
title: "graph contrastive using schnet"
---

# Abstract
새로운 3D contrastive 방법으로 학습을 하니 supervised 보다 성능이 좋아졌다.
pretrain data도 자기꺼만 사용하니 많이 필요없고 모델도 무겁지 않다.

최근 molecule 분야에 self-supervised 방법이 널리 사용되고 있다. label이 없는 데이터를 활용하여 data 자체의 supervision을 통해 데이터의 representation을 학습하는 방법.

기존 방법의 문제점
1) SSL시 molecule의 구조를 변경함. 분자는 이미지와 달리 단순 변환이라도 완전히 다른 특성을 초래할 수 있음.
2) 매우 많은 pretrain 데이터 사용
3) 매우 많은 모델 파라미터 사용
4) 3D 구조를 반영하지 못함

novelty
1) molecule의 성질을 유지시키면서 contrastive learning 하는 새로운 방법 (conformer, rotation, noise)
2) pretrain data로 자신만 사용
3) 적은 파라미터 사용
4) 3D 구조 활용

result
supervised 보다 pretrain 했을 경우 성능이 뛰어남. 우리의 방법이 분자 표현을 학습하는데에 적합한 방법임.


# 1. Introduction

# 2. Related Work

Schnet
1. **cutoff** 기반의 GNN
2. orthogonal function (**Gaussian function**)을 사용한 distance embedding
3. 3D 공간에 적합한 **continuous-filter** convolution 사용

SimCLR:

GraphCL: 
- Augmentation: Node dropping, Edge perturbation, Attribute masking, Subgraph
- Pretrain data: 456K from ChEMBL
- 

3D informax:

GeomGCL: 

MolCLR: 

GROVER: Transformer, 2D, **a very large number of parameters**

MoCL: 

MICRO-graph: 

MolCLE: 

ChemBERTa: 


# 3. Method

# 4. Experiments
|Dataset | BBBP  | BBBP  |ClinTox| SIDER | SIDER | BACE |
|  ---   |  ---  |  ---  |  ---  |  ---  | ---   | ---   |
|cutoff  | 5.0   | 8.0   | 5.0   | 5.0   | 8.0   | ---   |
|layers  | 2     | 3     | 3     | 2     | 3     | ---   |
|z_dim   | 512   | 512   | 256   | 512   | 256   | ---   |
|dropout | 0.2   | 0.0   | 0.2   | 0.2   | 0.0   | ---   |
|Super   | 0.85  | 0.898 | 0.804 | 0.579 | 0.608 | ---   |
|Pretrain| 0.867 | 0.915 |       | 0.585 |       | ---   |
<br />

|Dataset|ESOL|Freesolv|
|---|---|---|
|cutoff  | 5.0   | 5.0   |
|layers  | 2     | 2     |
|z_dim   | 512   | 512   |
|dropout | 0.2   | 0.2   | 
|Super   | 1.079 | 2.005 |   
|Pretrain| 0.82  |    |   
<br />

|Augmentation|ETKDG|Rotation|Noise|Atom Dropping|Attribute Masking|
|---|---|---|---|---|---|
|ETKDG             | 0.867 | 0.867 | 0.867 | 0.867 |
|Rotation          | 0.867 | 0.867 | 0.867 | 0.867 |
|Noise             | 0.867 | 0.867 | 0.867 | 0.867 |
|Atom Dropping     | 0.867 | 0.867 | 0.867 | 0.867 |
|Attribute Masking | 0.867 | 0.867 | 0.867 | 0.867 |




# 5. Conclusion



# Reference
SimCLR


# 3줄 요약
1. **Schnet** 기반의 encoder
2. orthogonal function (**Gaussian function**)을 사용한 distance embedding
3. 3D GNN에 적합한 **contrastive learning** 방법 제시

<br />
