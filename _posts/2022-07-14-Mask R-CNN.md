---
layout: single
title:  "Mask R-CNN 논문 리뷰"
categories : paper
tag : [Mask R-cnn, Segmentation, 논문리뷰, 딥러닝]
toc: true
toc_sticky: true
---

![header](https://capsule-render.vercel.app/api?type=waving&color=a2dcec&height=300&section=header&text=Mask R-CNN 논문 리뷰&fontSize=40&animation=fadeIn&fontAlignY=38&fontColor=FFFFFF)

- 논문 링크 : [Mask R-CNN](https://arxiv.org/pdf/1703.06870.pdf)

&nbsp;

# 요약

----------------------------------------------------------------



- Mask R-CNN은 일반적으로detection task보다는 instance segmentation task에서 주로 사용
    - Instance segentation
        - 이미지 내에 존재하는 모든 객체를 탐지하는 동시에 각각의 경우를 정확하게 픽셀 단위로 분류하는 task
        - 객체를 탐지하는 object detection task와 각각의 픽셀의 카테고리를 분류하는 semantic segmentation task가 결합된 것
    
    ![Untitled](/images/2022-07-14-Mask R-CNN/Untitled.png)
    
    - 위 그림을 보면 Semantic segmentation과 Instance segmentation의 차이를 확인할수있음
        - 객체도 잡히고 배경도 그대로

![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%201.png)

- Mask R-CNN은 Faster R-CNN의 RPN에서 얻은 RoI(Region of Interest)에 대하여 객체의 class를 예측하는 classification branch, bbox regression을 수행하는 bbox regression branch와 평행으로 segmentation mask를 예측하는 mask branch를 추가한 구조
    - mask branch는 각각의 RoI에 작은 크기의 FCN(Fully Convolutional Network)가 추가된 형태
- segmentation task를 보다 효과적으로 수행하기 위해 논문에서는 객체의 spatial location을 보존하는 RoIAlign layer를 추가



&nbsp;

# Mask R-CNN 핵심

-------------------------------------------------------------

- Mask branch
- RoIAlign
- Loss function
- Training
- Inference



&nbsp;

## Mask branch

![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%202.png)

- Faster R-CNN은 backbone network를 통해 얻은 feature map을 RPN에 입력하여 RoI 생성
- RoI pooling을 통해 고정된 크기의 feature map을 얻고 이를 fc layer에 입력한 후classification branch와 bbox regression branch에 입력하여 class label과 bbox offset이라는 두 가지 결과를 예측

&nbsp;

![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%203.png)

- Mask R-CNN은 두 branch와 **평행으로** segmentation mask를 예측하는 **mask branch**가 추가된 구조
- RoI pooling을 통해 얻은 고정된 크기의 feature map을 mask branch에 입력하여 segmentation mask 획득
    - segmentation mask는 class에 따라 분할된 이미지 조각을 의미
- segmentation task는 픽셀 단위로 class를 분류해야 하기 때문에 detection task보다 더 정교한 spatial layout를 필요로 함
    - spatial layout : 공간에 대한 배치 정보
    - 이를 위해 mask branch는 여러 개의 conv layer로 구성된 작은 **FCN**의 구조됨
- class label이나 bbox offset이 fc layer에 의해 output vector로 붕괴되는 것과 달리 mask는 이미지 내 객체에 대한 공간 정보를 효과적으로 encode하는 것이 가능

&nbsp;

![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%204.png)

- mask branch는 각각의 RoI에 대하여 class별로 binary mask를 출력
    - mask prediction이 classfication branch에 의존하는 기존의 방식과는 반대
    - 기존의 instance segmentation 모델은 하나의 이미지에서 여러 class를 예측한 반면, Mask R-CNN은 class별로 mask를 생성한 후 픽셀이 해당 class에 해당하는지 여부를 표시
    - mask branch와 classification branch를 분리 ****시킨다는 것을 의미
    
    —> 두 branch를 결합하는 방식을 사용할 경우 성능이 크게 하락
    
- mask branch는 최종적으로 ![image-20220714155524095](/images/2022-07-14-Mask R-CNN/image-20220714155524095.png) 크기의 feature map을 출력
    - m = feature map의 크기
    - K = class의 수

&nbsp;

## RoIAlign

- RoI pooling을 사용하면 입력 이미지 크기와 상관없이 고정된 크기의 feature map을 얻을 수 있다는 장점 가짐
- RoI pooling으로 인해 얻은 feature와 RoI 사이가 어긋나는 misalignment가 발생한다고 주장
    - 이러한 어긋남은 pixel mask를 예측하는데 매우 안 좋은 영향

![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%205.png)

- RoI pooling에 앞서 RPN을 통해 얻은 RoI를 backbone network에서 추출한 feature map의 크기에 맞게 투영하는 과정 존재
- 위는 RoI의 크기는 145x200이며, feature map은 16x16, sub sampling ratio(=32)에 맞게 나눠주면 projection을 수행한 feature map은 4.53 x 6.25크기가짐
- 픽셀 미만의 크기로 분할하는 것은 불가능하기 때문에 크기를 각각 반올림하여 4x6 크기의 feature map 생성
- 3x3 크기의 고정된 feature map을 얻기 위해 4x6 크기의 RoI에 대하여 RoI pooling
  을 수행
    - 고정된 크기에 맞추기 위해 stride는 1x2로 설정, 최종적으로 3x3 크기의 feature map 생성

&nbsp;

![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%206.png)

- RoI pooling 방식이 quantization과정을 수반하여 misalignment를 유도 함
    - quantization : 실수 입력값을 정수와 같은 이산 수치으로 제한하는 방법
- 위의 그림은 RoI pooling 시 quantization으로 인해 소실되는 정보 보여줌
- 왼쪽 그림을 통해 RoI projection을 수행하는 과정에서 소수점 부분이 반올림 되면서 초록색과 파란색 영역에 대한 정보가 손실됨
- 오른쪽 그림은 RoI pooling 시 stride를 반올림하게 되면서 feature map의 마지막 row에 대한 정보가 소실됨
- quantization으로 인한 misalignment는 translation invariant한 classification task 시에는 큰 영향이 없지만 pixel 단위로 mask를 예측하는 segmentation task 시에는 매우 안 좋은 영향을 줌
    - 논문에서는 이러한 문제를 해결하기 위해 각각의 RoI에 대하여 RoIAlign
     방법을 적용

&nbsp;

- RoIAlign 동작 순서

    ![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%207.png)

    1. RoI projection을 통해 얻은 feature map을 quantization 과정 없이 그대로 사용, 그 다음 출력하고자 하는 feature map의 크기에 맞게 projection된 feature map을 분할
        - 위의 예시에서는 3x3 크기의 feature map으로 출력할 것이기 때문에 width, height를 각각 3등분함
    2. 분할된 하나의 cell에서 4개의 sampling point을 찾음
        - cell의 height, width를 각각 3등분하는 점에 해당
    3. Bilinear interpolation을 적용
        - Bilinear interpolation
          
            ![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%208.png)
            
            - Bilinear interpolation은 2차원 좌표 상에서 두 좌표가 주어졌을 때 중간에 있는 값을 추정하는 방법
            
            ![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%209.png)
            
            - ![image-20220714155610579](S/images/2022-07-14-Mask R-CNN/image-20220714155610579.png) 는 2번 과정에서 얻은 4개의 sampling point의 좌표
            - ![image-20220714155630182](/images/2022-07-14-Mask R-CNN/image-20220714155630182.png)는 sampling point에 인접한 cell의 값
            - 위의 공식에 따라 입력된 feature의 각각의 RoI bin의 4개의 sampled location의 값을 연산
            - 각각 연산(더블 클릭하면 더욱 잘보입니다.)
              
              
                ![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%2010.png)
                
                ![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%2011.png)
                
                ![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%2012.png)
        
    4. 2번~3번 과정을 모든 cell에 대하여 반복(이렇게 하면 하나의 cell 에 4개의 sampling point 생성)
       
        ![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%2013.png)
        
    5. 하나의 cell에 있는 4개의 sampling point에 대하여 max pooling을 수행

- RoIAlign 방법을 통해 feature와 RoI 사이가 어긋나는 misalignment 문제를 해결

- 이를 통해 RoI의 정확한 spatial location을 보존하는 것이 가능, mask accuracy가 크게 향상
    - spatial location : 물리적으로 위치한 위치를 설명하는 좌표

&nbsp;

## Loss function

![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%2014.png)

- ![image-20220714155655039](/images/2022-07-14-Mask R-CNN/image-20220714155655039.png) : classification loss (= Faster R-CNN과 동일)
- ![image-20220714155727484](/images/2022-07-14-Mask R-CNN/image-20220714155727484.png) : bounding box loss (= Faster R-CNN과 동일)
- ![image-20220714155740588](/images/2022-07-14-Mask R-CNN/image-20220714155740588.png) : mask loss로 binary cross entropy loss
- mask branch에서 출력한 ![image-20220714155752069](/images/2022-07-14-Mask R-CNN/image-20220714155752069.png) 크기의 feature map의 각 cell에 sigmoid function을 적용한 후 loss 계산
- 기존의 segmentation 모델이 픽셀별로 서로 다른 class를 softmax loss function을 사용, 하지만 Mask R-CNN은 class branch와 mask branch를 분리하여 class별로 mask를 생성한 후 binary loss 계산

&nbsp;

## Training

- Mask R-CNN은 backbone network로 ResNet-FPN을 사용
    - FPN?
        - 예전에는 다양한 크기의 물체를 탐지하기 위해 이미지 자체의 크기를 리사이즈 하면서 물체를 찾았음
        - 이런 작업은 메모리 및 시간 측면에서 비효율 그래서 Feature Pyramid Network (FPN) 이라는 방법이 등장
        
        ![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%2015.png)
        
        1. Featurized Image Pyramid
            - 각 레벨에서 독립적으로 특징을 추출하여 객체를 탐지하는 방법
            - 연산량과 시간 관점에서 비효율적이며 현실에 적용하기 어렵다는 단점 존재
        2. Single Feature Map
            - 컨볼루션 레이어가 스케일 변화에 robust 하기 때문에 컨볼루션 레이어를 통해서 특징을 압축하는 방식
            - 멀티 스케일을 사용하지 않고 한번에 특징을 압축하여 마지막에 압축된 특징만을 사용하기 때문에 성능이 떨어진다는 평가 존재
        3. Pyramidal Feature Hierarchy
            - 서로 다른 스케일의 특징 맵을 이용하여 멀티 스케일 특징을 추출하는 방식
            - 각 레벨에서 독립적으로 특징을 추출하여 객체를 탐지하게 되는데, 이는 이미 계산 되어 있는 상위 레벨의 특징을 재사용 하지 않는다는 특징 가짐
        4. Feature Pyramid Network
            - Top-down 방식으로 특징을 추출, 각 추출된 결과들인 low-resolution 및 high-resolution 들을 묶는 방식
            - 각 레벨에서 독립적으로 특징을 추출하여 객체를 탐지하게 되는데 상위 레벨의 이미 계산 된 특징을 재사용 하므로 멀티 스케일 특징들을 효율적으로 사용
            - CNN 자체가 레이어를 거치면서 피라미드 구조를 만들고 forward 를 거치면서 더 많은 의미를 가짐
                - 각 레이어마다 예측 과정을 넣어서 Scale 변화에 더 강한 모델이 됨
            - skip connection, top-down, cnn forward 에서 생성되는 피라미드 구조를 합친 형태
            - 크게 Bottom-up , Top-down 나눠서 설명
                - Bottom-up
                    - Bottom-up pathway는 우리가 알고 있던 그 일반적인 forward propagation 의미
                        - forward propagation : 뉴럴 네트워크 모델의 입력층부터 출력층까지 순서대로 변수들을 계산하고 저장하는 것을 의미
                    - CNN이 피라미드 구조를 가진다고 했을 때, 동일한 해상도를 가진 층들을 묶어 하나의 stage로 표현
                    - 여기서 FPN에서는 같은 해상도 중 가장 깊은 semantic feature를 가지고 있는 층, 즉 가장 깊은 층의 activation을 사용
                    - 논문에서는 ResNet을 사용하는데, 각각 conv2, conv3, conv4, conv5에 대응하는 위와 같은 층들을 ![image-20220714155826439](/images/2022-07-14-Mask R-CNN/image-20220714155826439.png)와 같이 표현(![image-20220714155841387](/images/2022-07-14-Mask R-CNN/image-20220714155841387.png)은 메모리 효율상 버림)
                - Top-down
                    - 사실상 top-down pathway가 FPN의 핵심
                    - Top-down pathway에서는 보다 깊은 semantic feature를 가지고 있는, top-down pathway의 바로 위에 있는 층을 upsampling한 후, 이를 대응되는 bottom-up pathway의 층과 element-wise addition으로 결합
                        - bottom-up pathway 층의 activation은 channel을 맞추기 위해 1×1 convolution 연산 수행
                        - element-wise addition : 행렬 덧셈
                    - 이를 가장 밑에 층에 이르기까지 계속하고, 이렇게 결합된 층들에 마지막으로 3×3 convolution을 가하여 최종 feature map들을 형성
                    - 가장 위의 층은 bottom-up pathway의 최상층에 1×1 convolution을 가함으로써 형성
                    - 과정요약
                        1. ![image-20220714155900585](/images/2022-07-14-Mask R-CNN/image-20220714155900585.png)에 1×1 convolution을 가하여 ![image-20220714155914090](/images/2022-07-14-Mask R-CNN/image-20220714155914090.png)층을 형성
                        2. ![image-20220714155921222](/images/2022-07-14-Mask R-CNN/image-20220714155921222.png) 층을 upsampling한 결과와![image-20220714155934007](/images/2022-07-14-Mask R-CNN/image-20220714155934007.png)에 1×1 convolution을 가한 결과를 결합하여 ![image-20220714155953470](/images/2022-07-14-Mask R-CNN/image-20220714155953470.png)층을 형성
                        3. ![image-20220714160004414](/images/2022-07-14-Mask R-CNN/image-20220714160004414.png)층까지 계속한다.
                        4. ![image-20220714160019925](/images/2022-07-14-Mask R-CNN/image-20220714160019925.png)층에 3×3 convolution을 가하여 최종 feature map인 {![image-20220714160037988](/images/2022-07-14-Mask R-CNN/image-20220714160037988.png)}을 형성한다.
                    - 이렇게 형성된 최종 feature map들로부터 각각 prediction을 수행하여 multi-scale object detection을 수행
                    - FPN은 이렇게 위에서부터 pyramid 구조를 쌓아내려옴으로써 pyramid의 모든 층이 강력한 semantic feature map을 가질 수 있도록 함
                    - inference 시에 head 부분의 parameter를 모든 scale에서 공유해도 각각의 고유한 parameter를 학습하는 것과 비슷한 수준의 성능 가짐
                    
                
    
- 전체적인 구조는 Faster R-CNN에 기반하지만 FPN이 추가

- Faster R-CNN에서 사용되었던 4-step alternating training 방법을 통해 네트워크를 학습

&nbsp;

**전체 학습과정**

1. Input image Pre-processing
    - 원본 이미지의 width, height 중 더 짧은 쪽이 target size로 resize
    - 그리고 더 긴 쪽은 aspect ratio를 보존하는 방향으로 resize
    - 만약 더 긴 쪽이 maximum size를 초과하면 maximum size로 resize되고 더 짧은 쪽이 aspect ratio를 보존하는 방향을 resize
    - .target size, maximum size의 default는 각각 800, 1333
    
    &nbsp;
    
2. Feature pyramid by backbone network
   
    ![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%2016.png)
    
    - 전처리된 이미지를 **ResNet-FPN backbone network**에 입력하여 feature pyramid ${![image-20220714160104150](/images/2022-07-14-Mask R-CNN/image-20220714160104150.png)}$을 얻음
    
      &nbsp;
    
3. Region proposal by RPN
   
    2번 과정에서 얻은 feature pyramid별로 RPN에 입력하여 objectness score과 bbox regressor를 가진 Region proposal을 출력
    
    &nbsp;
    
4. Select best RoI by Proposal layer
    - RPN을 통해 얻은 Region proposal 중 최적의 RoI를 선정
    
    - Faster R-CNN의 Proposal layer, Anchor target layer, Proposal target layer에서 수행하는 과정과 동일
        1. objectness score가 높은 top-k개의 anchor를 선정합니다. 학습 시 k=12000로 설정
        2. bbox regressor에 따라 anchor box의 크기를 조정
        3. 이미지의 경계를 벗어나는 anchor box를 제거
        4. threshold=0.7로 지정하여 Non maximum suppression을 수행
        5. 지금까지의 과정은 각각의 feature pyramid level별({![image-20220714160615311](/images/2022-07-14-Mask R-CNN/image-20220714160615311.png)})로 수행, 이전 과정까지 얻은 모든 feature pyramid level의 anchor box에 대한 정보를 결합
        6. 마지막으로 결합된 모든 anchor box에 대하여 objectness score에 따라 top-N개의 anchor box를 선정, N=2000으로 설정
        
    - 최종적으로 수많은 anchor box 중 최적의 N개의 box만이 학습에 사용
    
        &nbsp;
    
5. feature map by RoI Align layer
    - backbone network를 통해 여러 scale을 가진 feature pyramid가 생성
    
    - 그리고 RPN과 Proposal layer를 거쳐 N개의 RoI가 선정
    
    - feature pyramid는 multi-scale feature map이기 때문에 RoI를 어떤 scale의 feature map과 매칭시킬지를 결정하는 과정이 필요
      
        ![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%2017.png)
        
        - 위와 같은 공식에 따라 RoI와 feature pyramid를 매칭
        - w, h = RoI의 크기
        - k = feature pyramid의 level의 index
        
    - RoI와 feature map을 사용하여 RoIAlign 과정을 통해 7x7 크기의 feature map을 출력
    
        &nbsp;
    
6. Classification and Bounding box regression by Fast R-CNN
    - 7x7 크기의 feature map을 fc layer를 거쳐 classfication branch, bbox regression branch에 각각 전달
    
    - 최종적인 class score과 bbox regressor 생성
    
      &nbsp;
    
7. Mask segment by Mask branch
   
    ![Untitled](/images/2022-07-14-Mask R-CNN/Untitled%2018.png)
    
    - RoIAlign 과정을 통해 얻은 7x7 크기의 feature map을 mask branch
      에 전달
    
    - mask branch는 3x3 conv - ReLU - deconv(by 2) - 1x1(xK) conv layer로 구성 (K는 class의 수)
    
    - 이를 통해 14x14(xK) 크기의 feature map 생성, 해당 feature map은 class별로 생성된 binary mask
    
    - 14x14 크기의 feature map 중 앞서 classification branch에서 얻은 가장 높은 score의 class에 해당하는 feature map을 선정하여 최종 prediction에 사용
        - 하나의 14x14 크기의 feature map이 선정
        
    - 이후 feature map의 각 cell별로 sigmoid 함수를 적용하여 0~1 사이의 값을 가지도록 조정
    
        &nbsp;
    
8. Post-processing of masks
    - 최종적으로 선정된 14x14 크기의 featue map을 원본 이미지의 mask와 비교하기 위해 rescale해주는 과정을 수행
    - mask threshold(=0.5)에 따라 mask segment의 각 픽셀값이 0.5 이상인 경우 class에 해당하는 객체가 있어 1을 할당, threshold 미만의 경우 0을 할당
    - 이를 통해 실제 mask와 비교할 수 있는 mask segment가 생성
    
    &nbsp;
    
9. Train Mask R-CNN by multi-task loss
    - multi-task loss function을 사용하여 학습 수행

&nbsp;

## Inference

- Proposal layer 구간에서 모든 feature pyramid level에 걸쳐 상위 1000개의 RoI만을 선정
- RoI를 classification branch와 bbox regression branch에 입력하여 나온 예측 결과에 Non maximum suppression을 적용, 상위 100개의 box만을 선정하여 mask branch에 입력해 Inference 수행