---
layout: single
title:  "OpenCV chapter 4"
categories : OpenCV
tag : [python, OpenCV]
toc: true
toc_sticky: true
---

![header](https://capsule-render.vercel.app/api?type=waving&color=a2dcec&height=300&section=header&text=OpenCV chapter 4&fontSize=40&animation=fadeIn&fontAlignY=38&fontColor=FFFFFF)

- 참고 및 출처
  - [파이썬으로 만드는 OpenCV 프로젝트](https://github.com/dltpdn/insightbook.opencv_project_python)
  - [귀퉁이서재_opencv](https://bkshin.tistory.com/entry/OpenCV-1-%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9C%BC%EB%A1%9C-%EB%A7%8C%EB%93%9C%EB%8A%94-OpenCV-%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8?category=1148027)

&nbsp;

## 목차

- 이미지 이동, 확대/축소, 회전

- 이미지 뒤틀기 (어핀 변환, 원근 변환)

- 리매핑, 오목/볼록 렌즈 왜곡, 방사 왜곡

- 모자이크 처리, 리퀴파이, 왜곡 거울

&nbsp;



## 10. 이미지 이동(Translation), 확대/축소(Scaling), 회전(Rotation)

&nbsp;

### 이미지 이동

- 원래 있던 좌표에 이동시키려는 거리만큼 더하기 

  - x_new = x_old + d₁
  - y_new = y_old + d₂

  - 위 식을 핼렬식으로 표현하면
    - ![image-20230110144133537](/images/2023-01-10-opencv4/image-20230110144133537.png)


- 행렬식을 다시 풀어서 써보면'

  - x_new = x_old + d₁ = 1*x_old + 0*y_old + d₁

  - y_new = y_old + d₂ = 0*x_old + 1*y_old + d₂

  - 위 식을 통해 이미지의 좌표를 이동하는 변환 행렬은 2X3 행렬
    - 변환 행렬 : 어떤 좌표를 선형 변환 해주는 행렬을 의미
    - 어떤 좌표를 다른 좌표로 이동시켜주는 행렬
    - 어떤 좌표에 변환 행렬을 곱해주면 다른 좌표가 구해지는 행렬


&nbsp;

- 이미지 이동에 대한 변환 행렬
  - ![image-20230110144211897](/images/2023-01-10-opencv4/image-20230110144211897.png)


- OpenCV에서는 변환행렬을 이용해서 이미지를 변환하는 기능을 하는 cv2.warpAffine() 함수를 제공

```python
dst = cv2.warpAffine(src, matrix, dsize, dst, flags, borderMode, borderValue)
```

```markdown
    src: 원본 이미지, numpy 배열
    matrix: 2 x 3 변환행렬, dtype=float32
    dsize: 결과 이미지의 크기, (width, height)
    flags(optional): 보간법 알고리즘 플래그
    borderMode(optional): 외곽 영역 보정 플래그
    borderValue(optional): cv2.BORDER_CONSTANT 외곽 영역 보정 플래그일 경우 사용할 색상 값 (default=0)
    dst: 결과 이미지
    
    flags의 값
        - cv2.INTER_LINEAR: default 값, 인접한 4개 픽셀 값에 거리 가중치 사용
        - cv2.INTER_NEAREST: 가장 가까운 픽셀 값 사용
        - cv2.INTER_AREA: 픽셀 영역 관계를 이용한 재샘플링
        - cv2.INTER_CUBIC: 인정합 16개 픽셀 값에 거리 가중치 사용
    
    borderMode의 값
        - cv2.BORDER_CONSTANT: 고정 색상 값
        - cv2.BORDER_REPLICATE: 가장자리 복제
        - cv2.BORDER_WRAP: 반복
        - cv2.BORDER_REFLECT: 반사
```

- 원본 이미지인 src를 변환 행렬 matrix에 따라 변환하는 함수
- 결과 이미지의 크기를 나타내는 파라미터는 dsize

&nbsp;

### 평행 이동 


```python
img = cv2.imread('./fish.jpg')
rows,cols = img.shape[0:2]  # 영상의 크기

dx, dy = 100, 50            # 이동할 픽셀 거리

# ---① 변환 행렬 생성 
mtrx = np.float32([[1, 0, dx],
                   [0, 1, dy]])  
# ---② 단순 이동
dst = cv2.warpAffine(img, mtrx, (cols+dx, rows+dy))   

# ---③ 탈락된 외곽 픽셀을 파랑색으로 보정
dst2 = cv2.warpAffine(img, mtrx, (cols+dx, rows+dy), None, \
                        cv2.INTER_LINEAR, cv2.BORDER_CONSTANT, (255,0,0) )

# ---④ 탈락된 외곽 픽셀을 원본을 반사 시켜서 보정
dst3 = cv2.warpAffine(img, mtrx, (cols+dx, rows+dy), None, \
                                cv2.INTER_LINEAR, cv2.BORDER_REFLECT)

imgs = {'original' : img, 'trans' : dst, 'BORDER_CONSTATNT' : dst2, 'BORDER_FEFLECT' : dst3}

fig, axes = plt.subplots(1,4,figsize=(20, 20))
plt.tight_layout(h_pad=0, w_pad=4)

for d,i in enumerate(imgs.keys()):
    
    axes[d].imshow(imgs[i][:,:,::-1])
    axes[d].set_title(i)
    axes[d].set_xticks([]) 
    axes[d].set_yticks([]) 

plt.show()
```


![png](/images/2023-01-10-opencv4/output_212_0.png)
    


- 물고기 이미지를 가로(x) 방향으로 100픽셀, 세로(y) 방향으로 50픽셀 평행 이동
- 가로의 양의 방향은 오른쪽이고, 세로의 양의 방향은 아래쪽
- 평행 이동을 시키면 기존 영역은 이미지가 잘림
- 잘리는 영역을 어떻게 보정할지를 borderMode 파라미터로 조정
- 외곽 영역 이외에는 픽셀의 탈락이 발생하지 않으므로 flags 파라미터는 무의미

&nbsp;

### 이미지 확대 및 축소

- 기존의 좌표에 특정한 값을 곱하면 됨

  - x_new = a₁ * x_old

  - y_new = a₂ * y_old


  - 이를 다시 풀어쓰면

    - x_new = a₁ * x_old = a₁ * x_old + 0 * y_old + 0 * 1

    - y_new = a₂ * y_old = 0 * x_old + a₂ * y_old + 0 * 1
    - ![image-20230110144343978](/images/2023-01-10-opencv4/image-20230110144343978.png)



- 변환 행렬은 평행 이동할 때와 마찬가지로 2 x 3 행렬
- 2 x 2 행렬로 나타낼 수 있는데 굳이 2 x 3 행렬로 표현한 이유는 cv2.warpAffine() 함수는 변환 행렬이 2 x 3 행렬이 아니면 오류가 발생

&nbsp;

### 행렬을 이용한 이미지 확대 및 축소


```python
img = cv2.imread('./fish.jpg')
height, width = img.shape[:2]

# --① 0.5배 축소 변환 행렬
m_small = np.float32([[0.5, 0, 0],
                       [0, 0.5,0]])  
# --② 2배 확대 변환 행렬
m_big = np.float32([[2, 0, 0],
                     [0, 2, 0]])  

# --③ 보간법 적용 없이 확대 축소
dst1 = cv2.warpAffine(img, m_small, (int(height*0.5), int(width*0.5)))
dst2 = cv2.warpAffine(img, m_big, (int(height*2), int(width*2)))

# --④ 보간법 적용한 확대 축소
dst3 = cv2.warpAffine(img, m_small, (int(height*0.5), int(width*0.5)), \
                        None, cv2.INTER_AREA)
dst4 = cv2.warpAffine(img, m_big, (int(height*2), int(width*2)), \
                        None, cv2.INTER_CUBIC)

# 결과 출력
imgs = {'original' : img, 'small' : dst1, 'big' : dst2, 'small INTER_AREA' : dst3, "big INTER_CUBIC" : dst4}

fig, axes = plt.subplots(1,5,figsize=(20, 20))
plt.tight_layout(h_pad=0, w_pad=4)

for d,i in enumerate(imgs.keys()):
    
    axes[d].imshow(imgs[i][:,:,::-1])
    axes[d].set_title(i)
    axes[d].set_xticks([]) 
    axes[d].set_yticks([]) 

plt.show()
```

![png](/images/2023-01-10-opencv4/output_217_0.png)
​    


- 위 코드에서는 똑같아 보이지만 2배, 1/2배 적용된 이미지가 나옴
- 일반적으로 보간법 파라미터로는 축소에는 cv2.INTER_AREA를 쓰고, 확대에는 cv2.INTER_CUBIC, cv2.INTER_LINEAR 사용

- 변환 행렬을 쓰지 않고도 확대 및 축소 cv2.resize() 함수 사용

```python
cv2.resize(src, dsize, dst, fx, fy, interpolation)
```

```markdown
    src: 입력 원본 이미지
    dsize: 출력 영상 크기(확대/축소 목표 크기, (width, height)형식), 생략하면 fx, fy 배율을 적용
    fx, fy: 크기 배율, dsize가 주어지면 dsize를 적용함
    interpolation: 보간법 알고리즘 선택 플래그 (cv2.warpAffine()과 동일)
    dst: 결과 이미지
```

- cv2.resize() 함수를 사용하면 확대/축소를 몇 픽셀로 할지 혹은 어떤 배율로 할지 선택 가능
- dsize는 확대/축소를 원하는 목표 이미지의 크기,  fx, fy는 변경할 배율
  -  fx = 2, fy = 0.5 -> x축으로 2배, y축으로 0.5배 스케일링

&nbsp;

### cv2.reize()로 이미지 확대 및 축소


```python
img = cv2.imread('./fish.jpg')
height, width = img.shape[:2]

#--① 크기 지정으로 축소
dst1 = cv2.resize(img, (int(width*0.5), int(height*0.5)), \
                         interpolation=cv2.INTER_AREA)

#--② 배율 지정으로 확대
dst2 = cv2.resize(img, None,  None, 2, 2, cv2.INTER_CUBIC)


#--③ 결과 출력
imgs = {'original' : img, 'small' : dst1, 'big' : dst2}

fig, axes = plt.subplots(1,3)
plt.tight_layout(h_pad=0, w_pad=4)

for d,i in enumerate(imgs.keys()):
    
    axes[d].imshow(imgs[i][:,:,::-1])
    axes[d].set_title(i)
    axes[d].set_xticks([]) 
    axes[d].set_yticks([]) 

plt.show()
```

![png](/images/2023-01-10-opencv4/output_221_0.png)


- 같은 크기로 나오지만 원본의 1/2, 2 배를 적용한 이미지가 나옴
- cv2.resize() 함수는 변환 행렬을 이용하여 이미지 스케일링을 하는 것보다 더 간결

&nbsp;

### 이미지 회전

- 이미지 회전을 위한 변환 행렬식


![image-20230110144538050](/images/2023-01-10-opencv4/image-20230110144538050.png)

- OpenCV는 간단하게 변환행렬을 생성할 수 있게 아래와 같은 함수를 제공

```python
mtrx = cv2.getRotationMatrix2D(center, angle, scale)
```

```markdown
    center: 회전축 중심 좌표 (x, y)
    angle: 회전할 각도, 60진법
    scale: 확대 및 축소비율
```

&nbsp;

### 변환행렬을 이용한 이미지 회전


```python
img = cv2.imread('./fish.jpg')
rows,cols = img.shape[0:2]

#---① 회전을 위한 변환 행렬 구하기
# 회전축:중앙, 각도:45, 배율:0.5
m45 = cv2.getRotationMatrix2D((cols/2,rows/2),45,0.5) 
# 회전축:중앙, 각도:90, 배율:1.5
m90 = cv2.getRotationMatrix2D((cols/2,rows/2),90,1.5) 

#---② 변환 행렬 적용
img45 = cv2.warpAffine(img, m45,(cols, rows))
img90 = cv2.warpAffine(img, m90,(cols, rows))

#---③ 결과 출력
# cv2.imshow('origin',img)
# cv2.imshow("45", img45)
# cv2.imshow("90", img90)
# cv2.waitKey(0)
# cv2.destroyAllWindows()


imgs = {'origin' : img, '45':img45, '90':img90}

fig, axes = plt.subplots(1,3,figsize=(20, 10))
plt.tight_layout(h_pad=0, w_pad=4)

for d,i in enumerate(imgs.keys()):
    
    axes[d].imshow(imgs[i][:,:,::-1])
    axes[d].set_title(i)
    axes[d].set_xticks([]) 
    axes[d].set_yticks([]) 

plt.show()
```

![png](/images/2023-01-10-opencv4/output_227_0.png)
​ &nbsp;

## 11. 이미지 뒤틀기(어핀 변환, 원근 변환)

- 이동, 확대/축소, 회전을 한 후에는 이미지의 모양이 그대로 유지됨 하지만 이미지 뒤틀기를 하면 기존 모양과 달라짐
- 이미지 뒤틀기에는 크게 두 가지가 있는데 어핀 변환과 원근 변환 존재

&nbsp;

### 어핀 변환(Affine Transform)

```python
martix = cv2.getAffineTransform(pts1, pts2)
```

```markdown
    pts1: 변환 전 영상의 좌표 3개, 3 x 2 배열
    pts2: 변환 후 영상의 좌표 3개, 3 x 2 배열
    matrix: 변환 행렬 반환, 2 x 3 행렬
```

- 3개의 좌표인 pts1이 pts2로 위치가 변한 만큼 이미지를 뒤트는 기능을 제공

&nbsp;

### 어핀 변환


```python
file_name = './fish.jpg'
img = cv2.imread(file_name)
rows, cols = img.shape[:2]

# ---① 변환 전, 후 각 3개의 좌표 생성
pts1 = np.float32([[100, 50], [200, 50], [100, 200]])
pts2 = np.float32([[80, 70], [210, 60], [250, 120]])

# ---② 변환 전 좌표를 이미지에 표시
cv2.circle(img, (100,50), 5, (255,0), -1)
cv2.circle(img, (200,50), 5, (0,255,0), -1)
cv2.circle(img, (100,200), 5, (0,0,255), -1)

#---③ 짝지은 3개의 좌표로 변환 행렬 계산
mtrx = cv2.getAffineTransform(pts1, pts2)

#---④ 어핀 변환 적용
dst = cv2.warpAffine(img, mtrx, (int(cols*1.5), rows))

#---⑤ 결과 출력
imgs = {'original' : img, 'affin' : dst}

fig, axes = plt.subplots(1,2,figsize=(10, 5))
plt.tight_layout(h_pad=0, w_pad=4)

for d,i in enumerate(imgs.keys()):
    
    axes[d].imshow(imgs[i][:,:,::-1])
    axes[d].set_title(i)
    axes[d].set_xticks([]) 
    axes[d].set_yticks([]) 

plt.show()
```

![png](/images/2023-01-10-opencv4/output_233_0.png)
​ &nbsp;


### 원근 변환(Perspective Transform)

- 어핀 변환은 이미지를 2차원으로 뒤트는 변환

- 원근 변환은 이미지를 3차원으로 변환, 멀리 있는 것은 작게 보이고, 가까이 있는 것은 크게 보이는 게 원근법의 원리

  - 원근법의 원리를 적용해 변환하는 방식이 원근 변환

  

```python
mtrx = cv2.getPerspectiveTransform(pts1, pts2)
```

```markdown
    pts1: 변환 이전 영상의 좌표 4개, 4 x 2 배열
    pts2: 변환 이후 영상의 좌표 4개, 4 x 2 배열
    mtrx: 변환행렬 반환, 3 x 3 행렬
```

- 변환행렬을 cv2.warpAffine() 함수에 전달해주었는데, 원근 변환은 별도의 함수 cv2.warpPerspective() 함수사용 파라미터는 cv2.warpAffine() 동일

&nbsp;

### 원근변환


```python
file_name = "./fish.jpg"
img = cv2.imread(file_name)
rows, cols = img.shape[:2]

#---① 원근 변환 전 후 4개 좌표
pts1 = np.float32([[0,0], [0,rows], [cols, 0], [cols,rows]])
pts2 = np.float32([[100,50], [10,rows-50], [cols-100, 50], [cols-10,rows-50]])

#---② 변환 전 좌표를 원본 이미지에 표시
cv2.circle(img, (0,0), 10, (255,0,0), -1)
cv2.circle(img, (0,rows), 10, (0,255,0), -1)
cv2.circle(img, (cols,0), 10, (0,0,255), -1)
cv2.circle(img, (cols,rows), 10, (0,255,255), -1)

#---③ 원근 변환 행렬 계산
mtrx = cv2.getPerspectiveTransform(pts1, pts2)
#---④ 원근 변환 적용
dst = cv2.warpPerspective(img, mtrx, (cols, rows))


imgs = {'original' : img, 'perspective' : dst}

fig, axes = plt.subplots(1,2,figsize=(20, 20))
plt.tight_layout(h_pad=0, w_pad=4)

for d,i in enumerate(imgs.keys()):
    
    axes[d].imshow(imgs[i][:,:,::-1])
    axes[d].set_title(i)
    axes[d].set_xticks([]) 
    axes[d].set_yticks([]) 

plt.show()
```

![png](/images/2023-01-10-opencv4/output_237_0.png)
​    


-  이미지의 위쪽 부분의 폭이 좁아져서 마치 멀리 있는 것처럼 보임, 이게 원근 변환
-  실제 많이 쓰이는 것은 원근 이미지를 평면 이미지로 변환할때 많이 사용



&nbsp;

### 삼각형 어핀 변환

- OpenCV가 제공하는 기하학적 변환은 기본적으로 사각형이 기준

- 과정

  1. 어핀 변환 전 삼각형 좌표 3개를 정한다.
  2. 어핀 변환 후 삼각형 좌표 3개를 정한다.
  3. 변환 전 삼각형 좌표를 감싸는 외접 사각형 좌표를 구한다.
  4. 변환 후 삼각형 좌표를 감싸는 외접 사각형 좌표를 구한다.
  5. 과정 3, 4의 사각형 영역을 관심 영역(ROI, regison of interest)으로 지정한다.
  6. 과정 5의 관심 영역을 기준으로 변환 전, 후의 삼각형 좌표를 다시 계산한다.
  7. 과정 6의 변환 전 삼각형 좌표를 변환 후 삼각형 좌표로 어핀 변환해주는 변환 행렬을 구한다.
  8. 과정 7에서 구한 변환행렬을 적용해 어핀 변환을 한다.
  9. 과정 8에서 변환된 관심 영역에서 과정 2의 삼각형 좌표만 마스킹한다.
  10. 과정 9에서 구한 마스크를 이용해서 어핀 변환한 이미지와 원본 이미지를 합성한다.

  

```python
x, y, w, h = cv2.boudingRect(pts) -> 위의 3, 4처럼 삼각형 좌표를 감싸는 외접 사각형 좌표 구할때 사용
```

```markdown
    pts: 다각형 좌표
    x, y, w, h = 외접 사각형의 좌표와 폭과 높이
```

```python
cv2.fillConvexPoly(img, pts, color, lineTypes) -> 9의 마스크를 구하기 위해 사용
```

```markdown
    img: 입력 이미지
    pts: 다각형 좌표
    color: 다각형을 채울 색상
    lineType(optional): 선 그리기 알고리즘 선택 플래그
```


```python
img = cv2.imread("./taekwonv1.jpg")
img2 = img.copy()
draw = img.copy()

# 변환 전,후 삼각형 좌표 ---①
pts1 = np.float32([[188,14], [85,202], [294,216]])
pts2 = np.float32([[128,40], [85,307], [306,167]])

# 각 삼각형을 완전히 감싸는 사각형 좌표 구하기 ---②
x1,y1,w1,h1 = cv2.boundingRect(pts1)
x2,y2,w2,h2 = cv2.boundingRect(pts2)

# 사각형을 이용한 관심영역 설정 ---③
roi1 = img[y1:y1+h1, x1:x1+w1]
roi2 = img2[y2:y2+h2, x2:x2+w2]

# 관심영역을 기준으로 좌표 계산 ---④
offset1 = np.zeros((3,2), dtype=np.float32)
offset2 = np.zeros((3,2), dtype=np.float32)
for i in range(3):
    offset1[i][0], offset1[i][1] = pts1[i][0]-x1, pts1[i][1]-y1
    offset2[i][0], offset2[i][1] = pts2[i][0]-x2, pts2[i][1]-y2

# 관심 영역을 주어진 삼각형 좌표로 어핀 변환 ---⑤
mtrx = cv2.getAffineTransform(offset1, offset2)
warped = cv2.warpAffine( roi1, mtrx, (w2, h2), None, \
                        cv2.INTER_LINEAR, cv2.BORDER_REFLECT_101)

# 어핀 변환 후 삼각형만 골라 내기 위한 마스크 생성 ---⑥
mask = np.zeros((h2, w2), dtype = np.uint8)
cv2.fillConvexPoly(mask, np.int32(offset2), (255))

# 삼각형 영역만 마스킹해서 합성 ---⑦
warped_masked = cv2.bitwise_and(warped, warped, mask=mask)
roi2_masked = cv2.bitwise_and(roi2, roi2, mask=cv2.bitwise_not(mask))
roi2_masked = roi2_masked + warped_masked
img2[y2:y2+h2, x2:x2+w2] = roi2_masked

# 관심 영역과 삼각형에 선 그려서 출력 ---⑧
cv2.rectangle(draw, (x1, y1), (x1+w1, y1+h1), (0,255,0), 1)
cv2.polylines(draw, [pts1.astype(np.int32)], True, (255,0,0), 1)
cv2.rectangle(img2, (x2, y2), (x2+w2, y2+h2), (0,255,0), 1)

imgs = {'origin' : draw, 'warped triangle' : img2}

fig, axes = plt.subplots(1,2,figsize=(20, 20))
plt.tight_layout(h_pad=0, w_pad=4)

for d,i in enumerate(imgs.keys()):
    
    axes[d].imshow(imgs[i][:,:,::-1])
    axes[d].set_title(i)
    axes[d].set_xticks([]) 
    axes[d].set_yticks([]) 

plt.show()
```

![png](/images/2023-01-10-opencv4/output_241_0.png)
​ &nbsp;


## 12. 리매핑(Remapping), 오목/볼록 렌즈 왜곡(Lens Distortion), 방사 왜곡(Radial Distortion)

&nbsp;

### 렌즈 왜곡(Lens Distortion)

- 변환 행렬로는 구할 수 없는 모양의 변환, 렌즈 왜곡 변환이 바로 변환 행렬로는 구할 수 없는 변환
- 렌즈 왜곡 변환에는 리매핑, 오목 렌즈/볼록 렌즈 왜곡, 방사 왜곡 존재

&nbsp;

### 리매핑(Remapping)

- 규칙성 없이 마음대로 이미지의 모양을 변환하는 것
- OpenCV는 cv2.remap()이라는 함수를 제공

```python
dst = cv2.remap(src, mapx, mapy, interpolation, dst, borderMode, borderValue)
```

```markdown
    src: 입력 이미지
    mapx, mapy: x축과 y축으로 이동할 좌표, src와 동일한 크기, dtype=float32
    dst(optional): 결과 이미지
    나머지 인자는 cv2.warpAffine()과 동일
```

ex) mapx[0][0]=10, mapy[0][0]=5 라고 지정하면 ,  src 좌표 (0, 0)에 있는 픽셀을 (10, 5) 이동하는걸 의미


```markdown
- mapx와 mapy는 초기 값으로 0 같은 의미 없는 값이 아니라 원래 이미지의 좌표 값 주는 것이 좋음, 전체 픽셀 중 옮기고 싶은 픽셀에 대해서만 새로운 좌표를 지정하거나 원래 위치에서 얼마만큼 이동하라고 명령하는 것이 편하기 때문
- mapx와 mapy를 np.zeros()로 초기화한 뒤 for문으로 초기화할 수 있지만 이렇게 하면 시간이 너무 오래 소요
- np.indices() 함수를 쓰면 빠르게 초기화 가능
```

```python
mapy, mapx = np.indices( (rows, cols), dtype=np.float32)
```

- np.indices 사용예

```python
np.indices((2,2))

array([[[0, 0],
        [1, 1]],

       [[0, 1],
        [0, 1]]])
        
        
np.indices((3, 3))

array([[[0, 0, 0],
        [1, 1, 1],
        [2, 2, 2]],

       [[0, 1, 2],
        [0, 1, 2],
        [0, 1, 2]]])
```

- 리매핑으로 이미지 뒤집기


```python
img = cv2.imread('./test_image.jpg')
rows, cols = img.shape[:2]



# 뒤집기 변환 행렬로 구현 ---①
st = time.time()
mflip = np.float32([ [-1, 0, cols-1],[0, -1, rows-1]]) # 변환 행렬 생성
fliped1 = cv2.warpAffine(img, mflip, (cols, rows))     # 변환 적용
print('matrix:', time.time()-st)

# remap 함수로 뒤집기 구현 ---②
st2 = time.time()
mapy, mapx = np.indices((rows, cols),dtype=np.float32) # 매핑 배열 초기화 생성
mapx = cols - mapx -1                                  # x축 좌표 뒤집기 연산
mapy = rows - mapy -1                                  # y축 좌표 뒤집기 연산
fliped2 = cv2.remap(img,mapx,mapy,cv2.INTER_LINEAR)  # remap 적용
print('remap:', time.time()-st2)


# 결과 출력 ---③
imgs = {'origin' : img, 'fliped1' : fliped1, 'fliped2': fliped2}

fig, axes = plt.subplots(1,3,figsize=(20, 20))
plt.tight_layout(h_pad=0, w_pad=4)

for d,i in enumerate(imgs.keys()):
    
    axes[d].imshow(imgs[i][:,:,::-1])
    axes[d].set_title(i)
    axes[d].set_xticks([]) 
    axes[d].set_yticks([]) 

plt.show()

>> matrix: 0.0010006427764892578
>> remap: 0.0010006427764892578
```


![png](/images/2023-01-10-opencv4/output_248_1.png)
    


- 뒤집을때 사용한 연산


```markdown
x' = cols - x - 1
y' = rows - y - 1
```

- 변환행렬을 이용하여 뒤집은 이미지와 cv2.remap() 함수로 리매핑하여 뒤집은 이미지의 결과는 같음
- cv2.remap() 함수로 변환하는 것은 변환 행렬로 변환하는 것보다 수행 속도가 더 느림
- 변환행렬로 표현할 수 있는 것은 변환행렬로 변환을 하는 것이 좋고 변환행렬로 표현할 수 없는 비선형 변환에만 cv2.remap() 함수를 사용

&nbsp;

### 삼각함수를 이용한 비선형 리매핑

```markdown
- 변환 행렬로 표현할 수 없는 비선형 변환
```


```python
l = 20      # 파장(wave length)
amp = 15    # 진폭(amplitude)

img = cv2.imread('./taekwonv1.jpg')
rows, cols = img.shape[:2]

# 초기 매핑 배열 생성 ---①
mapy, mapx = np.indices((rows, cols),dtype=np.float32)

# sin, cos 함수를 적용한 변형 매핑 연산 ---②
sinx = mapx + amp * np.sin(mapy/l)  
cosy = mapy + amp * np.cos(mapx/l)

# 영상 매핑 ---③
img_sinx=cv2.remap(img, sinx, mapy, cv2.INTER_LINEAR) # x축만 sin 곡선 적용
img_cosy=cv2.remap(img, mapx, cosy, cv2.INTER_LINEAR) # y축만 cos 곡선 적용

# x,y 축 모두 sin, cos 곡선 적용 및 외곽 영역 보정
img_both=cv2.remap(img, sinx, cosy, cv2.INTER_LINEAR, \
                    None, cv2.BORDER_REPLICATE)
# 결과 출력 
imgs = {'origin' : img, 'sin x' : img_sinx, 'cos y' : img_cosy, 'sin cos' : img_both}

fig, axes = plt.subplots(1,4,figsize=(20, 20))
plt.tight_layout(h_pad=0, w_pad=4)

for d,i in enumerate(imgs.keys()):
    
    axes[d].imshow(imgs[i][:,:,::-1])
    axes[d].set_title(i)
    axes[d].set_xticks([]) 
    axes[d].set_yticks([]) 

plt.show()
```

![png](/images/2023-01-10-opencv4/output_251_0.png)
​    


- x좌표, y좌표에 sin, cos 함수를 적용하여 새로운 사인파 코사인파 곡선으로 왜곡된 이미지 생성
- 마지막 이미지에는 sin, cos 함수를 모두 적용, cv2.BORDER_REPLICATE 파라미터로 외곽 보정 적용해서 외곽의 사라진 영역 보정

&nbsp;

### 오목 렌즈와 볼록 렌즈 왜곡

![image-20230110145054675](/images/2023-01-10-opencv4/image-20230110145054675.png)

- x축과 y축의 직각으로 각각 선을 그어서 만나는 지점을 좌표 (x, y)로 나타냅니다. 이러한 형태의 좌표 시스템을 직교 좌표계
- 원점으로부터의 거리(r)와 사잇각(Θ)을 이용해서 (r, Θ)로 나타내는 방법이 있는데, 이를 극좌표계
- 두 좌표계는 상호 변환이 가능

```python
r, theta = cv2.cartToPolar(x, y): 직교 좌표 → 극좌표 변환
x, y = cv2.polarToCart(r, theta): 극좌표 → 직교 좌표 변환
```

- 좌표의 변환뿐만 아니라 좌표의 기준점 변환도 중요, 직교 좌표계를 사용할 때는 좌측 상단을 원점(0, 0)
- 반면에 극좌표에서는 이미지의 중앙을 원점, 중앙을 (0, 0)으로 두기 위해서 좌표의 값을 -1 ~ 1로 정규화

&nbsp;

### 볼록/오몬 렌즈 왜곡 효과


```python
img = cv2.imread('./taekwonv1.jpg')
print(img.shape)
rows, cols = img.shape[:2]

# ---① 설정 값 셋팅
exp = 2       # 볼록, 오목 지수 (오목 : 0.1 ~ 1, 볼록 : 1.1~)
scale = 1           # 변환 영역 크기 (0 ~ 1)

# 매핑 배열 생성 ---②
mapy, mapx = np.indices((rows, cols),dtype=np.float32)

# 좌상단 기준좌표에서 -1~1로 정규화된 중심점 기준 좌표로 변경 ---③
mapx = 2*mapx/(cols-1)-1
mapy = 2*mapy/(rows-1)-1

# 직교좌표를 극 좌표로 변환 ---④
r, theta = cv2.cartToPolar(mapx, mapy)

# 왜곡 영역만 중심확대/축소 지수 적용 ---⑤
r[r< scale] = r[r<scale] **exp  

# 극 좌표를 직교좌표로 변환 ---⑥
mapx, mapy = cv2.polarToCart(r, theta)

# 중심점 기준에서 좌상단 기준으로 변경 ---⑦
mapx = ((mapx + 1)*cols-1)/2
mapy = ((mapy + 1)*rows-1)/2

# 재매핑 변환
distorted = cv2.remap(img,mapx,mapy,cv2.INTER_LINEAR)


imgs = {'original' : img, 'distorted' : distorted}

fig, axes = plt.subplots(1,2,figsize=(20, 20))
plt.tight_layout(h_pad=0, w_pad=4)

for d,i in enumerate(imgs.keys()):
    
    axes[d].imshow(imgs[i][:,:,::-1])
    axes[d].set_title(i)
    axes[d].set_xticks([]) 
    axes[d].set_yticks([]) 

plt.show()
>> (444, 400, 3)
```


![png](/images/2023-01-10-opencv4/output_257_1.png)
    


- exp는 이미지의 왜곡 지수를 나타내는 변수로 1이면 원본과 동일하게 하고, 1보다 작으면 오목 렌즈 효과를 내고, 1보다 크면 볼록 렌즈 효과
- 아래 코드는 좌표의 기준점을 바꾸고 -1~1 범위로 정규화하는 코드,  이후에 다시 좌상단 기준점으로 변경

```python
mapx = 2*mapx/(cols-1)-1
mapy = 2*mapy/(rows-1)-1
```

실질적인 렌즈 효과는 아래 코드에서 수행

```python
r[r< scale] = r[r<scale] **exp  
```

- 좌표의 범위를 -1~1로 정규화, scale의 최댓값은 1설정됨
- 극좌표계로 바꿨을 때의 r은 원의 반지름, 반지름이 scale보다 작은 범위에 있는 좌표에 대해서는 exp를 곱함, (eps가 1보다 크면 볼록, 1보다 작으면 오목)

&nbsp;

### 방사 왜곡

- 카메라를 통해 이미지를 촬영할 때 카메라 가장자리 부분에서 약간의 왜곡 -> 배럴 왜곡
- 들어가는 듯한 왜곡 -> 핀쿠션 왜곡

![image-20230110145208681](/images/2023-01-10-opencv4/image-20230110145208681.png)

&nbsp;

### 배럴 왜곡, 핀쿠션 왜곡


```python
# 왜곡 계수 설정 ---①
k1, k2, k3 = 0.5, 0.2, 0.0 # 배럴 왜곡
h1, h2, h3 = -0.3, 0, 0    # 핀큐션 왜곡

img = cv2.imread('./girl.jpg')
rows, cols = img.shape[:2]

def make_distorted(k1, k2, k3):
    global img, rows, cols

    # 매핑 배열 생성 ---②
    mapy, mapx = np.indices((rows, cols),dtype=np.float32)

    # 중앙점 좌표로 -1~1 정규화 및 극좌표 변환 ---③
    mapx = 2*mapx/(cols-1)-1
    mapy = 2*mapy/(rows-1)-1
    r, theta = cv2.cartToPolar(mapx, mapy)

    # 방사 왜곡 변영 연산 ---④
    ru = r*(1+k1*(r**2) + k2*(r**4) + k3*(r**6)) 

    # 직교좌표 및 좌상단 기준으로 복원 ---⑤
    mapx, mapy = cv2.polarToCart(ru, theta)
    mapx = ((mapx + 1)*cols-1)/2
    mapy = ((mapy + 1)*rows-1)/2
    
    # 리매핑 ---⑥
    distored = cv2.remap(img,mapx,mapy,cv2.INTER_LINEAR)
    
    return distored


distored = make_distorted(k1, k2, k3)
distored2 = make_distorted(h1, h2, h3)


imgs = {'original' : img, 'distored' : distored, 'distored2' : distored2}

fig, axes = plt.subplots(1,3,figsize=(20, 20))
plt.tight_layout(h_pad=0, w_pad=4)

for d,i in enumerate(imgs.keys()):
    
    axes[d].imshow(imgs[i][:,:,::-1])
    axes[d].set_title(i)
    axes[d].set_xticks([]) 
    axes[d].set_yticks([]) 

plt.show()
```


![png](/images/2023-01-10-opencv4/output_262_0.png)


- 오목과 비슷한 프로세스

ru = r*(1+k1*(r**2) + k2*(r**4) + k3*(r**6)) 

- 위 연산식은 배럴 왜곡, 핀쿠션 왜곡을 적용해주는 연산식
- k의 값에 따라서 배럴 왜곡, 핀쿠션 왜곡 결정

&nbsp;

## 13. 모자이크 처리(Mosaic), 리퀴파이(Liquify), 왜곡 거울(Distortion Mirror)

&nbsp;

### 모자이크 처리

- 모자이크를 적용할 관심 영역의 이미지를 특정 비율로 축소시킨 뒤 다시 확대하면 모자이크 됨
- 크기가 작은 이미지를 최대 픽셀 값 이상의 크기로 확대하면 이미지가 깨짐, 이 원리를 적용한 것
- 관심 영역을 축소했다가 다시 확대하면 원래의 픽셀과 비슷하긴 하지만, 보간법에 의해서 연산한 결과라서 선명도가 떨어져 뿌옇게 됨, 이때 보간법은 cv2.INTER_AREA를 사용


```python
rate = 15               # 모자이크에 사용할 축소 비율 (1/rate)
win_title = 'mosaic'    # 창 제목
img = cv2.imread('./taekwonv1.jpg')    # 이미지 읽기

while True:
    x,y,w,h = cv2.selectROI(win_title, img, False) # 관심영역 선택
    if w and h:
        roi = img[y:y+h, x:x+w]   # 관심영역 지정
        roi = cv2.resize(roi, (w//rate, h//rate)) # 1/rate 비율로 축소
        
        # 원래 크기로 확대
        roi = cv2.resize(roi, (w,h), interpolation=cv2.INTER_AREA)  
        img[y:y+h, x:x+w] = roi   # 원본 이미지에 적용
        plt.imshow(img[:,:,::-1])
        plt.title('mosaic') 
        plt.xticks([]) 
        plt.yticks([]) 
    else:
        break

plt.show()
cv2.destroyAllWindows()
```

![png](/images/2023-01-10-opencv4/output_267_0.png)

&nbsp;


### 리퀴파이 도구

- 어플의 보정효과 -> 리퀴파이(Liquify)라고 함

- 이미지의 원하는 부분만 작게 하거나 크게 하는 기능을 리퀴파이

- 리퀴파이 원리

  - 사각형 영역을 4개의 삼각형 영역으로 나눔
  - 마우스의 위치를 가운데 교차점으로 지정
  - 마우스를 드래그하면 교차점의 위치가 오른쪽과 같이 변환
  - 각 4개의 삼각형의 크기가 변화후 각각의 4개의 삼각형에 대해서 각각 어핀 변환 수행

  ![image-20230110145319732](/images/2023-01-10-opencv4/image-20230110145319732.png)


```python
win_title = 'Liquify'   # 창 이름
half = 50               # 관심 영역 절반 크기
isDragging = False      # 드래그 여부 플래그

# 리퀴파이 함수
def liquify(img, cx1,cy1, cx2,cy2) :
    # 대상 영역 좌표와 크기 설정
    x, y, w, h = cx1-half, cy1-half, half*2, half*2
    # 관심 영역 설정
    roi = img[y:y+h, x:x+w].copy()
    out = roi.copy()

    # 관심영역 기준으로 좌표 재 설정
    offset_cx1,offset_cy1 = cx1-x, cy1-y
    offset_cx2,offset_cy2 = cx2-x, cy2-y
    
    # 변환 이전 4개의 삼각형 좌표
    tri1 = [[ (0,0), (w, 0), (offset_cx1, offset_cy1)], # 상,top
            [ [0,0], [0, h], [offset_cx1, offset_cy1]], # 좌,left
            [ [w, 0], [offset_cx1, offset_cy1], [w, h]], # 우, right
            [ [0, h], [offset_cx1, offset_cy1], [w, h]]] # 하, bottom

    # 변환 이후 4개의 삼각형 좌표
    tri2 = [[ [0,0], [w,0], [offset_cx2, offset_cy2]], # 상, top
            [ [0,0], [0, h], [offset_cx2, offset_cy2]], # 좌, left
            [ [w,0], [offset_cx2, offset_cy2], [w, h]], # 우, right
            [ [0,h], [offset_cx2, offset_cy2], [w, h]]] # 하, bottom

    
    for i in range(4):
        # 각각의 삼각형 좌표에 대해 어핀 변환 적용
        matrix = cv2.getAffineTransform( np.float32(tri1[i]), \
                                         np.float32(tri2[i]))
        warped = cv2.warpAffine( roi.copy(), matrix, (w, h), \
            None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101)
        # 삼각형 모양의 마스크 생성
        mask = np.zeros((h, w), dtype = np.uint8)
        cv2.fillConvexPoly(mask, np.int32(tri2[i]), (255,255,255))
        
        # 마스킹 후 합성
        warped = cv2.bitwise_and(warped, warped, mask=mask)
        out = cv2.bitwise_and(out, out, mask=cv2.bitwise_not(mask))
        out = out + warped

    # 관심 영역을 원본 영상에 합성
    img[y:y+h, x:x+w] = out
    return img 

# 마우스 이벤트 핸들 함수
def onMouse(event,x,y,flags,param):     
    global cx1, cy1, isDragging, img      # 전역변수 참조
    # 마우스 중심 점을 기준으로 대상 영역 따라다니기
    if event == cv2.EVENT_MOUSEMOVE:  
        if not isDragging :
            img_draw = img.copy()       
            # 드래그 영역 표시
            cv2.rectangle(img_draw, (x-half, y-half), \
                    (x+half, y+half), (0,255,0)) 
            cv2.imshow(win_title, img_draw) # 사각형 표시된 그림 화면 출력
    elif event == cv2.EVENT_LBUTTONDOWN :   
        isDragging = True                   # 드래그 시작
        cx1, cy1 = x, y                     # 드래그 시작된 원래의 위치 좌표 저장
    elif event == cv2.EVENT_LBUTTONUP :
        if isDragging:
            isDragging = False              # 드래그 끝
            # 드래그 시작 좌표와 끝난 좌표로 리퀴파이 적용 함수 호출
            liquify(img, cx1, cy1, x, y)    
            cv2.imshow(win_title, img)

    
img = cv2.imread("./taekwonv1.jpg")
h, w = img.shape[:2]

cv2.namedWindow(win_title)
cv2.setMouseCallback(win_title, onMouse) 
cv2.imshow(win_title, img)
while True:
    key = cv2.waitKey(1)
    if key & 0xFF == 27:
        break
cv2.destroyAllWindows()
```

![image-20230110145345809](/images/2023-01-10-opencv4/image-20230110145345809.png)