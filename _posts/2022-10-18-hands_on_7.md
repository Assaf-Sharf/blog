---
layout: single
title:  "핸즈온 머신러닝 - 7"
categories : scikit-learn
tag : [scikit-learn, machine-learning, python]
toc: true
toc_sticky: true
---

![header](https://capsule-render.vercel.app/api?type=waving&color=a2dcec&height=300&section=header&text=핸즈온 머신러닝 - 7&fontSize=40&animation=fadeIn&fontAlignY=38&fontColor=FFFFFF)

- 참고 : [핸즈온 머신러닝 2판](http://www.kyobobook.co.kr/product/detailViewKor.laf?mallGb=KOR&ejkGb=KOR&barcode=9791162242964)

------------------------------------------------------

&nbsp;

## 앙상블 학습과 랜덤 포레스트

- 일련의 예측기로부터 예측을 수집하면 가장 좋은 모델하나보다 더 좋은 예측을 얻을 수 있음
- 훈련 세트로부터 무작위로 각기 다른 서브셋을 만들어 일련의 결정 트리 분류기를 훈련

&nbsp;

### 투표 기반 분류기

- 좋은 분류기를 만드는 매우 간단한 방법은 각 분류기의 예측을 모아서 가장 많이 선택된 클래스를 예측하는 것
- 다수결 투표로 정해지는 분류기를 **직접 투표 분류기** 라고 함

> 앙상블 방법은 예측기가 가능한 한 서로 독립적일 때 최고의 성능을 보임
>
> 다양한 분류기를 얻는 한 가지 방법은 각기 다른 알고리즘으로 학습시키는 것, 매우 다른 종류의 오차를 만들 가능성이 높기 때문에 앙상블 모델의 정확도를 향상시킴

&nbsp;

**투표 기반 분류기 훈련 예시**

```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC

log_clf = LogisticRegression(solver="lbfgs", random_state=42)
rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)
svm_clf = SVC(gamma="scale", random_state=42)

voting_clf = VotingClassifier(
    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],
    voting='hard')
voting_clf.fit(X_train, y_train)


from sklearn.metrics import accuracy_score

for clf in (log_clf, rnd_clf, svm_clf, voting_clf):
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)
    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))
    
>>  LogisticRegression 0.864
    RandomForestClassifier 0.896
    SVC 0.896
    VotingClassifier 0.912
```

- 모든 분류기가 클래스의 확률을 예측할 수 있다면 개별 분류기의 예측을 평균 내어 확률이 가장 높은 클래스를 예측할 수 있음 이를 **간접 투표** 라고 함
  - 위 방식은 확률이 높은 투표에 비중을 더 두기 때문에 직접 투표 방식보다 성능이 높음
  - voting= 'hard' -> voting='soft'로 바꾸고 모든 분류기가 클래스의 확률을 추정할수 있다면 가능
  - SVC 기본값에서는 클래스 확률을 제공 X, probability 매개변수 True 설정해야 확률 추정 가능

&nbsp;

### 배깅과 페이스팅

- 같은 알고리즘을 사용하고 훈련 세트의 서브셋을 무작위로 구성하여 분류기를 각기 다르게 학습시키는 것
- 훈련 세트에서 중복을 허용하여 샘플링하는 방식을 **배깅**
- 중복을 허용하지 않고 샘플링 하는 방식을 **페이스팅**

- 배깅과 페이스팅에서는 같은 훈련 샘플을 여러 개의 예측기에 걸쳐 사용 가능 하지만 배깅만이 한 예측기를 위해 같은 훈련 샘플을 여러 번 샘플링할 수 있음

- 모든 예측기가 훈련을 마치면 앙상블은 모든 예측기의 예측을 모아서 새로운 샘플에 대한 예측을 만듬
  - 분류일경우 통계적 최빈값, 회귀는 평균으로 계산
- 배깅과 페이스팅은 병렬로 학습이 가능 

&nbsp;

**사이킷런의 배깅과 페이스팅**

- sklearn API를 통한 결정 트리 분류기 500개의 앙상블 훈련시키는 코드

  - 중복 허용해 무작위로 선택된 100개 샘플 학습 (배깅), bootstrap=False (페이스팅)

    ```python
    from sklearn.ensemble import BaggingClassifier
    from sklearn.tree import DecisionTreeClassifier
    
    bag_clf = BaggingClassifier(
        DecisionTreeClassifier(), n_estimators=500,
        max_samples=100, bootstrap=True, random_state=42)
    bag_clf.fit(X_train, y_train)
    y_pred = bag_clf.predict(X_test)
    
    from sklearn.metrics import accuracy_score
    print(accuracy_score(y_test, y_pred))
    >> 0.904
    ```

    - BaggingClassifier도 확률 추정가능 -> 간접투표 사용가능 
    - predict_proba() 있으면 간접투표방식 사용


- ![image-20221018113544333](/images/2022-10-18-hands_on_7/image-20221018113544333.png)
  - 위 그림에서 처럼 앙상블 예측이 결정 트리 하나의 예측보다 일반화가 더 잘됨
  - 앙상블은 비슷한 편향에서 더 작은 분산을 만듬 (훈련 세트의 오차 수가 거의 비슷하지만 결정 경계는 덜 불규칙)
- bootstrap은 각 예측기가 학습하는 서브셋에 다양성을 증가시키므로 배깅이 페이스팅보다 편향이 조금 더 높음
  - 다양성을 추가한다는 것은 예측기들의 상관관계를 줄이므로 앙상블의 분산 감소
  - 전반적으로 배깅이 더 나은 모델을 만들기 때문에 더 선호

&nbsp;

**oob 평가**

- 배깅을 사용하면 어떤 샘플은 한 예측기를 위해 여러 번 샘플링되고 어떤 것은 전혀 선택이 안될수도 있음

- BaggingClassifier는 기본값으로 중복을 허용(bootstrap=True) 훈련 세트의 크기만큼인 m개 샘플을 선택

  - 평균적으로 각 예측기에 훈련 샘플의 63%만 샘플링
  - 선택되지 않은 훈련 샘플의 나머지 37%를 **oob 샘플**이라고 함

- 예측기가 훈련되는 동안에도 oob 샘플을 사용하지 않으므로 별도의 검증 세트를 사용하지 않고 oob 샘플을 사용해 평가 가능

  - 앙상블의 평가는 각 예측기의 oob 평가를 평균하여 얻음
  - oob_score = True 로 수행

  ```python
  bag_clf = BaggingClassifier(
      DecisionTreeClassifier(), n_estimators=500,
      bootstrap=True, oob_score=True, random_state=40)
  bag_clf.fit(X_train, y_train)
  bag_clf.oob_score_
  >> 0.9013
  ```

  - oob score 결과를 보면 약 90.1% 정확도를 얻을수 있음

  ```python
  from sklearn.metrics import accuracy_score
  y_pred = bag_clf.predict(X_test)
  accuracy_score(y_test, y_pred)
  
  >> 0.912
  ```

  - oob 결정 함수의 값은 oob_decision_function_ 변수에서 확인 가능
  - 결정 함수는 각 훈련 샘플의 클래스 확률을 반환 (predict_proba() 있기 때문)

&nbsp;

### 랜덤 패치와 랜덤 서브스페이스

- BaggingClassifier는 특성 샘플링도 지원, 샘플링은 max_features, bootstrap_features 두 매개변수로 조절
- 작동은 max_samples, bootstrap과 동일하지만 샘플이 아닌 특성에 대한 샘플링
  - 각 예측기는 무작위로 선택한 입력 특성의 일부분으로 훈련
- 매우 고차원의 데이터셋을 다룰 때 유용함
- 훈련 특성과 샘플을 모두 샘플링 하는 것을 **랜덤 패치 방식**
- 훈련 샘플을 모두 사용하고 (bootstrap=False, max_samples=1.0) 특성은 샘플링하는 (bootstrap_features=True, max_features < 1.0) 것을 **랜덤 서브스페이스 방식**
- 특성 샘플링은 더 다양한 예측기를 만들며 편향을 늘리는 대신 분산을 낮춤

&nbsp;

