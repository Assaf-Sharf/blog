---
title: "컴퓨터 비전의 모든 것  "
date: 2024-04-22
last_modified_at: 2024-04-22
categories:
  - 컴퓨터비전
tags:
  - 컴퓨터비전


published: true
toc: true
toc_sticky: true
---


# 서론

컴퓨터 비젼이란 영상비젼으로부터 본질을 파악하는 것

그래픽스와 반대되는 개념 컴퓨터로 영상 비전을 만드는것 


과거의 기반을 흐름을 통해서 내다보는 해안을 보는 기술

짧은 시간 동안 압축적으로 컴퓨터 비전의 핵심 분야를 살펴보기 때문에 다음과 같은 방식으로 강의가 진행됩니다.

특징
1. 준 근현대사 강의
2. 딥러닝 기반 기술만 커버
3. 영어 강의 자료(용어 통일, 최신 논문)


# 학습 목표
컴퓨터 비전과 인공지능의 관계를 이해하고 컴퓨터 비전의 개념을 설명할 수 있다.

핵심 단어

1. 컴퓨터 비전
2. 인공지능
3. 딥러닝

## 컴퓨터 비젼이란

 인공지능은 인간의 지능을 컴퓨터 시스템으로 구현하는것

 지능은 인지,지각,기어, 이해사고 능력을 포함한다는 
 
 컴퓨터 비전이 바로 이 시작 능력을 컴퓨터 시스템으로 구현하는것


# 고정 적인 머신 비젼 방법
![머신비젼](/assets/img/AI/1_1.png)
1. 입력 데이터 수집
2. 전문가들이 특징 수집
3. 추출된 특징을 간단한 모델로 학습

![머신비젼](/assets/img/AI/1_2.png)
1. 입력만 넣으면 
2. 특징 추출과 특징까지 모델 학습 진행됨


결론적으로 전문가들이 직접 Feature extraction(특징 추출)을 설계할 피룡 없이 입출력 쌍만 주어지면면 End-to end 학습 방식이다


코스에서 배우는것

이미지

# Image Classification (1) : 개념

## 교육 자료 링크
https://www.boostcourse.org/ai340/lecture/1462946


# 들어가기 전에

본 강의에서는 컴퓨터 비전의 가장 기본적인 task, Image Classification을 소개합니다. 또한 CNN(Convolutional Neural Network)의 역사를 간략하게 살펴보며, 컴퓨터 비전 분야에서 CNN 중요한 이유에 대해 알아보겠습니다.

# 학습 목표

컴퓨터 비전의 가장 기본적인 task인 Image Classification의 개념을 정확히 파악하고 설명할 수 있다. 컴퓨터 비전 분야에서 CNN이 중요한 이유와 CNN의 발전 과정을 설명할 수 있다.


# 핵심 단어

1. Image Classificiation
2. CNN(Convolutional Neural Network)
3. AlexNet
4. VGGNet

분류기 

매핑을 classfier 라고 부른다

# K-N N이란
![머신비젼](/assets/img/AI/1_2.png)

K Nearest Neighbors
쿼리 데이터가 들어오면 어는곳에 가까운지 추론하는 기술

모든 데이터를 가지고 있다면 영상엔진에 검증하기 편해진다

검색하는데 데이터 및 용량때문에 문제가 발생한다

Nearest Neighbor은 질의(query) 데이터가 입력으로 들어왔을 때, 해당 질의 데이터 근방에 포진하고 있는 k개의 이웃 데이터의 클래스 정보를 기반으로 질의 데이터의 클래스를 분류하는 방법

K-nn 영상간의 유사도를 정의를 해야한다.
정의를 하는것을 쉬운게 아닌다

방대한 데이터를 압축해서 녹여 녹는다
neural newwork에 넣어논다

# CNN (Convolutional Neural Networsks) 합섭곱 신경망

평균 영상으로 정보를 포함되는것을 보여줄수 있다. 
layer단순해서 평균이미지 

적용시점에서 대표적인 패턴을 학습 학습시에 다르게 특정만 자르면 문제가 된다.

# single-layer Neural Network 구조
 주어진 입력 이미지의 모든 피겟ㄹ을 서로다른 가중치를 기반으로 가중합을 수행하고 그 결과를 (non-linear) Activation function에 입력하여 최종저그올 분류하는 모델입니다.

  해당 문제의 문제점은 평균적인 이미지와 동떨어지는 이미지의 경우 잘표현되지 않는다는점
  두번째는 Testtime 에서 성능이 매우 떨어질 수 있다는 문제점

  ex) 말의 부분적인 모습으로 성능이 떨어진다.


 locally connected network
 하나의 특징을 뽑는게 아니라 
 weight에서 작게 만들어서 만들어 낸다.
 전영역을 순회해서 뽑는것은 cnn을 만든다.
 파라미터 재확용을 해서 오버피팅 방지할수 있다.

BackBone base network 라고 생각한다.

이미지 분류

영상 인식 모델

# AlexNet 

 CNN 구조는 1998년 Yann LeCun에 의해 처음 제안되었습니다.(LeNet) 물론 매우 단순한 구조였지만, AlexNet은 LeNet에서 많은 영감을 받아 유사한 부분이 많습니다. 그러나 AlexNet은 LeNet에 비해 훨씬 깊어졌고, ImgaeNet이란 대규모 이미지 데이터셋을 통해 학습을 진행했으며, 향상된 Activation Function 및 Drop out과 같은 Regularization(정칙화 : 역문제를 해결할때나 기계 학습에서 잘못 설정된 문제를 풀거나 과적합을 방지하는 기법) 기법을 적용하였습니다. 구체적으로 다음과 같이 구현할 수 있습니다.

 ![AlexNet 구조](/assets/img/AI/1-4.png)


이떄 Max Pooling( 픽셀마다 최댓값을 뽑아낸다)된 Activattion map(활성화 함수 : 인공신경망에서 입력을 변환하는 함수)을 Linear layer(선형 계층 : 선형 변환을 수행하는 레이어이다 )의 입력으로 사용하기 위해서는 벡터화 작업을 먼저 수행해줘야하기 때문에 , network의 하단을 보면 flatten( 추출된 주요 특징을 전결합층에 전달하기위해 1차원 자료로 바꿔주는 layer이다 ) 작업을 수행하는 코드르 확인할 수 있다.

 백터화는 1) Average polling(Channel 축)
 2) flatten의 방식을 통해 구현할 수 있습니다.
 또 AlexNet은 현재에서는 사용하지 않는 몇가지 특징을 있는데

 이미지 명함을 normalization하는 Local Response Normalization(현재는 Batch normalization을 사용) 그리고 깊지 않은 network에서 receptive field를 넓히고자 큰 필터사이즈를 사용하는 등의 특징이 있습니다. 이떄 Receptive field는 출력의 한 픽셀 값을 도출해내기까지 참고한 input space duddurml zmrldlqslek.,



# VGGNet

 ![VGGNet 구조](/assets/img/AI/1-5.png)

VGGNet도 AlexNet과 굉장히 유사한 형태를 가지고 있지만 더 깊습니다 (16 and 19 layers) 또한 앞서 언급했던 AlexNet의 Linear Response Normalizaiton을 사용하지 않고 작은 보다 작은 사이즈의 필터를 사용하고 있습니다. 허나 이런 단순한 구조를 가지고 있으면서도 AlexNet에 비해 상당히 개선된 성능을 보여주었습니다. 나아가 미리 학습된 특징등을 다른 task에 활용할 수 있을 정도로 개선된 일반화 성능을 보여주기도 합니다.

----
# 참조 pooling이란
 Convolution을 거쳐서 나온 activation maps이 있을때 이를 이루는 convolution layer을 resizing하여 새로운 layer을 얻는것

![pooling](/assets/img/AI/1-6.webp)
---

---
# 참조 FC(Fully connected layer)

완전히 연결되었다는 뜻으로
한층의 모든 뉴런이 다음층이 모든 뉴런이 연결된 상태로 2차원 배열 형태의 이미지를 1차원의 평탄화 작업을 통해 이미지를 분류하는데 사용되는 계층입니다.


1. 2차원 배열 형태의 이미지를 1차원 배열로 평탄화

2. 활성화 함수(Relu, Leaky Relu, Tanh,등)뉴런을 활성화

3. 분류기(Softmax) 함수로 분류

​

1~3과정을 Fully Connected Layer라고 말할 수 있습니다.
[출처] [딥러닝 레이어] FC(Fully Connected Layers)이란?|작성자 인텔리즈

---

# 자료출처

1. Max Pooling

https://hobinjeong.medium.com/cnn%EC%97%90%EC%84%9C-pooling%EC%9D%B4%EB%9E%80-c4e01aa83c83

2. flatten
https://velog.io/@yuns_u/flatten%EA%B3%BC-dense

3. Linear Layer

https://velog.io/@nochesita/%EB%A0%88%EC%9D%B4%EC%96%B4-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B8%B0-1-Linear

4. pool
https://hobinjeong.medium.com/cnn%EC%97%90%EC%84%9C-pooling%EC%9D%B4%EB%9E%80-c4e01aa83c83

5. FC(fully connectd layer )

https://blog.naver.com/intelliz/221709190464