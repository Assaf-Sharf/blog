---
layout: single
title:  "9-27 부덕아? 그만."
categories : Daily_feedback
toc : true
---

왔다빡.

부덕이가 야망이 개크다.

하면서 햇갈린거 여기다가 정리좀 하겠다.

### torch.index_select


```python
import torch

#torch.index_select(인풋텐서, 방향, 뽑을 것들(텐서로 입력) )
# TODO : [1, 3]을 만드세요!

A = torch.Tensor([[1, 2],
                  [3, 4]])

indices = torch.tensor([0])
B = torch.index_select(A, 1, indices)
output = B.view(2)
print(output)
#tensor([1., 3.])
```

### torch.gather

```python
torch.gather(input, dim, index, *, sparse_grad=False, out=None)
```
3차원 문제가 겁나게 안풀리길래 별걸 다 넣어봤는데
결국 해결책은 torch.tensor와 torch.Tensor의 차이였다.
gather함수에서는 index항이 int로 들어가야 했다. 따라서 torch.Tensor는 안 된다.


### torch.Tensor / torch.tensor
-   torch.Tensor
    -   Class
    -   int 입력시 float으로 변환
    -   torch 데이터 입력시 입력 받은 데이터의 메모리 공간을 사용
    -   list, numpy 데이터 입력 시 입력 받은 데이터를 복사하여 새롭게 torch.Tensor를 만든 후 사용
-   torch.tensor
    -   Function
    -   int 입력시 int 그대로
    -   입력 받은 데이터를 새로운 메모리 공간으로 복사 후 사용
출처 (https://jadon.tistory.com/36)


### matmul, mm은 broadcating 차이
까먹었었는데 다시 쓴다.
matmul은 지원 되니까 왠만하면 돌아간다
그러므로 mm 쓰는 것을 권장한다.


### torch.nn
basic block을 대신 만들어 주기 위한 모듈들의 모임



모델에서의 값들
- "Tensor"          - ❌ gradient 계산    - ❌ 값 업데이트    - ❌ 모델 저장시 값 저장
- "Parameter"    - ✅ gradient 계산    - ✅ 값 업데이트    - ✅ 모델 저장시 값 저장
- "Buffer"           - ❌ gradient 계산    - ❌ 값 업데이트    - ✅ 모델 저장시 값 저장


### nn.Module
