---
layout: post
title:  "첫번째 포스팅"
---



import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
import os
import datetime

browser = webdriver.Chrome()
browser.maximize_window() # 창 최대화

# 페이지 이동
url = 'https://finance.naver.com/sise/sise_rise.naver'
browser.get(url)

# 조회 항목 초기화 (체크 해제)
checkboxes = browser.find_elements(By.NAME, 'fieldIds')
for checkbox in checkboxes:
    if checkbox.is_selected(): # 체크된 상태라면
        checkbox.click() # 클릭 (체크 해제)

# 항목 체크
items_to_select = ['거래량', '거래대금']
for checkbox in checkboxes:
    parent = checkbox.find_element(By.XPATH, '..') # 부모 element
    label = parent.find_element(By.TAG_NAME, 'label')
    # print(label.text)
    if label.text in items_to_select: # 선택 항목과 일치한다면
        checkbox.click()
# 적용하기 클릭
btn_apply = browser.find_element(By.XPATH, '//a[@href="javascript:fieldSubmit()"]')
btn_apply.click()


# 데이터 추출
df1 = pd.read_html(browser.page_source)[1]
df1.dropna(axis='index', how='all', inplace=True)
df1 = df1.reset_index(drop=True) #인덱스 번호 재정렬

# browser.page_source는 브라우저의 페이지 소스코드입니다.
soup = BeautifulSoup(browser.page_source, 'html.parser')

# 모든 링크 가져오기
links = soup.find_all('a')

# 링크 텍스트와 URL 저장할 리스트 생성
link_texts = []
link_urls = []

# 링크 텍스트와 URL 추출하여 리스트에 추가
for link in links:
    link_texts.append(link.text)
    link_urls.append(link['href'])

# 리스트를 데이터프레임으로 변환
df11 = pd.DataFrame({'Link Text': link_texts, 'URL': link_urls})

#불필요 행 삭제
df11.dropna(axis='index', how='all', inplace=True)
df11 = pd.DataFrame({'종목명': link_texts, 'URL': link_urls})
df11.dropna(axis='index', how='all', inplace=True)
df11.drop(df11.index[0:114], inplace=True) #불필요한 인덱스 열 삭제
df11 = df11.reset_index(drop=True) #인덱스 번호 재정렬



browser.quit()
```


```python
# 하이퍼링크 함수 정의
def create_hyperlink(row):
     return '=HYPERLINK("https://finance.naver.com{}","{}")'.format(row['URL'], row['종목명'])

# Apply the function to create hyperlinks in column 'Hyperlink'
df1['종목명'] = df11.apply(create_hyperlink, axis=1)
```


```python
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
import os
import datetime

browser = webdriver.Chrome()
browser.maximize_window() # 창 최대화

# 페이지 이동
url = 'https://finance.naver.com/sise/sise_rise.naver?sosok=1'
browser.get(url)

# 조회 항목 초기화 (체크 해제)
checkboxes = browser.find_elements(By.NAME, 'fieldIds')
for checkbox in checkboxes:
    if checkbox.is_selected(): # 체크된 상태라면
        checkbox.click() # 클릭 (체크 해제)

# 항목 체크
items_to_select = ['거래량', '거래대금']
for checkbox in checkboxes:
    parent = checkbox.find_element(By.XPATH, '..') # 부모 element
    label = parent.find_element(By.TAG_NAME, 'label')
    # print(label.text)
    if label.text in items_to_select: # 선택 항목과 일치한다면
        checkbox.click()
# 적용하기 클릭
btn_apply = browser.find_element(By.XPATH, '//a[@href="javascript:fieldSubmit()"]')
btn_apply.click()


# 데이터 추출
df2 = pd.read_html(browser.page_source)[1]
df2.dropna(axis='index', how='all', inplace=True)
df2 = df2.reset_index(drop=True) #인덱스 번호 재정렬

# browser.page_source는 브라우저의 페이지 소스코드입니다.
soup = BeautifulSoup(browser.page_source, 'html.parser')

# 모든 링크 가져오기
links = soup.find_all('a')

# 링크 텍스트와 URL 저장할 리스트 생성
link_texts = []
link_urls = []

# 링크 텍스트와 URL 추출하여 리스트에 추가
for link in links:
    link_texts.append(link.text)
    link_urls.append(link['href'])

# 리스트를 데이터프레임으로 변환
df22 = pd.DataFrame({'Link Text': link_texts, 'URL': link_urls})

#불필요 행 삭제
df22.dropna(axis='index', how='all', inplace=True)
df22 = pd.DataFrame({'종목명': link_texts, 'URL': link_urls})
df22.dropna(axis='index', how='all', inplace=True)
df22.drop(df22.index[0:114], inplace=True) #불필요한 인덱스 열 삭제
df22 = df22.reset_index(drop=True) #인덱스 번호 재정렬



browser.quit()
```


```python
# 하이퍼링크 함수 정의
def create_hyperlink(row):
     return '=HYPERLINK("https://finance.naver.com{}","{}")'.format(row['URL'], row['종목명'])

# Apply the function to create hyperlinks in column 'Hyperlink'
df2['종목명'] = df22.apply(create_hyperlink, axis=1)
```


```python
df = pd.concat([df1, df2], axis=0)
```


```python
df["등락률"]= df["등락률"].str.replace("+", " ", ) #모든 하이픈(-)을 공백으로 대체
df["등락률"]= df["등락률"].str.replace("%", " ", ) #모든 하이픈(-)을 공백으로 대체
df['등락률'] = df['등락률'].astype('float64')

df = df[df['등락률'] > 5]
df = df.sort_values(by=['등락률'], ascending=False)
df = df.loc[df['종목명'].str.contains('ACE|ETN|SOL|TIGER|HANARO|KBSTAR|KTOP|KOSEF|KoreaStock|히어로즈|WOORI|ARIRANG|KODEX|TIMEFOLIO') == False]
df = df.reset_index(drop=True)
df.index=df.index + 1
df['등락률'] = df['등락률'].astype('str')
df['등락률'] = df['등락률']+'%'

suffix = datetime.datetime.now().strftime('%Y-%m-%d')

df['N'] = suffix
#파일 저장
f_name = './datafiles/' + suffix + '_sise_final_data.csv'
df.to_csv(f_name,encoding='utf-8-sig') #csv파일로 생성
```
