---
layout: post
title: "머신러닝 공부일기 2"
---

# 2021-10-02 데이터 전처리

다음주 종강 프로젝트 **무조건** 완성시키기

## 1. 데이터 전처리

- 결손값(NaN, Null)은 허용되지 않음
- 사이킷런 머신러닝 알고리즘은 문자열을 입력값으로 허용하지 않음. 그래서 전처리 해줘야함

### 1-1. 데이터 인코딩

- 쉽게 말해 사이킷런이 받아들일 수 있는 데이터 형태로 변경해주는 작업
- 레이블 인코딩과 원-핫 인코딩이 대표적

#### 1-1-1. 레이블 인코딩

- 카테고리형 데이터를 코드형 숫자값으로 변경

- ex) ["TV","Radio","Computer"] -> [1,2,3] : TV를 1로 Radio를 2로 Computer를 3의 값으로 변경

- 단점으로는 몇몇 머신러닝 알고리즘의 성능저하를 일으킬 요소가 있음

    a. 레이블 인코딩으로 부여한 숫자는 (우리가 알기론) 단순히 숫자로 치환한 것으로 알지만 머신러닝 알고리즘은 이를 상하관계로 인식
    
    b. a의 이유로 선형회귀 알고리즘엔 적용할 수 없음


```python
from sklearn.preprocessing import LabelEncoder


items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']


encoder = LabelEncoder()
encoder.fit(items)
labels = encoder.transform(items)
print('인코더 변환값:', labels)
```

    인코더 변환값: [0 1 4 5 3 3 2 2]
    

- 인코더가 어떤 값을 어떤 숫자로 변경했는지 확인


```python
print('인코딩 클래스?',encoder.classes_)
```

    인코딩 클래스? ['TV' '냉장고' '믹서' '선풍기' '전자레인지' '컴퓨터']
    

- 디코딩(인코딩 원본을 확인함)


```python
print('디코딩 원본?',encoder.inverse_transform([0, 2, 4, 1, 5, 4, 3, 2]))
```

    디코딩 원본? ['TV' '믹서' '전자레인지' '냉장고' '컴퓨터' '전자레인지' '선풍기' '믹서']
    

#### 1-1-2. 원-핫 인코딩

- 피처 값의 유형에 따라 새로운 피처를 추가해 고유 값에 해당하는 칼럼에만 1을 표시하는 인코딩 방식을 말함
- 아래 코드로 이해하는게 훨 도움됨


```python
from sklearn.preprocessing import OneHotEncoder
import numpy as np

items = ['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']

encoder = LabelEncoder()
encoder.fit(items)
labels = encoder.transform(items)
# ↑여기까지는 레이블 인코딩과 동일

# 원-핫 인코딩을 위한 사전준비
labels = labels.reshape(-1,1)

#원-핫 인코딩 적용
oh_encoder = OneHotEncoder()
oh_encoder.fit(labels)
oh_labels = oh_encoder.transform(labels)

print('원-핫 인코딩 데이터:\n', oh_labels.toarray())
print('\n원-핫 인코딩 데이터 차원:', oh_labels.shape)
```

    원-핫 인코딩 데이터:
     [[1. 0. 0. 0. 0. 0.]
     [0. 1. 0. 0. 0. 0.]
     [0. 0. 0. 0. 1. 0.]
     [0. 0. 0. 0. 0. 1.]
     [0. 0. 0. 1. 0. 0.]
     [0. 0. 0. 1. 0. 0.]
     [0. 0. 1. 0. 0. 0.]
     [0. 0. 1. 0. 0. 0.]]
    
    원-핫 인코딩 데이터 차원: (8, 6)
    

- pandas에는 원-핫 인코딩 과정을 한 줄로 끝내는 함수가 존재


```python
import pandas as pd

df = pd.DataFrame({'item':['TV', '냉장고', '전자레인지', '컴퓨터', '선풍기', '선풍기', '믹서', '믹서']})

#데이터 프레임하나 만들고 get_dummies()쓰면 끝
pd.get_dummies(df)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>item_TV</th>
      <th>item_냉장고</th>
      <th>item_믹서</th>
      <th>item_선풍기</th>
      <th>item_전자레인지</th>
      <th>item_컴퓨터</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
</div>



### 1-2. 피처 스케일링과 정규화

- 서로 다른 변수의 값 범위를 일정한 수준으로 맞추는 작업(피처 스케일링)
- 대표적인 방법: 표준화, 정규화

#### 1-2-1. 표준화

- 데이터의 피처 각각 평균이 **0**이고 분산이 **1**인 가우시안 정규 분포를 가진 값으로 변환
- StandardSclaler, MinMaxScaler

#### 1-2-2. 정규화

- 서로 다른 피처의 크기를 통일하기 위해 크기를 변환하는 개념
- ex) 100Kg과 1,000,000원의 값을 가진 변수들은 단위가 동일하지 않기 때문에 이를 동일한 크기로 비교하기 위해 **0~1**사이의 값으로 변환


```python
#StandardScaler를 사용하기 전
from sklearn.datasets import load_iris

iris = load_iris()
iris_data = iris.data
iris_df = pd.DataFrame(data=iris_data, columns=iris.feature_names)

print('feature 들의 평균 값')
print(iris_df.mean())
print('\nfeature 들의 분산 값')
print(iris_df.var())
```

    feature 들의 평균 값
    sepal length (cm)    5.843333
    sepal width (cm)     3.057333
    petal length (cm)    3.758000
    petal width (cm)     1.199333
    dtype: float64
    
    feature 들의 분산 값
    sepal length (cm)    0.685694
    sepal width (cm)     0.189979
    petal length (cm)    3.116278
    petal width (cm)     0.581006
    dtype: float64
    


```python
#StandardScaler를 사용
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
scaler.fit(iris_df)
iris_scaled = scaler.transform(iris_df)

# transform()은 스케일 변환된 데이터 세트가 Numpy ndarray로 반환되고 이를 df형식으로 변환
iris_df_scaled = pd.DataFrame(data=iris_scaled, columns=iris.feature_names)

print('feature 들의 평균 값')
print(iris_df_scaled.mean())
print('\nfeature 들의 분산 값')
print(iris_df_scaled.var())
```

    feature 들의 평균 값
    sepal length (cm)   -1.690315e-15
    sepal width (cm)    -1.842970e-15
    petal length (cm)   -1.698641e-15
    petal width (cm)    -1.409243e-15
    dtype: float64
    
    feature 들의 분산 값
    sepal length (cm)    1.006711
    sepal width (cm)     1.006711
    petal length (cm)    1.006711
    petal width (cm)     1.006711
    dtype: float64
    

- standardScaler로 표준화시킨 평균값의 경우 너무 작은 값이라 0이라고 봐야 함


```python
#MinMaxScaler - 위에서 쓰이는 방식하고 동일함. 불러오는 라이브러리만 다름(라이브러리만 적고 생략한다는 뜻)
#항목 중 음수가 있으면 -1~1사의 값으로 변환

from sklearn.preprocessing import MinMaxScaler
```

### 1-3. 스케일링시 유의할 점

- 학습 데이터로 fit()이 적용된 스케일링 기준 정보를 그대로 테스트 데이터에 적용해야함
- 테스트 데이터로 다시 fit()돌리면 스케일링 기준 정보가 달라 예측 결과가 잘 안나올 수 있음
- 무슨 말인지 모르겠으니 손코딩 하면서 익히기로..


```python
from sklearn.preprocessing import MinMaxScaler
import numpy as np


#Scaler클래스의 fit(), transform()은 2차원 이상 데이터만 가능하므로 reshape(-1,1)로 차원 변경
train_array = np.arange(0, 11).reshape(-1,1)
test_array = np.arange(0,6).reshape(-1,1)
```


```python
train_array.T
```




    array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10]])



- 1. fit()에 train_array를 돌리면 최솟값 0, 최댓값 10이 설정되고 1/10 Scale이 적용될 것이고
- 2. 1.에서 했던 Scale을 통해 transform()으로 학습 데이터를 변환하면 원본 데이터에의 1은 0.1로 2는 0.2, ... 로 바뀜


```python
scaler = MinMaxScaler()

#1.의 과정을 수행하는 행
scaler.fit(train_array)

#2.의 과정을 수행하는 행, 즉 위에서 적용한 스케일러를 가지고 변환을 시키는 것!
train_scaled = scaler.transform(train_array)

print('원본 train_array:', np.round(train_array.reshape(-1),2))
print('스케일링 된 train_array:', np.round(train_scaled.reshape(-1),2))
```

    원본 train_array: [ 0  1  2  3  4  5  6  7  8  9 10]
    스케일링 된 train_array: [0.  0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1. ]
    

- 이제 위에서 말했던 테스트 데이터로 다시 fit()을 실행하는 경우가 아래의 경우임


```python
#이 행에선 test_array를 fit()에 돌리면 원본 데이터의 최솟값0, 최댓값이 5로 설정됨(train_array가 아님을 주의)
scaler.fit(test_array)

#test_array의 스케일러는 1/5가 될 것임
test_scaled = scaler.transform(test_array)


print('원본 test_array:', np.round(test_array.reshape(-1),2))
print('스케일링 된 test_array:', np.round(test_scaled.reshape(-1),2))
```

    원본 test_array: [0 1 2 3 4 5]
    스케일링 된 test_array: [0.  0.2 0.4 0.6 0.8 1. ]
    

- 학습데이터의 스케일러(1/10)과 테스트데이터의 스케일러(1/5)가 같지 않음
- 다시 말하면 기준이 절대적인 것이 아니라 상대적인 것으로 바뀐 것이라 값이 동일하게 나와버림(각자 입맛에 맞도록 맞춘거니까)
- **테스트 데이터로 다시 fit()을 적용해서는 안됨!**

*타이타닉은 강사님이 제공해준 데이터 보면서 태블릿 코랩으로 해보고 넘길 계획. 오피지지 수료 프로젝트 제출할 정도의 실력은 갖춰진듯*
