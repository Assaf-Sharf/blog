---
layout: post
title: 머신러닝 디자인 패턴 톺아보기 - 머신러닝 기본용어, 배경지식
excerpt: "머신러닝 디자인 패턴의 챕터1을 공부했다."
categories:
  - TIL
tags: 
  - ML
  - ML-Term
  - TIL
last_modified_at: 2021-11-30T08:06:00-05:00
---

### 저번에 사고 묵혀둔 "머신러닝 디자인 패턴"을 다시 꺼내들었다. 많고 많은 책 중에 이 책을 선택한 이유는 역자인 맹윤호님의 책 소개글 중 _"단순히 돌아가는 코드를 수록해놓은 책이 아니라 다양한 기술 의사결정에 있어서 기준점이 되어줄 책입니다."_  라는 문장 때문이다. ML을 약 1년간 어설프게 공부했던 나에게는 조금 색다른 책이 아닐까하는 호기심과 한층 더 성장하고 싶은 욕구가 책을 구매하기에 매우 충분했다.(아직도 저 문장을 읽고 정신이 번쩍 들던 그때가 기억이 난다.) 물론 나에게는 아직 많이 버거운 책일지도 모르지만, 책에서 전하고자 하는 바를 조금이나마 얻어갔으면 하는 마음에 매일 조금씩 공부하고 이곳에 흔적을 남겨보려 한다.
* * *
* * *
<br>

# 1. 기본 머신러닝 용어
### 1) 머신러닝 모델 : 데이터에서 패턴을 학습하는 알고리즘
* 신경망(neural network) 모델
* 선형 회귀(linear regression) 모델
* 결정 트리(decision tree) 모델
* 클러스터링(clustering) 모델

❓ 딥러닝(deep learning) 모델은 뭘까? 2개 이상의 은닉층(hidden layer)(입력층이나 출력층이 아닌 계층)이 있는 신경망은 딥러닝으로 분류됨

### 2) 데이터셋 : 머신러닝 모델의 학습, 검증, 테스트에 사용되는 데이터
* 학습 데이터 : 학습 프로세스 중에 모델에 제공되는 데이터
* 검증 데이터 : 학습 데이터셋에 포함되지 않는 데이터, 각 학습 에폭이 완료된 후 모델의 성능 평가에 사용
* 테스트 데이터 : 학습 과정에 전혀 사용되지 않는 데이터, 학습이 끝난 모델의 성능을 평가하는데 사용

❗ 데이터의 종류 : 구조화된 데이터(=테이블 데이터), 구조화되지 않는 데이터로 분류
![캡처](https://user-images.githubusercontent.com/77676907/144068114-0a618efe-2a92-4eae-b4cd-726a5fa067a5.PNG)

### 3) 특징 가공(feature engineering) : 데이터의 수칫값을 조정하거나, 수치가 아닌 데이터를 모델에서 이해할 수 있는 수치 형식으로 변환하는 작업

### 4) 인스턴스(instance) : 예측을 위해 모델로 보내는 데이터 항목
ex) 테스트 데이터셋의 행(라벨 열 없음), 분류하려는 이미지, 감정 분석 모델로 보낼 텍스트 문서 등

### 5) 서빙(serving) : 다른 사용자가 모델에 접근하여 예측값을 받을 수 있도록 모델을 제공하기 위해 들어오는 접근 요청을 수락하고 모델을 마이크로서비스 형태로 배포하여 예측값을 전송하는 시스템을 구축하는 과정

### 6) 예측 : 모델에 새 데이터를 전송하고 출력을 사용하는 프로세스, 미래 가치를 추정하는 경우에 적합한 말
❓ 미래 가치를 추정하는 경우란 무엇을 말할까? 예를 들면, 자전거를 타는 주기, 장바구니가 버려질 여부와 같은 미래에 일어날 일(=미래 가치)이 어떻게 될지 예측하는 것을 말함. 이미지 및 텍스트 분류 모델의 경우에는 미래 결과가 없기 때문에 예측이라는 단어보다는 **추론(inference)** 이 적합함

### 7) 머신러닝 모델 개발 프로세스
![image](https://user-images.githubusercontent.com/77676907/144071590-830ae858-1520-4fd3-9950-71c8a2451fa0.png)

<br>

# 2. 머신러닝의 문제
### 1) 데이터의 품질
## **_"Garbage in, Garbage out"_**
* 데이터 정확도 : 학습 데이터 특징의 정확도, 해당 특징에 해당하는 실측 라벨의 정확도를 나타냄

    -> 데이터 수집 후 오타, 중복 항목, 단위 불일치, 누락된 특징, 기타 오류 등을 파악해야 함
* 데이터 완전성 : 예측 하려는 목표에 알맞은 데이터가 수집되었는지를 나타냄

    -> 학습 데이터에 각 라벨의 다양한 표현이 포함되도록 해야함  ex) 고양이 사진 -> 10개의 품종 중 하나로 판단하는 모델이 있다고 가정, 고양이가 아닌 다른 사진을 넣어도 10개의 품종 중 하나로 예측하는 경우 발생 => 데이터의 완전성이 부족함, '고양이 아님'에 대한 데이터와 라벨도 학습에 필요!
* 데이터 일관성 : 수집된 데이터의 단위 표준화, 형식 일관성 유지가 되었는지를 나타냄

    -> 여러 사람이 데이터셋의 각 항목에 라벨을 지정한 다음, 각 항목에 가장 일반적으로 적용되는 라벨을 사용하면 조금 더 보완 가능
* 데이터 적시성 : 데이터의 사건이 발생한 시점과 DB에 추가된 시점 사이의 지연 시간을 나타냄

    -> 특정 이번트가 발생한 시점과 데이터셋에 추가된 시점의 타임스탬프를 추적한 후 특징 가공을 할 때 이러한 차이점을 반영함으로써 보완 가능

### 2) 학습 과정에서 나타나는 재현성
* 머신러닝 모델에는 근본적으로 무작위성이 내재되어 있음
* **ML 모델은 처음 학습시킬 때 가중치는 임의의 값으로 초기화되는데, 모델이 학습을 반복하다 보면 이러한 가중치는 특정한 값으로 수렴됨**
* 이로 인해, 동일한 학습 데이터를 사용하여 동일한 모델에 코드를 입력했다고 해도 두 모델은 학습이 끝나고 나면 약간 다른 결과를 생성하는 경우 발생 ➡ **재현성 문제 야기**

❓ 그럼 어떻게 해결하지? **학습을 싱핼할 때마다 동일한 무작위성이 적용되도록 사용하는 시드값을 고정** (단, 동일한 데이터, 동일한 랜덤시드를 적용해야 효과를 봄)
```python
tf.random.set_seed(value) # value로 랜덤 시드 고정

from sklearn.utils import shuffle
data = suffle(data, random_state=value) # 데이터도 value의 랜덤 시드를 고정하여 섞어주어 재현성 보장
```
