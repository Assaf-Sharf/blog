---
title: "python-26: Web Scrapping"
layout: single
categories : python
tag: [coding, github, jekyll, blog, python]
toc: true
toc_sticky: true
author_profile: false
---

### Pypi
- https://pypi.org/search/
- 다른사람이 만든 프로젝트나 모듈을 모아둔 곳


### Requests
- HTTP for Humans
- https://requests.readthedocs.io/en/latest/

```
Response = get(website)
Print(response.status_code)
```

- 웹 스크래핑: 내가 쓴 코드가 웹사이트에 들어가서 데이터를 추출해냄


### 개발자 일자리 찾기  
- https://kr.indeed.com/?r=us
- https://weworkremotely.com/

### Beautifusoup
- 웹사이트(HTML)의 데이터를 받아올수 있게 해주는 파이썬 라이브러리

- Beautifulsoup 들어가는 법: <br>
  리플에서 큐브모양 클릭 , beautifulsoup 검색, beautifulsoup4 설치, requests도 설치확인

- `get(f{바뀌는 변수})` 여기서 `f` 는 문자열안에 변수를 넣을 수 있게 해줌
 
```py
from request import get
 
base_url = "https://weworkremotely.com/remote-jobs/search?term="
 
search_term = "python"
 
response = get(f"{base_url}{search_term}")
 
print(response.text)
```

```py
def say_hello(name, age):
  print(f"Hello {name} you are {age} years old")
 
 
say_hello("nico", 12)
say_hello(age=12, name="nico")
```

![image](https://user-images.githubusercontent.com/111720411/209949024-32e34359-65f6-435b-bf94-c77a37f30a65.png)

- 첫번째가 positional(매개변수와 인수와의 관계간에 순서가 반드시 맞아야함)
- 두번째로(argument의 이름을 적어주면) 하면 순서가 맞지 않아도 됨
- 웹을 가져오기 위해 requests의 get을 임포트

```py
from requests import get
#beautifulsoup 사용을 위해 임포트
from bs4 import BeautifulSoup
base_url = "https://weworkremotely.com/remote-jobs/search?utf8=%E2%9C%93&term="
search_term = "python"
```

- 나중에 url과 검색어를 변경하여 재사용할 수 있게 f문자열 포매팅 <br>
  `response = get(f"{base_url}+{search_term}")`
- 웹사이트에서 정상적인 응답(200)을 주지 않을때를 대비
```py
if not response.status_code == 200:
print("Can't request website")
```

- 정상이라면 페이지의 html 코드를 쫙 긁어 옴

```py
else:
print(response.text)
soup = BeautifulSoup(response.text, 'html.parser')
```

- section의 jobs클래스 리스트를 만들어주자

```py
jobs = soup.find_all('section', class_="jobs")
for job_section in jobs:
job_posts = job_section.find_all('li')
```

- viewlall제거

```py
job_posts.pop(-1)
for post in job_posts:
anchors = post.find_all('a')
anchor = anchors[1]
```

- list의 길이(len)을 알고 있다면 item들의 순서에 맞춰 변수명을 넣어줄 수 있음 <br>

```py
company_name, shift, region = anchor.find_all('span', class_="company")
link = anchor['href']
```

- find_all은 항상 list를 주기 때문에 title하나만 원해서 .find

```py
title = anchor.find('span', class_="title")
print(company_name, shift, region, title)
print("🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸")
```

- .string = html태그는 없애줌



