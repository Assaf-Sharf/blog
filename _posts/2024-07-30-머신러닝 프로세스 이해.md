머신러닝 프로세스 이해

## 사용할 데이터셋 다운로드 하기


```python
import os
import tarfile
import urllib.request

DOWNLOAD_ROOT = "https://raw.githubusercontent.com/ageron/handson-ml2/master/"
HOUSING_PATH = os.path.join("datasets", "housing") # 디렉토리 설정하기 - /기본 경로/datasets/housing
HOUSING_URL  = DOWNLOAD_ROOT + "datasets/housing/housing.tgz" # 다운로드 할 파일의 URL

def fetch_housing_data(housing_url= HOUSING_URL, housing_path= HOUSING_PATH):
  os.makedirs(housing_path, exist_ok= True) # 디렉토리 만들기
  tgz_path = os.path.join(housing_path, "housing.tgz") # 파일의 경로
  urllib.request.urlretrieve(housing_url, tgz_path) # URL로 지정한 파일을 다운로드
  housing_tgz = tarfile.open(tgz_path) # 다운 받은 파일 열기
  housing_tgz.extractall(path= housing_path) # 압축 파일(housing.tgz) 압축 풀기
  housing_tgz.close() # 파일 닫기

fetch_housing_data()
```

## 다운 받은 데이터셋(csv) 파일을 pandas 데이터 프레임으로 만들기


```python
import pandas as pd

def load_housing_data(housing_path=HOUSING_PATH, filename="housing.csv"):
  csv_path = os.path.join(housing_path, filename) # os.path.join("/datasets/housing", "housing.csv") -> /datasets/housing/housing.csv
  return pd.read_csv(csv_path) # 데이터 프레임 리턴
```

## 데이터 세트 확인 
- feature들에 대한 이해가 제일 중요하다. 어떻게 다룰 것인지, 무엇을 우선순위로 둘지 (feature에 의미가 없는 경우 -> 비정형데이터는 딥러닝으로 해결해야 한다.(텍스트 음성, 이미지))


```python
housing = load_housing_data()
housing.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>-122.23</td>
      <td>37.88</td>
      <td>41.0</td>
      <td>880.0</td>
      <td>129.0</td>
      <td>322.0</td>
      <td>126.0</td>
      <td>8.3252</td>
      <td>452600.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>1</th>
      <td>-122.22</td>
      <td>37.86</td>
      <td>21.0</td>
      <td>7099.0</td>
      <td>1106.0</td>
      <td>2401.0</td>
      <td>1138.0</td>
      <td>8.3014</td>
      <td>358500.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>2</th>
      <td>-122.24</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1467.0</td>
      <td>190.0</td>
      <td>496.0</td>
      <td>177.0</td>
      <td>7.2574</td>
      <td>352100.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1274.0</td>
      <td>235.0</td>
      <td>558.0</td>
      <td>219.0</td>
      <td>5.6431</td>
      <td>341300.0</td>
      <td>NEAR BAY</td>
    </tr>
    <tr>
      <th>4</th>
      <td>-122.25</td>
      <td>37.85</td>
      <td>52.0</td>
      <td>1627.0</td>
      <td>280.0</td>
      <td>565.0</td>
      <td>259.0</td>
      <td>3.8462</td>
      <td>342200.0</td>
      <td>NEAR BAY</td>
    </tr>
  </tbody>
</table>
</div>



### housing 데이터 알아보기
각 컬럼의 의미를 살펴보기

* longitude : 경도
* latitude : 위도
* housing_median_age : 중간 주택 연도
* total_rooms : 방의 총 개수
* total_bedrooms : 침실의 총 개수
* population : 인구
* households : 가구
* median_income : 중간 소득
* median_house_value : 중간 주택 가격
* ocean_proximity : 바다와의 거리

### 데이터의 기본 정보 확인 


```python
housing.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 20640 entries, 0 to 20639
    Data columns (total 10 columns):
     #   Column              Non-Null Count  Dtype  
    ---  ------              --------------  -----  
     0   longitude           20640 non-null  float64
     1   latitude            20640 non-null  float64
     2   housing_median_age  20640 non-null  float64
     3   total_rooms         20640 non-null  float64
     4   total_bedrooms      20433 non-null  float64
     5   population          20640 non-null  float64
     6   households          20640 non-null  float64
     7   median_income       20640 non-null  float64
     8   median_house_value  20640 non-null  float64
     9   ocean_proximity     20640 non-null  object 
    dtypes: float64(9), object(1)
    memory usage: 1.6+ MB
    


```python
housing['population'].unique
```




    <bound method Series.unique of 0         322.0
    1        2401.0
    2         496.0
    3         558.0
    4         565.0
              ...  
    20635     845.0
    20636     356.0
    20637    1007.0
    20638     741.0
    20639    1387.0
    Name: population, Length: 20640, dtype: float64>



### 결측치 확인


```python
housing.isna().sum()
```




    longitude               0
    latitude                0
    housing_median_age      0
    total_rooms             0
    total_bedrooms        207
    population              0
    households              0
    median_income           0
    median_house_value      0
    ocean_proximity         0
    dtype: int64



### 데이터프레임의 통계적 특징 확인

- `describe()` 메소드를 이용해 통계적 특징 확인


```python
housing.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20433.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>-119.569704</td>
      <td>35.631861</td>
      <td>28.639486</td>
      <td>2635.763081</td>
      <td>537.870553</td>
      <td>1425.476744</td>
      <td>499.539680</td>
      <td>3.870671</td>
      <td>206855.816909</td>
    </tr>
    <tr>
      <th>std</th>
      <td>2.003532</td>
      <td>2.135952</td>
      <td>12.585558</td>
      <td>2181.615252</td>
      <td>421.385070</td>
      <td>1132.462122</td>
      <td>382.329753</td>
      <td>1.899822</td>
      <td>115395.615874</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-124.350000</td>
      <td>32.540000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>0.499900</td>
      <td>14999.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-121.800000</td>
      <td>33.930000</td>
      <td>18.000000</td>
      <td>1447.750000</td>
      <td>296.000000</td>
      <td>787.000000</td>
      <td>280.000000</td>
      <td>2.563400</td>
      <td>119600.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-118.490000</td>
      <td>34.260000</td>
      <td>29.000000</td>
      <td>2127.000000</td>
      <td>435.000000</td>
      <td>1166.000000</td>
      <td>409.000000</td>
      <td>3.534800</td>
      <td>179700.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>-118.010000</td>
      <td>37.710000</td>
      <td>37.000000</td>
      <td>3148.000000</td>
      <td>647.000000</td>
      <td>1725.000000</td>
      <td>605.000000</td>
      <td>4.743250</td>
      <td>264725.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>-114.310000</td>
      <td>41.950000</td>
      <td>52.000000</td>
      <td>39320.000000</td>
      <td>6445.000000</td>
      <td>35682.000000</td>
      <td>6082.000000</td>
      <td>15.000100</td>
      <td>500001.000000</td>
    </tr>
  </tbody>
</table>
</div>



숫자로 확인도 좋지만 best는 **시각화** 하는 것

### 시각화 - 데이터의 형태를 빠르게 검토


```python
import matplotlib.pyplot as plt
```


```python
housing.hist(
    bins=50,
    figsize = (20, 15)
)

plt.show()
```


    
![png](output_19_0.png)
    


![output_19_0](https://github.com/user-attachments/assets/66481bf5-f6a4-4e16-88b9-050932234aa1)

## 테스트 세트 만들기


```python
from sklearn.model_selection import train_test_split

train_set, test_set = train_test_split(
    housing,
    test_size = 0.2,
    random_state= 42
)
```


```python
housing['median_income'].hist()
train_set['median_income'].hist()
test_set['median_income'].hist()
```




    <Axes: >




    
![png](output_23_1.png)
    


![output_22_1](https://github.com/user-attachments/assets/0e254bb9-6b94-4d9b-b87c-1425979ee6f7)


```python
import numpy as np

#income_cat : 소득 구간
housing['income_cat'] = pd.cut(
    housing['median_income'],   # 구간 분할 대상 데이터(연속형 데이터)
    bins = [0.0, 1.5 , 3.0, 4.5, 6.0 , np.inf],
    labels=[1, 2, 3, 4, 5]
)

housing[['median_income' , 'income_cat']].head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>median_income</th>
      <th>income_cat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>8.3252</td>
      <td>5</td>
    </tr>
    <tr>
      <th>1</th>
      <td>8.3014</td>
      <td>5</td>
    </tr>
    <tr>
      <th>2</th>
      <td>7.2574</td>
      <td>5</td>
    </tr>
    <tr>
      <th>3</th>
      <td>5.6431</td>
      <td>4</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3.8462</td>
      <td>3</td>
    </tr>
  </tbody>
</table>
</div>



어떻게 구간 분할을 할 것인가?


```python
housing.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20433.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
      <td>20640.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>-119.569704</td>
      <td>35.631861</td>
      <td>28.639486</td>
      <td>2635.763081</td>
      <td>537.870553</td>
      <td>1425.476744</td>
      <td>499.539680</td>
      <td>3.870671</td>
      <td>206855.816909</td>
    </tr>
    <tr>
      <th>std</th>
      <td>2.003532</td>
      <td>2.135952</td>
      <td>12.585558</td>
      <td>2181.615252</td>
      <td>421.385070</td>
      <td>1132.462122</td>
      <td>382.329753</td>
      <td>1.899822</td>
      <td>115395.615874</td>
    </tr>
    <tr>
      <th>min</th>
      <td>-124.350000</td>
      <td>32.540000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>0.499900</td>
      <td>14999.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>-121.800000</td>
      <td>33.930000</td>
      <td>18.000000</td>
      <td>1447.750000</td>
      <td>296.000000</td>
      <td>787.000000</td>
      <td>280.000000</td>
      <td>2.563400</td>
      <td>119600.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>-118.490000</td>
      <td>34.260000</td>
      <td>29.000000</td>
      <td>2127.000000</td>
      <td>435.000000</td>
      <td>1166.000000</td>
      <td>409.000000</td>
      <td>3.534800</td>
      <td>179700.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>-118.010000</td>
      <td>37.710000</td>
      <td>37.000000</td>
      <td>3148.000000</td>
      <td>647.000000</td>
      <td>1725.000000</td>
      <td>605.000000</td>
      <td>4.743250</td>
      <td>264725.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>-114.310000</td>
      <td>41.950000</td>
      <td>52.000000</td>
      <td>39320.000000</td>
      <td>6445.000000</td>
      <td>35682.000000</td>
      <td>6082.000000</td>
      <td>15.000100</td>
      <td>500001.000000</td>
    </tr>
  </tbody>
</table>
</div>



['median_income'] : 최솟값 ~ 최댓값의 75%에 몰려있다 => 앞쪽에도 데이터가 분포하도록 잘라줘야함

시각화로 판단 : 0-6까지 많이 몰려있으니 이 구간을 공평하게 잘라주겠다.
6~는 하나의 구간으로 잡는다. (데이터가 많이 없으니)




```python
housing['income_cat'].hist()
```




    <Axes: >




    
![png](output_29_1.png)
    


![output_27_1](https://github.com/user-attachments/assets/97cf3d9d-da23-4e57-af57-648577a382bf)


```python
어느정도 공평하게 잘라진 것 같다.
너무 정규분포에 집착하지 말 것
```


```python
trina_set,  test_set = train_test_split(
    housing,
    test_size = 0.2,
    random_state = 42,
    stratify = housing['income_cat']
    
)
```


```python
housing['median_income'].hist()
train_set['median_income'].hist()
test_set['median_income'].hist()
```




    <Axes: >




    
![png](output_33_1.png)
    


![output_30_1](https://github.com/user-attachments/assets/0c2c619c-4f4b-40be-b146-4bf384a1aefa)

## 랜덤 vs 계층 분할


```python
def income_cat_proportions(data):
    return data["income_cat"].value_counts() / len(data)

# 1. 랜덤 분할
train_set, test_set = train_test_split(
    housing,
    test_size=0.2,
    random_state=42
)

# 2. 계층 분할
train_set_strat, test_set_strat = train_test_split(
    housing,
    test_size=0.2,
    random_state=42,
    stratify=housing['income_cat']
)

compare_props = pd.DataFrame({
    "전체": income_cat_proportions(housing),
    "계층 샘플링": income_cat_proportions(test_set_strat),
    "무작위 샘플링": income_cat_proportions(test_set),
}).sort_index()

compare_props["무작위 샘플링 오류율"] = 100 * compare_props["무작위 샘플링"] / compare_props["전체"] - 100
compare_props["계층 샘플링 오류율"] = 100 * compare_props["계층 샘플링"] / compare_props["전체"] - 100
compare_props
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>전체</th>
      <th>계층 샘플링</th>
      <th>무작위 샘플링</th>
      <th>무작위 샘플링 오류율</th>
      <th>계층 샘플링 오류율</th>
    </tr>
    <tr>
      <th>income_cat</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>0.039826</td>
      <td>0.039971</td>
      <td>0.040213</td>
      <td>0.973236</td>
      <td>0.364964</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.318847</td>
      <td>0.318798</td>
      <td>0.324370</td>
      <td>1.732260</td>
      <td>-0.015195</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.350581</td>
      <td>0.350533</td>
      <td>0.358527</td>
      <td>2.266446</td>
      <td>-0.013820</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.176308</td>
      <td>0.176357</td>
      <td>0.167393</td>
      <td>-5.056334</td>
      <td>0.027480</td>
    </tr>
    <tr>
      <th>5</th>
      <td>0.114438</td>
      <td>0.114341</td>
      <td>0.109496</td>
      <td>-4.318374</td>
      <td>-0.084674</td>
    </tr>
  </tbody>
</table>
</div>




```python
train_set, test_set = train_test_split(
    housing,
    test_size=0.2,
    random_state=42,
    stratify=housing['income_cat']
)
```

## EDA - 탐색적 데이터 분석

탐색적 데이터 분석 프로세스의 초기 단계에서 수행되는 매우 중요한 작업이다.
왜 하냐 ? 주어진 데이터의 주요 특성을 이해하고, 데이터에 숨겨진 패턴, 이상치, 구조 등을 탐색하는 과정이다.
따라서 크게 두 가지 방법으로 수행될 수 있다.

1. 시각화 : 차트나 그림 등을 그려 데이터의 분포나 변수 간 관계 파악
2. 통계 : 평균, 중앙값 , 이상치 등과 같은 요약 통계 정보를 사용하여 변수의 특성을 살펴보는 방법이다.

데이터를 잘라놓고 EDA를 진행해야한다.
 - -> test.train 자른 후, train만 EDA를 진행한다.


```python
housing = train_set.copy()
```


```python
plt.figure(figsize = (10,7))

plt.scatter(
    x= housing['longitude'],
    y= housing['latitude']
)
```




    <matplotlib.collections.PathCollection at 0x1ea6b144690>




    
![png](output_42_1.png)
    


![output_38_1](https://github.com/user-attachments/assets/41a62668-d7fa-4b46-87ce-dbb7d95c3fef)

EDA 가설 세워보기 
-  1. 집이 많이 밀집될수록 비쌀까? ->
EDA 가설 확인
- 밀집도 확인 alpha 부여해보자


```python
plt.figure(figsize = (10,7))

plt.scatter(
    x= housing['longitude'],
    y= housing['latitude'],
    alpha = 0.1
)
```




    <matplotlib.collections.PathCollection at 0x1ea6b571e50>




    
![png](output_45_1.png)
    


![output_40_1](https://github.com/user-attachments/assets/2e171cd1-7a6b-40f0-8c1e-9d8e973d15f2)

인구 수 , 집 가격을 포함해서 시각화


```python
plt.figure(figsize=(10, 7))

plt.scatter(
    x=housing['longitude'],
    y=housing['latitude'],
    alpha=0.1,
    s=housing['population'] / 100, # 인구수가 많으면 많을 수록 점이 커짐
    label="Population",
    c=housing['median_house_value'], # 집 가격에 따라 색이 변화될 수 있도록 설정
    cmap=plt.get_cmap('jet') # 컬러 테마
)
plt.legend()
plt.colorbar()
plt.show()
```


    
![png](output_48_0.png)
    


![output_42_0](https://github.com/user-attachments/assets/f477566b-4d4d-4232-bc10-53cf40156811)


```python
# Download the California image
images_path = os.path.join(".", "images", "end_to_end_project")
os.makedirs(images_path, exist_ok=True)
DOWNLOAD_ROOT = "https://raw.githubusercontent.com/ageron/handson-ml2/master/"
filename = "california.png"
print("Downloading", filename)
url = DOWNLOAD_ROOT + "images/end_to_end_project/" + filename
urllib.request.urlretrieve(url, os.path.join(images_path, filename))

import matplotlib.image as mpimg
california_img=mpimg.imread(os.path.join(images_path, filename))
ax = housing.plot(kind="scatter", x="longitude", y="latitude", figsize=(10,7),
                       s=housing['population']/100, label="Population",
                       c="median_house_value", cmap=plt.get_cmap("jet"),
                       colorbar=True, alpha=0.4,

                      )
plt.imshow(california_img, extent=[-124.55, -113.80, 32.45, 42.05], alpha=0.5,
           cmap=plt.get_cmap("jet"))
plt.ylabel("Latitude", fontsize=14)
plt.xlabel("Longitude", fontsiㅠze=14)

plt.legend(fontsize=16)
plt.show()
```

    Downloading california.png
    


    
![png](output_50_1.png)
    


![output_43_1](https://github.com/user-attachments/assets/badeda21-3642-4a8b-836a-803318202494)

- 무작정 해안가라고 해서 집값이 비싸진 않다.
  - 북쪽에는 인구도 많이 없고 집도 싸다.
  - 내륙쪽에도 비싼집이 몰려있는 구간이 종종 있다.

## 상관관계 조사하기(SCC - Standard Correlation Coefficient)

- 표준 상관계수 조사
- 피어슨 상관계수 ( 피어슨의 $r$)
- 데이터끼리 얼마나 영향을 미치나에 대한 수치
  - $x$가 증가 하면 $y$는 어떻게 증가/감소 하는가?
- -1 ~ 1로 표현


```python
corr_matrix = housing.drop("ocean_proximity", axis=1).corr()
corr_matrix['median_house_value'].sort_values(ascending=False)
```




    median_house_value    1.000000
    median_income         0.687151
    income_cat            0.642256
    total_rooms           0.135140
    housing_median_age    0.114146
    households            0.064590
    total_bedrooms        0.047781
    population           -0.026882
    longitude            -0.047466
    latitude             -0.142673
    Name: median_house_value, dtype: float64



## 데이터와 데이터의 관계
### 1. 분산 ( variance )
- 데이터에 대한 이산정도를 나타낸다.
  - 이산 정도 : 데이터의 펼쳐짐 정도
- 편차 제곱의 평균

$$
\sigma^{2} = \frac{1}{n}\sum_{i=1}^n{(x_i-\bar{x})^2}\\(\bar{x}:평균)
$$




```python
import numpy as np

data1 = np.array([80, 85, 90, 95, 100])
data2 = np.array([50, 70, 90, 110, 130])

data1.mean(), data2.mean()
```




    (90.0, 90.0)




```python
# 분산
data1.var(), data2.var()
```




    (50.0, 800.0)



### 2. 표준편차

통계적으로 이야기 할 때는 표준편차를 더 많이 쓴다.

$$
\sigma = \sqrt{\sigma^{2}}
$$


```python
data1.std(), data2.std()
```




    (7.0710678118654755, 28.284271247461902)



### 3. 공분산 ( covariance )


- 두 데이터 집단간의 상관정도를 나타낸다.
- 평균 편차곱
- **방향성**은 보여줄 수 있으나, 강도(세기)를 나타내는데는 한계가 있다.
  - 표본 데이터의 크기에 따라서 값의 차이가 큰 단점이 있다.

$$ \text{cov} = \frac{1}{n}\sum_{i=1}^{n}{(x_i-\bar{x})(y_i-\bar{y})}\\ (\bar{x}:x의 평균, \bar{y}:y의 평균) $$


```python
def covariance(data1, data2):
  x_ = np.mean(data1) # data1의 평균
  y_ = np.mean(data2) # data2의 평균

  return np.sum((data1 - x_) * (data2 - y_)) / len(data1) - 1

```


```python
data1 = np.array([80, 90, 100, 90, 80])
data2 = np.array([70, 80, 90, 80, 70])

covariance(data1, data2)
```




    55.0




```python
data3 = [80, 85, 90, 85, 80]
data4 = [90, 85, 80, 85, 90]

covariance(data3, data4)
```




    -15.0



공분산에서 숫자 15 자체는 의미없다.
부호만 확인 ( 방향성)


```python
data5 = [800, 850, 900, 850, 800]
data6 = [900, 850, 800, 850, 900]

covariance(data5, data6)
```




    -1401.0



data3,data4 -> data5,data6 스케일 변화
 - 데이터의 스케일이 다르면 공분산의 차이가 커진다.
- 숫자 자체의 의미는 역시 없다. 부호만 확인 하자.

### 4.상관계수


- 공분산의 한계를 극복하기 위해서 만들어짐
  - 공분산은 데이터의 방향성만 판단이 가능
- `-1 ~ 1` 까지의 실수를 가지며, 0과 가까울수록 상관도가 적다는 것을 의미

$$
 \text{correlation-coefficient} = \frac{공분산}{\sqrt{{x분산} \cdot {y분산}}}
$$

$$
r = \frac{\sum(x-\bar{x})(y-\bar{y})}{\sqrt{{\sum(x-\bar{x})^2}\cdot{\sum(y-\bar{y})^2}}}
$$


```python
# 상관계수 구현하기
def corrcoef(data1, data2):
  x_ = np.mean(data1)
  y_ = np.mean(data2)

  # 분모( x의 분산 * y의 분산)
  x_y_var = np.sum((data1 - x_) ** 2) * np.sum((data2 - y_)**2)
  # 분자( 공분산 )
  x_y_cov = np.sum( (data1-x_)*(data2-y_))

  return x_y_cov / np.sqrt(x_y_var)
```

data1과 data2 모두 증가할 때 증가하고, 감소할 때 감소


```python
data1 = np.array([80, 85, 100, 90, 95])
data2 = np.array([70, 75, 85, 80, 83])

corrcoef(data1, data2)
```




    0.9837827088491458



따라서 상관계수의 값이 높은 것을 확인할 수 있다.


```python
data3 = np.array([10, 20, 30, 40, 50])
data4 = np.array([6, 5, 6, 5, 7])

corrcoef(data3, data4)
```




    0.37796447300922725



둘 사이의 관계가 별로 없기 때문에 상관관계가 낮음을 확인할 수 있다.


```python
data5 = np.array([80, 85, 100, 90, 95])
data6 = np.array([100, 90, 70, 90, 80])

corrcoef(data5, data6)
```




    -0.970725343394151




```python
data5 = np.array([800, 850, 1000, 900, 950])
data6 = np.array([1000, 900, 700, 900, 800])

corrcoef(data5, data6)
```




    -0.970725343394151



스케일을 키워도 값 자체는 변하지 않음을 확인할 수 있다.

### 5. 피어슨 상관계수 $r$


- $0 \leq |r| \ \leq 1$
  - $0 \leq |r| \ \leq 0.3$ : 약한 상관 관계
  - $0.3 \leq |r| \ \leq 0.7$ : 보통의 상관 관계
  - $0.7 \leq |r| \ \leq 1$ : 강한 상관 관계


```python
from pandas.plotting import scatter_matrix
feature_names = ["median_house_value", "median_income", "total_rooms", "housing_median_age"]

scatter_matrix(housing[feature_names], figsize = (12,8))
plt.show()
```


    
![png](output_84_0.png)
    


![output_76_0](https://github.com/user-attachments/assets/2a26101a-9466-4e1a-a097-aa9e6de3581b)

## 특성 조합 (Feature Combination)

- **두 개 이상의 특성을 조합해서 새로운 특성 생성**
- 비율 구하기
- 관계 설정(곱셈)
- 다항식 등등 ..



```python
# 가구당 방의 비율 구해보기
housing['rooms_per_household'] = housing['total_rooms']/housing['households']
housing['bedrooms_per_room'] = housing['total_bedrooms'] / housing['total_rooms'] 
housing['population_per_household'] = housing['population'] / housing['households']
```


```python
housing.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>longitude</th>
      <th>latitude</th>
      <th>housing_median_age</th>
      <th>total_rooms</th>
      <th>total_bedrooms</th>
      <th>population</th>
      <th>households</th>
      <th>median_income</th>
      <th>median_house_value</th>
      <th>ocean_proximity</th>
      <th>income_cat</th>
      <th>rooms_per_household</th>
      <th>bedrooms_per_room</th>
      <th>population_per_household</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12655</th>
      <td>-121.46</td>
      <td>38.52</td>
      <td>29.0</td>
      <td>3873.0</td>
      <td>797.0</td>
      <td>2237.0</td>
      <td>706.0</td>
      <td>2.1736</td>
      <td>72100.0</td>
      <td>INLAND</td>
      <td>2</td>
      <td>5.485836</td>
      <td>0.205784</td>
      <td>3.168555</td>
    </tr>
    <tr>
      <th>15502</th>
      <td>-117.23</td>
      <td>33.09</td>
      <td>7.0</td>
      <td>5320.0</td>
      <td>855.0</td>
      <td>2015.0</td>
      <td>768.0</td>
      <td>6.3373</td>
      <td>279600.0</td>
      <td>NEAR OCEAN</td>
      <td>5</td>
      <td>6.927083</td>
      <td>0.160714</td>
      <td>2.623698</td>
    </tr>
    <tr>
      <th>2908</th>
      <td>-119.04</td>
      <td>35.37</td>
      <td>44.0</td>
      <td>1618.0</td>
      <td>310.0</td>
      <td>667.0</td>
      <td>300.0</td>
      <td>2.8750</td>
      <td>82700.0</td>
      <td>INLAND</td>
      <td>2</td>
      <td>5.393333</td>
      <td>0.191595</td>
      <td>2.223333</td>
    </tr>
    <tr>
      <th>14053</th>
      <td>-117.13</td>
      <td>32.75</td>
      <td>24.0</td>
      <td>1877.0</td>
      <td>519.0</td>
      <td>898.0</td>
      <td>483.0</td>
      <td>2.2264</td>
      <td>112500.0</td>
      <td>NEAR OCEAN</td>
      <td>2</td>
      <td>3.886128</td>
      <td>0.276505</td>
      <td>1.859213</td>
    </tr>
    <tr>
      <th>20496</th>
      <td>-118.70</td>
      <td>34.28</td>
      <td>27.0</td>
      <td>3536.0</td>
      <td>646.0</td>
      <td>1837.0</td>
      <td>580.0</td>
      <td>4.4964</td>
      <td>238300.0</td>
      <td>&lt;1H OCEAN</td>
      <td>3</td>
      <td>6.096552</td>
      <td>0.182692</td>
      <td>3.167241</td>
    </tr>
  </tbody>
</table>
</div>




```python
corr_matrix = housing.drop("ocean_proximity", axis=1).corr()
corr_matrix["median_house_value"].sort_values(ascending=False)
```




    median_house_value          1.000000
    median_income               0.687151
    income_cat                  0.642256
    rooms_per_household         0.146255
    total_rooms                 0.135140
    housing_median_age          0.114146
    households                  0.064590
    total_bedrooms              0.047781
    population_per_household   -0.021991
    population                 -0.026882
    longitude                  -0.047466
    latitude                   -0.142673
    bedrooms_per_room          -0.259952
    Name: median_house_value, dtype: float64



## 머신러닝을 휘한 데이터 준비

 - 데이터에 대한 각종 전처리를 수행하는 **파이프라인 생성**
 - 사이킷런의 **Simpleimputer** 는 누락값을 채우는 클래스
 -  파이프라인을 구축하고자 할 때 사이킷런 류의 클래스를 사용해야 한다. 판다스의 기능으로는 파이프라인을 구성하기 어렵다.



```python
### 필요없는 Feature 제거 
housing = housing.drop("income_cat" , axis = 1)

#Feature , Lable 분리
label_name = "median_house_value"

#Lable만 꺼내오기
housing_label = housing[label_name].copy()

#Feature
housing = housing.drop(label_name, axis = 1)
```

### NaN 값 처리

- 데이터 샘플을 제거(행 삭제)
- 아예 컬럼을 제거
  - 한 컬럼에 NaN값이 너무나 많은 경우
- 특정 값으로 채우기
  - 0, 평균, 중간값 등등..
  - 데이터가 충분하다면 NaN값을 예측하기 위한 모델을 만들어서 예측값으로 채우는 경우도 있다.
- 판다스의 `fillna`, `dropna`


```python
# 사이킷런의 SimpleImputer는 누락값을 채우는 클래스
from sklearn.impute import SimpleImputer

imputer = SimpleImputer(strategy='median') # 누락값을 중간값으로 채우기
```


```python
# 머신러닝 데이터 전처리를 수행할 때 
# 연속형 데이터 / 범주형 데이터 따로 관리

# 연속형 데이터만 모아낼 DF를 새롭게 생성
housing_num = housing.drop("ocean_proximity" , axis = 1)
housing_num.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Index: 16512 entries, 12655 to 19773
    Data columns (total 11 columns):
     #   Column                    Non-Null Count  Dtype  
    ---  ------                    --------------  -----  
     0   longitude                 16512 non-null  float64
     1   latitude                  16512 non-null  float64
     2   housing_median_age        16512 non-null  float64
     3   total_rooms               16512 non-null  float64
     4   total_bedrooms            16354 non-null  float64
     5   population                16512 non-null  float64
     6   households                16512 non-null  float64
     7   median_income             16512 non-null  float64
     8   rooms_per_household       16512 non-null  float64
     9   bedrooms_per_room         16354 non-null  float64
     10  population_per_household  16512 non-null  float64
    dtypes: float64(11)
    memory usage: 2.0 MB
    


```python
X = imputer.fit_transform(housing_num)
```


```python
housing_tr = pd.DataFrame(
    X, # NaN값이 채워진 배열
    columns=housing_num.columns,
    index=housing_num.index
)

housing_tr.info()
```

    <class 'pandas.core.frame.DataFrame'>
    Index: 16512 entries, 12655 to 19773
    Data columns (total 11 columns):
     #   Column                    Non-Null Count  Dtype  
    ---  ------                    --------------  -----  
     0   longitude                 16512 non-null  float64
     1   latitude                  16512 non-null  float64
     2   housing_median_age        16512 non-null  float64
     3   total_rooms               16512 non-null  float64
     4   total_bedrooms            16512 non-null  float64
     5   population                16512 non-null  float64
     6   households                16512 non-null  float64
     7   median_income             16512 non-null  float64
     8   rooms_per_household       16512 non-null  float64
     9   bedrooms_per_room         16512 non-null  float64
     10  population_per_household  16512 non-null  float64
    dtypes: float64(11)
    memory usage: 2.0 MB
    

### 범주형 데이터 처리

- `ocean_proximity`는 문자열 데이터이면서, 범주형(Categorical) 데이터
  - OneHotEncoding을 수행


```python
housing_cat = housing[["ocean_proximity"]]
housing_cat.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ocean_proximity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12655</th>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>15502</th>
      <td>NEAR OCEAN</td>
    </tr>
    <tr>
      <th>2908</th>
      <td>INLAND</td>
    </tr>
    <tr>
      <th>14053</th>
      <td>NEAR OCEAN</td>
    </tr>
    <tr>
      <th>20496</th>
      <td>&lt;1H OCEAN</td>
    </tr>
  </tbody>
</table>
</div>




```python
from sklearn.preprocessing import OneHotEncoder

cat_encoder = OneHotEncoder()
housing_cat_one_hot = cat_encoder.fit_transform(housing_cat)
```


```python
housing_cat_one_hot_df = pd.DataFrame(
    housing_cat_one_hot.toarray(),
    columns = cat_encoder.categories_,
    index = housing_cat.index
)

housing_cat_one_hot_df.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>&lt;1H OCEAN</th>
      <th>INLAND</th>
      <th>ISLAND</th>
      <th>NEAR BAY</th>
      <th>NEAR OCEAN</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>12655</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>15502</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2908</th>
      <td>0.0</td>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>14053</th>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>20496</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
</div>



- 특성조합도 결국 데이터를 '의미있게' 변환시킨 것이다.
- 이 데이터의 변환 내용도 사이킷런의 일부로 변환시킬 수 있지 않을까?
  + -> 사용자 정의 트랜스포머 (사이킷런에서 제공하지 않는 트렌스포머를 만들어보자 : 클래스 상속)



## 사용자 정의 Transformer 만들기

- 비즈니스 로직을 위한 특성 공학을 데이터에 적용
  - 사이킷 런에서는 제공하지 않는 데이터 변환이 있다.
    - 방의 비율, 가구 수 대비 인구수의 비율을 구하거나 등등..
    - 우리가 직접 짜야 할 변환 과정
      - 사이킷런에는 없는 작업
      - 우리가 직접 로직을 만들어서 사이킷런에 포함될 수 있도록 설정

---
- 사이킷런의 `BaseEstimator` 클래스 상속
  - 개발한 클래스가 사이킷런 소속에 포함될 수 있도록 해준다.
- 사이킷런의 `TransformerMixin` 클래스 상속
  - `fit_transform()` 자동 구현

### ***Duck Typing 문법***

- ***메소드의 구현***에 의해서 ***클래스의 정체성이 결정***되는 현상
- `fit()`, `transform()` 메소드를 클래스 내에 정의함에 따라서 사이킷런이 `Transformer`로 인식 한다.

사용할 컬럼의 인덱스 확인 - 컬럼명을 사용 못하기 때문


```python
housing.columns
```




    Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',
           'total_bedrooms', 'population', 'households', 'median_income',
           'ocean_proximity', 'rooms_per_household', 'bedrooms_per_room',
           'population_per_household'],
          dtype='object')




```python
# 상속 받을 클래스 가져오기
from sklearn.base import BaseEstimator, TransformerMixin

rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6

class CombinedAttributeAdder(BaseEstimator, TransformerMixin):

  # population_per_households 특성 조합을 해봤는데, 딱히 효과가 없는 것 같다.
  #  개발자의 선택에 따라서 추가 할지 말지에 대한 설정값 추가
  def __init__(self, add_population_per_households=True):
    self.add_population_per_households = add_population_per_households

  # fit은 transform을 하기위한 데이터 준비과정이 필요하다. 데이터를 입력 받고, transform에서 변환하기 위한 데이터를 준비
  # 아무것도 안하는데 X를 받는 이유 : Transformer의 Duck Typing 문법을 적용하기 위해
  def fit(self, X):
    return self

  # X에 전체 데이터 들어옴. 여기서 3,4,5,6번 데이터를 가지고 와서
  #  비율을 구하는 특성 공학 수행
  def transform(self, X):
    rooms_per_households = X[:, rooms_ix] / X[:, households_ix]
    bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]

    if self.add_population_per_households:
      population_per_households = X[:, population_ix] / X[:, households_ix]
      return np.c_[X, rooms_per_households, bedrooms_per_room, population_per_households]
    else:
      return np.c_[X, rooms_per_households, bedrooms_per_room]



```

특성공학에 사용된 컬럼 삭제


```python
housing.drop(['rooms_per_household', 'bedrooms_per_room','population_per_household'], axis=1, inplace=True)
housing.columns
```




    Index(['longitude', 'latitude', 'housing_median_age', 'total_rooms',
           'total_bedrooms', 'population', 'households', 'median_income',
           'ocean_proximity'],
          dtype='object')




```python
housing.values
```




    array([[-121.46, 38.52, 29.0, ..., 706.0, 2.1736, 'INLAND'],
           [-117.23, 33.09, 7.0, ..., 768.0, 6.3373, 'NEAR OCEAN'],
           [-119.04, 35.37, 44.0, ..., 300.0, 2.875, 'INLAND'],
           ...,
           [-122.72, 38.44, 48.0, ..., 172.0, 3.1797, '<1H OCEAN'],
           [-122.7, 38.31, 14.0, ..., 501.0, 4.1964, '<1H OCEAN'],
           [-122.14, 39.97, 27.0, ..., 197.0, 3.1319, 'INLAND']], dtype=object)




```python
attr_adder = CombinedAttributeAdder()
housing_extra_attribs = attr_adder.fit_transform(housing.values)
housing_extra_attribs[:3]
```




    array([[-121.46, 38.52, 29.0, 3873.0, 797.0, 2237.0, 706.0, 2.1736,
            'INLAND', 5.485835694050992, 0.20578363026077975,
            3.168555240793201],
           [-117.23, 33.09, 7.0, 5320.0, 855.0, 2015.0, 768.0, 6.3373,
            'NEAR OCEAN', 6.927083333333333, 0.16071428571428573,
            2.6236979166666665],
           [-119.04, 35.37, 44.0, 1618.0, 310.0, 667.0, 300.0, 2.875,
            'INLAND', 5.3933333333333335, 0.1915945611866502,
            2.223333333333333]], dtype=object)


