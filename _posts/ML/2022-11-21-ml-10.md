---
title:  "[ML] "
layout: single

categories: "ML"
tags: ["머신러닝"]

toc: true
toc_sticky: true
toc_label : "목차"
toc_icon: "bars"

published: false
---

<small>학습 목표 : 머신러닝 파이프라인 구축(문제 이해, 데이터 샘플 준비, 모형 구축) 방법에 대해 알아본다.</small>

***

# <span class="half_HL">✔️ 학습 목표</span>
- 문제 이해
- 데이터 샘플 준비
- 모형 구축
- 구축된 모형으로 실제 데이터 검증
- 구축된 모형을 공개하고 유지 보수

# <span class="half_HL">✔️ 머신러닝 프로세스</span>
비즈니스에 대한 이해가 필요합니다. 본인이 가지고 있는 다양한 문제 상황에 대한 적절한 이해가 있어야 한다. 내가 무엇을 예측하고 싶은지, 어ㄷ느 정도 정확하도록 성능 모형 학습할지 

내가 해결하고자 하는 문제에 대한 정확한 이해 필요
뭘 예측? 어느정도 ㅇ정확하도록  또는 어느 정도의 성능으로 모형을 학습해야하는지 학습된 모형을 어떤 방식으로 활용할지에 따라서도 뒤에 이루어지는 작업이 달라짐

배경지식에 대한 이해가 잘 되어있따면 데이터 언더스텐딩 
데이터들이 나오는데 거기서 나온 배경을 이해했고, 거기서 나온데이터가 있잖아요 거기서 생긴 데이터가 어떤 구조인지 어떤 부분을 변수로 삼아야하는지 어떻게 처리해야하는지 구체적인 데이터 자체에 대한 구체적인 이해 하는 과정이 필요함

배경지식과 데이터 자체에 대한 확실한 이해가 수반되어야 한다.

이를 기반으로 데이터를 준비할 수 있음, 준비된 상황에서 모델을 학습시킴
대략적인 모양의 구조를 갖추고 모양을 가지고 학습을 시키고 학습된 모양이 최적의 어느 성능을 낼수있게 잘 활용한다.

데이터는 Training Data, Test Data(검증용)로 나눌 수 있음
트레이닝 데이터는 모형에 넣어서 학습을 시킨다. -> 함수가 도출 될 것이다 f()
학습된 함수를 가지고 실제 상황에서 잘 활용이 되는지 검증하기 위해 학습에 사용하지 않았던 train 데이터를 적용해서 예측하고 실력 검증

최종적인 목표가 됨에도 불구하고 모형을 세우는 과정에 과몰입하게 되고 모형만 잘 세우면 끝아니낙? 하고 말게 되는데 검증하고 최선의 모형 찾는것이 중요하다.

모형을 실제 문제 상황에 사용하는 경우, 서비스를 한다거나 하면 디플로이먼트를 고민해야함
학습한 어떤 최적의 모형이 있어서 사용하는데 많은 문제들ㅇ이 생길 수 있음

실시간으로 예측해주고 결과를 알려줘야하는데 계산과정이 복잡해서 겨과가 늦게 나온다던지..
적용관계에서 어느정도 이상 수준의 정확도를 좀 꾸준하게 편차언ㅂㅅ이 보여줘야하는데 그렇지 않다던지...

활용해야겠죠 거기서 나온 지식이나 최종적인 모형을 가지고 액션을 취하거나... 그런 현실적인 부분들은 관련된 현업 업무를 하는 과정에서 경험하게 될 것임.

데이터 준ㅂ미 이해 학습 단계 !

# <span class="half_HL">✔️ 데이터 관련 용어</span>
- **Dataset**
  - 정의된 구조로 모아져 있는 데이터 집합
- **Data Point (Observation)**
  - 데이터 세트에 속해 있는 하나의 관측치
- **Feature (Variable, Attribute)**
  - 데이터를 구성하는 하나의 특성
    - 숫자형, 범주형, 시간, 텍스트, 이진형
- **Label (Target, Response)**
  - 입력 변수들에 의해 예측, 분류되는 출력 변수

예 : 키, 나이, 몸무게로 혈압을 예측해 본다면 10명을 대상으로 각 정보를 얻을 수 있음
전체 데이터가 데이터셋이 됨
관측치는 한 사람, 두 사람. 이렇게 관측 대상에 대해 관측치!
피처는 키, 나이, 몸무게가 관측치를 규정하는 특성이 됨
테스크에서 예측하고 싶은것이 혈압 -> 타겟 

- 출력 변수(y), 입력 변수(x)
- 관측치
- 관측치의 개수(n), Feature의 수(p)

<br>

# <span class="half_HL">✔️ 분류와 회귀</span>
종속변수가 범주형이냐 연속형이냐에 따라 분류와 회귀로 나누어진다

회귀는 둘 간의 상관관계를 표현해 줄 수 있는 함수를 찾는 것이다.

||분류(Classification) |회귀(Regression)|
|:--|:----|:----|
|결과 |종속변수(y)가 범주형일 때| 종속변수(y)가 연속형일 때|
|예제 |입력된 보험 청구권에 대해서 자동 심사와 인심사 분류 |날씨, 유가, 경제 지표 등을 이용한 주가 예측|

<br>

# <span class="half_HL">✔️ 데이터 준비 과정</span>
- Dataset Exploration
  - 데이터 모델링을 하기 전에 데이터 변수 별 기본적인 특성들을 탐색하고 데이터의 분포적인 특징 이해
  - 사분위수, 평균, 중간값 등을 파악해서 어떤 특징을 가지고 있는지 파악
  - 데이터가 의미있는 데이터가 맞는지, 잘 수집이 되어있는 것인지, 문제가 없는지를 파악
  - Garbage In Garbage Out(GIGO) 방지
  - EDA(Exploratory Data Analysis) 라고도 부름
- Missing Value
  - 데이터를 수집하다 보면 일부 데이터가 수집되지 않고 결측치로 남아 있는 경우가 있어서 이러한 부분 보정 필요
  - 이런 결측치로 인해 제대로 계산되지 않고 오류를 일으키는 문제가 발생할 수 있음
  - 미리 처리해 줘야 함(결측치 고정/삭제 등)
- Data Types and Conversion
  - 데이터셋 안에 여러 종류의 데이터 타입(숫자, 텍스트, 범주, 시간 등)이 있을 수 있고, 이를 분석이 가능한 형태로 변환 후 사용해야 함
  - 머신러닝 모형에 적용하기 위해선 숫자, 벡터 등 컴퓨터가 계산할 수 있는 형태로 변형해줘야 함

**EDA -> Data 정제 -> Machine Learning**

머신러닝 모양을 학습하는 과정에서 60 ~ 70% 정도의 시간은 데이터 준비에 시간 소요, 20 ~ 30 % 모형 학습시키고 검증하는 단계, 그 후 배포하는 단계로 이어짐

- Normalization
  - 데이터 변수들의 단위가 크게 다른 경우들이 있고 이러한 것들이 모델 학습에 영향을 주는 경우가 있어서 정규화 필요
  - 예 : 집 평수(10 ~ 100 단위), 집 값(억 단위)
  - 대표적인 방법 : 평균을 빼고 표준편차로 나눠줌

- Outlers
  - 관측치 중에서 다른 관측치와 크게 차이나는 관측치들이 있고 이러한 관측치들은 모델링 전 처리가 필요함

- Feature Selection
  - 많은 변수 중에서 모델링을 할 때 중요한 변수가 있고 그렇지 않은 변수가 있어서 선택이 필요한 경우가 있음
  - 예 : 반도체 생산과정에서 나오는 반도체 장비의 데이터 분석, 수천개 수만개에 달하는 정보들을 한번에 획득하고 변수도 굉장히 많은데 우리가 궁극적으로 알고 싶은 건 많은 변수들에서 획득된 정보를 가지고 최종적으로 내가 지금 만들고 있는 이 반도체가 정상으로 나올건가 불량으로 나올건가를 알고싶은 거. 근데 그거를 설명할 수 있는 변수들이 너무 많음. 그안에는 당연히 굉장히 핵심적이고 중요한 변수들도 있겠지만 또 불필요한 이 모형을 학습하는데 있어서 쓸모없는 변수가 있을 수 있다.
   그래서 우리는 모형을 구축하고 최종적인 결과물을 설명하는데 있어서 중요한 변수들이 있다. --> 피처 셀렉션 변수선택 과정이 필요하다.

에이아이가 어떤 결과를 냈는데 왜 저런 결과를 냈지? 어떤 변수가 그 영향을 줬지? 이런 것들을 결정하느 ㄴ것도 굉장히 중요한 문제 상황이다.(연구 주제이기도 함)


- Data Sampling
  - 모델을 검증하거나 이상 관측치를 찾는 모델링을 할 때 또는 앙상블 모델링을 할 때 가지고 있는 데이터를 일부분 추출하는 과정을 거치기도 함
  - 내가 가지고 있는 train 데이터를 모두 사용하는 것이 아니라 일부 샘플링 과정을 통해 모형을 학습하고 고도화시키는 과정을 거칠 수 있음
  - 모형 성능 향상, 이상치 제거와 같은 작업 가능

<br>

# <span class="half_HL">✔️ 모델링(Modeling)</span>
**Model** 은 입력 변수와 출력 변수 간의 관계를 정의해줄 수 있는 추상적인 함수 구조이다.

트레이닝 데이터로 트레이닝시키고, 검증함. 피드백 루프가 매우매우 필요함

트레이닝 데이터를 가지고 모형을 학습하고 검증하고 잘 안되는 경우가 생기기 때문에 어떤 부분이 잘못되었을 까 어떤 절차들을 더 해야 핧까 .. .실마리를 얻고 피드백 루트를 통해서 다시 한 번 들어가서 모형을 바꿔본다넌지... 만족할 만한 수준이 되었을 때 최종적인 모형이 나오는 과정이다.

이 과정을 잘 이해해야 함

피트백 루프 여러번 돌 수 있음... ㅠㅠ 도르륵
<br>

# <span class="half_HL">✔️ 모델링 검증</span>
**판단 기준** : 오차
- Underfit
  - 모형이 train data에 대해 학습이 잘 안됨
  - 너무 간단하게 모형을 세워서 학습한 경우

- Overfit
  - 너무 과도하게 적합시킨 경우

테스트 데이터에 대해서 계산된 오차를 가지고 오차가 크냐 작냐로 언더핏, 오버핏 고려해볼 수 있음

- Training error
  - 학습 데이터에 대한 예측 오차 (손실)
- Validation error
  - 유효성 검사 데이터에 대한 예측 오차 (일반적인 오차)

모델의 복잡도에 따라서 training error, validation error, testing error 달라짐
training error는 모델의 복잡도가 커짐에 따라 줄어든다
validation error는 어느정도 줄어들다가 커지는 현상이 발생한다.
- 모델이 너무 복잡해서 오차 클 수 있고, 모델이 너무 간략해서 오차가 클 수 있다.

너무 복잡하지도 않고 간단하지도 않은 적절ㄹ한 수준의 모형으로 학습시켜야 함

복잡도를 결정하게 되는 것은 


파라미터이고 

하이퍼파라미터는 어던 구조를 결정하는데 있어서 영향을 줄 수 있는 어떤 선택의 요소를 말함
그거셍 따라서 모형의 복잡도가 달라질 수 있다.


잊지말아야하는 점 
우리가 모양의 복잡도를 결정하고 그에 따라서 벨이리데이션 에러가 변화가 일어나고 작을 때 
에러가 가장 작을 때의 복잡도를 갖는 모델을 선택해야함

** 모델링 검증 방법

1번으로 하면 모형이 일반화가 잘 되는지확인하기 어렵기 때문에 적합하지 않음
2번은 적절한 하이퍼 파라미터를 고를 수 없음 하이퍼파라미터를 바꿔보면서 검증해봐야하는데 최적의 모형선택에까지도 영향을 받지 않았던 그런 데이터 테스트 데이터를 가지고 검증하는 것이 검증력이 높음

하이퍼파라미트를 튜닝하는데 있어서도 여향을 주지않는 거니까..

그런 실제 상황을 만족시키기 위해 3번 
train, validation, test로 3개로 나눠서 모델의 복잡도를 결정하고(가장 적합한) 
벨리데이션을 테스트로 편입해서 결정된 모델 컨퍼런스 뒤에 모형을 가지고 트레인시키고 테스팅해서 실제로 이정도 성능 나올거야 ~ 결과 리포트 하게 됨


데이터가 적은 경우, 트레이닌ㅇ, 벨리데이션, 테스팅으로 나누기 어려우면 cross validation을 쓸 수 있음 (4번)
전체 데이터를 폴드로 나누고 트레이닝을 5개로 나누고 벨리데이션을 순차적으로 바꿔가면서 적용해서 어떤 파라미터 최적의 상태 찾고 테스팅하고 ... 할 수 ㅣㅇㅆ음

가장 추천하는 것은 세번째 가장 일반적인 검증 단계이다.

<br>

# <span class="half_HL">✔️ Reference</span>
- [K-MOOC - 실습으로 배우는 머신러닝 | 김영훈 교수](http://www.kmooc.kr/courses/course-v1:SSUk+SSMOOC20K+2022_T2/about)