---
title:  "[ML] 부스팅(Boosting) 모델(XGBoost, LightGBM, CatBoost🐈)"
layout: single

categories: "ML"
tags: ["XGBoost", "LightGBM", "CatBoost"]

toc: true
toc_sticky: true
toc_label : "목차"
toc_icon: "bars"

published: false
---

<small>GBT(Gradient Boosting Machine) 단점을 보완 및 개선한 모델인 XGBoost, LightGBM, CatBoost에 대해 알아본다.</small>

***

> 🎯 **학습 목표** <br>
Gradient Boosting 기반의 Machine Learning 기법인 **XGboost**, **LightGBM**, **CatBoost** 에 대해 알아본다.

<br>

# <span class="half_HL">✔️ XGboost</span>
XGboost는 Extreme Gradient Boosting의 약자로, 그래디언트 부스팅 프레임워크를 사용하는 결정 트리(Decision Tree) 기반의 앙상블 학습 방법입니다. 

이 알고리즘은 <u>정형 데이터(Structured Data)를 가지고 예측할 때 매우 우수한 성능을 보여 주목을 받았으며</u> 분류(Classification)과 회귀(Regression) 같은 예측 분석에 사용됩니다. 또한 구조화되지 않은 데이터(이미지, 텍스트 등)와 관련된 예측 문제에서서 다른 모든 알고리즘이나 프레임워크를 능가하는 경향이 있습니다.

<br>

<div style="text-align : center;">
<img src="https://miro.medium.com/max/1400/1*QJZ6W-Pck_W7RlIDwUIN9Q.jpeg" width="500">
</div>
<center><small>Fig 1. 결정 트리에서 XGBoost로의 알고리즘 진화 과정</small></center>

<br>

## 1. XGBoost 장단점
### (1) XGBoost의 장점
- 병렬 학습이 가능해 GBM 대비 학습시간이 적게 걸림
- **과적합 규제(Regularization)**, **트리 가지치기(Tree Pruning)**, **조기 중단(Early Stopping)** 과 같은 성능 향상에 필요한 기능 탑재
- **다양한 옵션(Hyper Parameter)** 을 제공하며 Customizing이 용이함

### (2) XGBoost의 단점
- GBM에 비해 좋은 성능을 보여주고 비교적 빠르지만 여전히 **학습시간이 느림**
- 하이퍼파라미터 수가 많아 튜닝을 하게 되면 시간이 오래 걸림
- 적절하지 못한 튜닝은 모델의 **오버피팅(OverFitting)** 을 야기함

## 2. XGBoost 하이퍼 파라미터

### (1) 사이킷런 API 기준 하이퍼파라미터

<br>

<div style="text-align : center;">
<img src="https://assaeunji.github.io/images/xgboost_params.png" width="500">
</div>
<center><small>Fig 2. 사이킷런 API 기준 하이퍼파라미터</small></center>

<br>

### (3) 과적합 해결 방안
- ```learning_rate```를 낮추고 ```n_estimators```를 높인다.
- ```max_depth``` 값을 낮춘다.
- ```min_child_weight``` 값을 높인다.
- ```gamma``` 값을 높인다.
- ```subsample```, ```colsample_bytree``` 값을 조정한다.

<br>

# <span class="half_HL">✔️ LightGBM</span>

# <span class="half_HL">✔️ CatBoost</span>

# <span class="half_HL">✔️ Reference</span>
- [멋쟁이사자처럼 AI SCHOOL] 박조은 강사님 강의자료
- [WIKIPEDIA, The Free Encyclopedia - Boosting (machine learning)](https://en.wikipedia.org/wiki/Boosting_(machine_learning))
- [Towards Data Science by Vishal Morde - XGBoost Algorithm: Long May She Region!](https://towardsdatascience.com/https-medium-com-vishalmorde-xgboost-algorithm-long-she-may-rein-edd9f99be63d)
- [📷Fig 2 출처 : Github 블로그 by assaeunji - XGBoost vs. LightGBM, 어떤 알고리즘이 더 좋을까?](https://assaeunji.github.io/machine%20learning/2021-01-07-xgboost/)


<br>

👩🏻‍💻개인 공부 기록용 블로그입니다
<br>오류나 틀린 부분이 있을 경우 댓글 혹은 메일로 따끔하게 지적해주시면 감사하겠습니다.
{: .notice}