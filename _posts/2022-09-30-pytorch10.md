---
layout: single
title:  "Pytorch-10 Pytorch Troubleshooting"
categories : Pytorch
tag : troubleshooting, OOM
toc : true
---



# Pytorch Troubleshooting
스스로 문제를 해결하는 능력을 가져야 한다!
주로 GPU 문제를 다루겠음

## OOM - 공포의 단어
:out of memory
- 왜, 어디서 발생했는지 어려움
- Error backtracking도 이상한데로 감
- 메모리의 이전상황의 파악이 어려움


방법 모아봄
## Batch size 줄임 -> GPU clean -> Run


## GPUUtil 사용하기
nvidia-smi 처럼 GPU 상태를 보여주는 모듈
Colab은 환경에서 GPU상태 보여주기 편함
iter 마다 메모리 늘어나는지 확인

## torch.cuda.empty_cache() 써보기
사용되지 않은 gpu 상 cache 정리
가용 메모리 확보
del 과는 구분 필요
reset 대신 쓰기 좋음처
-> 학습전에 써 보는 것 추천

## training loop 에 tensro로 축적되는 변수는 확인
tensor로 처리된 변수는 gpu 상에 메모리 사용
해당 변수 loop안에 연산에 있을 때 gpu에 computational graph 생성



## del 명령어를 적절히 사용하기
필요가 없어진 변수는 적절한 삭제가 필요함
ex) loop이 끝나더라도 메모리를 차지하는 경우


## 가능한 batch 사이즈를 실험해보기
학습시 oom 발생 : batch 사이즈 1로 실험해보기


## torch.no_grad() 사용하기
Inference 시점에서는 torch.no_grad() 구문을 사용
backward pass 로 인해 쌓이는 메모리 x

```python
with torch.no_grad():
	for ~~
```


# 이외에도
OOM, CUDNN_STATUS_NOT_INIT, device-side-assert 등의 에러

colab에서 너무 큰 사이즈는 실행하지 말자

cnn의 대부분 에러는 크기가 안맞아서 생기는!

tensor의 float precision을 16bit로 줄일 수 있음




