---
layout: single
title: "텍스트 탐지&인식 2편"
permalink: /projects/pnid/05
tag: [Vision AI, Drawing]
author_profile: false
sidebar:
  nav: "docs1"
date: 2023-10-10
use_math: true
---

도면 내 텍스트 영역 탐지에 이어 이번 포스트에서는 **탐지 영역 내 텍스트를 인식하는 기술**에 대해 소개드립니다.

## 📋 Table of Contents

1. [텍스트 인식 배경](#1-텍스트-인식-배경)
2. [텍스트 인식 모델의 프레임워크 분석](#2-텍스트-인식-모델의-프레임워크-분석)
3. [텍스트 인식 모델 구축 과정](#3-텍스트-인식-모델-구축-과정)
4. [결론](#4-결론)

## 1. 텍스트 인식 배경
OCR(Optical Character Recognition)은 인쇄된 광학 문자 이미지를 기계가 읽을 수 있는 디지털 텍스트 데이터로 변환하는 기술입니다. 더 나아가 Real world에서 발생할 수 있는 다양한 노이즈와 왜곡이 섞여 있는 텍스트를 인식하는 STR(Scene Text Recognition)도 많은 발전을 하고 있습니다. 이 기술들은 디지털 서류 전환, 기밀문서 마스킹, 표지판 및 간판 인식 등 다양한 분야에서 유용하게 활용되는 기술이죠.<br><br>
현재 OCR은 주로 공문서, 신분증, 영수증, 서적 등과 같이 정형화된 포맷이나 사전적 의미가 있는 텍스트를 디지털화하는 데 많이 적용되고 있습니다. 예를 들어 아래 영수증과 같이 정형화된 포맷의 경우, 특정 영역에는 날짜, 시간, 품목, 가격 등과 같은 정해진 타입의 텍스트가 작성될 것이라 예상할 수 있습니다. 또한, 사전적 의미가 있는 텍스트의 경우, 잘못 인식된 경우에도 문맥을 고려하여 오타를 수정할 수 있습니다. <br><br>
하지만 설계 도면의 텍스트는 주로 특정 건설 사업에서 정의된 코드로 구성되어 있습니다. 이러한 코드들은 특수 기호들과 조합되어 최대 20자 이상의 단어로 표현될 수 있습니다. 따라서 설계 도면의 특성에 맞는 텍스트 인식 모델을 개발하는 것이 필요합니다.

<div align="center">
<img src="../../assets/images/2023-09-09-PnID(5)/OCR_example.png" alt="OCR-Example" />
</div>
<center>[ 영수증 OCR 인식 예시 ]</center>
*출처: [이미지 출처](https://viso.ai/computer-vision/optical-character-recognition-ocr/){:target="_blank"}*

## 2. 텍스트 인식 모델의 프레임워크 분석
텍스트 인식 모델의 성능을 평가하고 비교하는 일은 그 어떤 분야에서도 쉽지 않습니다. 2019년에 발표된 논문 ["What Is Wrong With Scene Text Recognition Model Comparisons? Dataset and Model Analysis"](https://arxiv.org/abs/1904.01906){:target="_blank"} 에서는 이러한 어려움을 극복하기 위한 프레임워크를 제안하고 있습니다. 여기서는 이 논문에서 제시한 프레임워크의 네 가지 핵심 스테이지를 통해 텍스트 인식 모델을 분석해보겠습니다.
### Transformation(Trans.): 변환 스테이지
이 단계에서는 Spatial Transformation Network(STN)의 변형 중 하나인 Thin-Plate Spline(TPS) 변환을 사용합니다. TPS 변환은 다양한 형태의 기하학적 왜곡을 쉽게 표현할 수 있어, 복잡한 텍스트 형태를 보정하는 데 사용됩니다. 특히 곡선 또는 기울어진 텍스트와 같은 어려운 형태의 텍스트를 정규화하여 후속 단계의 처리를 향상시킵니다.
### Feature Extraction(Feat.): 특징 추출 스테이지
이 단계에서는 입력 데이터로부터 중요한 시각 정보를 추출하여 학습된 패턴을 기반으로 새로운 데이터를 분류하거나 인식하는 데 필수적입니다. 일반적인 CNN 아키텍처는 합성곱 신경망 구조를 기반이며 텍스트의 크기, 폰트, 배경 등 관련 없는 정보를 제외하고 텍스트 이미지의 정보를 분류하는 작업을 합니다. 연구 결과, ResNet 아키텍처가 VGG와 RCNN보다 우수한 성능을 보였습니다. 이는 텍스트 이미지의 정보를 분류하는 작업에서 뛰어난 효과를 발휘합니다.
### Sequence Modeling (Seq.): 시퀀스 모델링 스테이지
이 단계에서는 텍스트를 캐릭터 단위로 인식하는 것이 아닌 텍스트의 시퀀스를 문맥 정보로써 인식합니다. 따라서, 모델은 추출된 특징을 시퀀스로 재구성하고, 문맥 정보를 포함하여 더 나은 시퀀스를 형성하는 데 목표를 두고 있습니다. 여기서 BiLSTM을 사용하는 경우 더 넓은 문맥을 이해하고 문자를 예측할 수 있습니다.
### Prediction (Pred.): 예측 스테이지
이전 단계를 통해 얻은 특징들을 단어들의 시퀀스로 예측하는 작업을 수행합니다. 여기서 두 가지 선택 사항이 있습니다. 첫 번째로 [Connectionist Temporal Classification(CTC)](https://dl.acm.org/doi/abs/10.1145/1143844.1143891){:target="_blank"}는 중복 문자와 공백을 제거하여 가변 길이의 출력 문자 시퀀스를 예측하는 방법입니다. 두 번째로 [Attention-based Sequence Prediction (Attn)](https://openaccess.thecvf.com/content_iccv_2017/html/Cheng_Focusing_Attention_Towards_ICCV_2017_paper.html){:target="_blank"} 은 주요 정보 흐름을 파악하여 출력 문자 시퀀스를 예측합니다. 특히 Attn은 문자 간의 의존성을 학습할 수 있도록 돕기 때문에 문자 일부가 가려져있거나 누락된 경우에 더 나은 결과를 보입니다.

<div align="center">
<img src="../../assets/images/2023-09-09-PnID(5)/previously_proposed_combinations.png" alt="Previously-Proposed-Combinations" />
</div>
<center>[ 기존 텍스트 인식 모델의 스테이지 조합 ]</center>
*출처: [이미지 출처](https://arxiv.org/abs/1904.01906){:target="_blank"}*

위 그림은 기존에 제안된 텍스트 인식 모델을 네 가지 스테이지로 구분지어 정의하고 일관된 벤치마크 데이터셋으로 성능을 평가한 결과 자료입니다.<br>
각 스테이지의 특성을 이해하고 이를 조합하여 적합한 모델을 개발한다면, 설계 도면 내 텍스트를 인식하는 데 더 나은 성능을 기대할 수 있습니다. 따라서 설계 도면 내 텍스트를 인식 분야에서는 어떤 stage의 조합이 최적의 조합일지 실험해보겠습니다.

## 3. 텍스트 인식 모델 구축 과정
